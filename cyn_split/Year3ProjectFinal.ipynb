{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using 'all' file instead of 'wmo' file\"\"\"\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset,num2date\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm, poisson, lognorm, chisquare, linregress, ttest_ind, power_divergence, ks_2samp, chi2_contingency\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import factorial\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib tk    #Uncomment for interactive figures\n",
    "import geopy.distance as gd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read .nc file, credits: Theo Rashid'''\n",
    "tic = time.time() #Expect runtime ~5 min\n",
    "\n",
    "nc_ibtracs = 'Allstorms.ibtracs_all.v03r10.nc' #Using 'all' file\n",
    "ibt = Dataset(nc_ibtracs)\n",
    "\n",
    "name          = ibt.variables['name'][:] #Name of TC\n",
    "storm_sn      = ibt.variables['storm_sn'][:] \n",
    "time_record   = ibt.variables['source_time'][:] #Time of record\n",
    "landfall      = ibt.variables['landfall'][:]\n",
    "\n",
    "genesis_basin = ibt.variables['genesis_basin'][:]\n",
    "season        = ibt.variables['season'][:]\n",
    "\n",
    "lat           = ibt.variables['source_lat'][:] #Latitude of TC centre\n",
    "lon           = ibt.variables['source_lon'][:] #Longitude of TC centre\n",
    "max_wind      = ibt.variables['source_wind'][:] #Max. wind speed\n",
    "min_pres      = ibt.variables['source_pres'][:] #Central pressure\n",
    "dist2land     = ibt.variables['dist2land'][:] #Distance to land\n",
    "    \n",
    "\n",
    "nc_landmask = 'ETOPO1_Ice_g_gmt4.nc' #Land mask from ETOPO1 Global Relief Model\n",
    "land = Dataset(nc_landmask)\n",
    "\n",
    "landmask_lon = land.variables['lon'][:] #Longitude points of land mask\n",
    "landmask_lat = land.variables['lat'][:] #Latitude points\n",
    "z = land.variables['z'][:] #Altitude\n",
    "landmask_LAT, landmask_LON = np.meshgrid(landmask_lat, landmask_lon) #Create meshgrid for getting and plotting each point\n",
    "\n",
    "source_list = [10,14,19,21] #These are data from ibt, 10 is jtwc_wp, #14 is cma, #19 is wmo tokyo, #21 is hko\n",
    "LAT         = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "LON         = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "MAX_WIND    = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "MIN_PRES    = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "DIST2LAND   = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "TIME_RECORD = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "LANDFALL    = np.nan * np.ones(shape=(np.size(lat,0),np.size(lat,1),len(source_list)))\n",
    "\n",
    "for INDEX_RECORD_SOURCE in source_list: \n",
    "    LAT      [:,:,source_list.index(INDEX_RECORD_SOURCE)] = lat[:,:,INDEX_RECORD_SOURCE] \n",
    "    LON      [:,:,source_list.index(INDEX_RECORD_SOURCE)] = lon[:,:,INDEX_RECORD_SOURCE]\n",
    "    MAX_WIND [:,:,source_list.index(INDEX_RECORD_SOURCE)] = max_wind[:,:,INDEX_RECORD_SOURCE]\n",
    "    MIN_PRES [:,:,source_list.index(INDEX_RECORD_SOURCE)] = min_pres[:,:,INDEX_RECORD_SOURCE]\n",
    "    \n",
    "    DIST2LAND   = dist2land.data[:]\n",
    "    TIME_RECORD = time_record.data[:]\n",
    "    LANDFALL    = landfall.data[:].astype(float)\n",
    "\n",
    "TCinseason = [] #Index of TCs occuring on or after 2014, needed for rainfall\n",
    "for i in range(len(list(season))):\n",
    "    if list(season)[i] >= 2014:\n",
    "        TCinseason.append(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract PHI data\n",
    "tic = time.time() #Expect runtime ~3min\n",
    "\n",
    "#Input extreme point = [x,y]\n",
    "extremeP_N = [122.9, 19.2]\n",
    "extremeP_S = [122.6, 3.5]\n",
    "extremeP_E = [128.2, 6.2]\n",
    "extremeP_W = [117.4, 18.1]\n",
    "\n",
    "#Slope of lines bounding region\n",
    "m_top_P = (extremeP_N[1]-extremeP_W[1])/(extremeP_N[0]-extremeP_W[0])\n",
    "m_bot_P = (extremeP_S[1]-extremeP_E[1])/(extremeP_S[0]-extremeP_E[0])\n",
    "m_left_P = (extremeP_S[1]-extremeP_W[1])/(extremeP_S[0]-extremeP_W[0])\n",
    "m_right_P = (extremeP_N[1]-extremeP_E[1])/(extremeP_N[0]-extremeP_E[0])\n",
    "\n",
    "#Intercept of lines\n",
    "c_top_P = extremeP_N[1]-m_top_P*extremeP_N[0]\n",
    "c_bot_P = extremeP_S[1]-m_bot_P*extremeP_S[0]\n",
    "c_left_P = extremeP_S[1]-m_left_P*extremeP_S[0]\n",
    "c_right_P = extremeP_N[1]-m_right_P*extremeP_N[0]\n",
    "\n",
    "#Get points in land mask file which are in PHI area\n",
    "def philippine_landmask_points(landmask_LON,landmask_LAT):\n",
    "    landmask_points = []\n",
    "    \n",
    "    for i in range(17400,18500): \n",
    "        for i2 in range(5600,6600):\n",
    "            equation_top = m_top_P * landmask_LON[i,i2] + c_top_P\n",
    "            equation_bot = m_bot_P * landmask_LON[i,i2] + c_bot_P \n",
    "            equation_left = m_left_P * landmask_LON[i,i2] + c_left_P \n",
    "            equation_right  = m_right_P * landmask_LON[i,i2] + c_right_P\n",
    "    \n",
    "            if landmask_LAT[i,i2] <= equation_top and landmask_LAT[i,i2] <= equation_right and landmask_LAT[i,i2] >= equation_bot and landmask_LAT[i,i2] >= equation_left:\n",
    "                landmask_points.append(i)\n",
    "                landmask_points.append(i2)\n",
    "        \n",
    "    return landmask_points\n",
    "    \n",
    "#Get TC centre points in PHI area\n",
    "def philippine_data_extraction(LON,LAT,after2014=False,separate_NS=False): \n",
    "    #after2014: True means only include TC data after 2014\n",
    "    #Separate NS: If you want to separate PHI into Northern and Southern parts, type 'N' or 'S' respectively,\n",
    "    #    otherwise, or for GD, type 'False'\n",
    "    \n",
    "    philippine_data = []\n",
    "    PHI_TCposition = {}\n",
    "    \n",
    "    philippine_data_N = []\n",
    "    philippine_data_S = []\n",
    "    PHI_TCposition_N = {}\n",
    "    PHI_TCposition_S = {}\n",
    "    \n",
    "    if separate_NS == False:\n",
    "        for i in range (len(LON)):\n",
    "            PHI_TCposition[str(i)] = []\n",
    "            for i2 in range (len(LON[i])): \n",
    "                equation_top = m_top_P * LON[i,i2] + c_top_P\n",
    "                equation_bot = m_bot_P * LON[i,i2] + c_bot_P \n",
    "                equation_left = m_left_P * LON[i,i2] + c_left_P \n",
    "                equation_right  = m_right_P * LON[i,i2] + c_right_P\n",
    "\n",
    "                if after2014 == True:\n",
    "                    if i in TCinseason and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data.append((i))\n",
    "                        PHI_TCposition[str(i)].append(i2)\n",
    "                else:\n",
    "                    if LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data.append((i))\n",
    "                        PHI_TCposition[str(i)].append(i2)\n",
    "                        \n",
    "        return np.unique(philippine_data), PHI_TCposition\n",
    "                    \n",
    "    elif separate_NS == True:\n",
    "        NSlatboundary = 14.4 #Set latitude for dividing into North and South\n",
    "        for i in range(len(LON)):\n",
    "            PHI_TCposition_N[str(i)] = []\n",
    "            PHI_TCposition_S[str(i)] = []\n",
    "            for i2 in range (len(LON[i])): \n",
    "                equation_top = m_top_P * LON[i,i2] + c_top_P #Equation of straight line\n",
    "                equation_bot = m_bot_P * LON[i,i2] + c_bot_P \n",
    "                equation_left = m_left_P * LON[i,i2] + c_left_P \n",
    "                equation_right  = m_right_P * LON[i,i2] + c_right_P\n",
    "                \n",
    "                #Check to see if a point is inside the boundary\n",
    "                if after2014 == True:\n",
    "                    if i in TCinseason and LAT[i,i2] > NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_N.append((i))\n",
    "                        PHI_TCposition_N[str(i)].append(i2)\n",
    "                    elif i in TCinseason and LAT[i,i2] <= NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_S.append((i))\n",
    "                        PHI_TCposition_S[str(i)].append(i2)\n",
    "\n",
    "                else:\n",
    "                    if LAT[i,i2] > NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_N.append((i))\n",
    "                        PHI_TCposition_N[str(i)].append(i2)\n",
    "                    elif LAT[i,i2] <= NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_S.append((i))\n",
    "                        PHI_TCposition_S[str(i)].append(i2)\n",
    "                    \n",
    "        return np.unique(philippine_data_N), np.unique(philippine_data_S), PHI_TCposition_N, PHI_TCposition_S\n",
    "                \n",
    "\n",
    "landmask_in_area_PHI = np.array(philippine_landmask_points(landmask_LON,landmask_LAT))\n",
    "landmask_in_area_PHI = landmask_in_area_PHI.reshape(int(len(landmask_in_area_PHI)/2),2)\n",
    "\n",
    "z_coastline_PHI = [] #Find PHI coastline from land mask (this list contains index of elements)\n",
    "z_land_PHI = [] #Find PHI land points from land mask\n",
    "for i in range(len(landmask_in_area_PHI)):\n",
    "    if z[landmask_in_area_PHI[i,1],landmask_in_area_PHI[i,0]] == 0: #Coast if altitude == 0\n",
    "        z_coastline_PHI.append(landmask_in_area_PHI[i,0])\n",
    "        z_coastline_PHI.append(landmask_in_area_PHI[i,1])\n",
    "    elif z[landmask_in_area_PHI[i,1],landmask_in_area_PHI[i,0]] >= 0: #Land if altitude >= 0\n",
    "        z_land_PHI.append(landmask_in_area_PHI[i,0])\n",
    "        z_land_PHI.append(landmask_in_area_PHI[i,1])\n",
    "        \n",
    "z_coastline_PHI = np.asarray(z_coastline_PHI).reshape(int(len(z_coastline_PHI)/2),2)\n",
    "z_land_PHI = np.asarray(z_land_PHI).reshape(int(len(z_land_PHI)/2),2)\n",
    "\n",
    "z_coastline_coord_PHI = np.zeros(z_coastline_PHI.shape) #list of coordinates of PHI coastline (change index to actual coordinates)\n",
    "z_coastline_coord_PHI[:,0] = landmask_lon[z_coastline_PHI[:,0]]\n",
    "z_coastline_coord_PHI[:,1] = landmask_lat[z_coastline_PHI[:,1]]\n",
    "\n",
    "z_land_coord_PHI = np.zeros(z_land_PHI.shape) #List of coordinates of PHI land\n",
    "z_land_coord_PHI[:,0] = landmask_lon[z_land_PHI[:,0]]\n",
    "z_land_coord_PHI[:,1] = landmask_lat[z_land_PHI[:,1]]\n",
    "\n",
    "landfallTC_PHI_jtwc = philippine_data_extraction(LON[:,:,0],LAT[:,:,0])[0] #list (keys)\n",
    "landfallTC_PHI_jtwc_after2014 = philippine_data_extraction(LON[:,:,0],LAT[:,:,0], True)[0]\n",
    "landfallTC_PHI_cma = philippine_data_extraction(LON[:,:,1],LAT[:,:,1])[0] #list (keys)\n",
    "landfallTC_PHI_cma_after2014 = philippine_data_extraction(LON[:,:,1],LAT[:,:,1], True)[0]\n",
    "landfallTC_PHI_wmo = philippine_data_extraction(LON[:,:,2],LAT[:,:,2])[0] #list (keys)\n",
    "landfallTC_PHI_wmo_after2014 = philippine_data_extraction(LON[:,:,2],LAT[:,:,2], True)[0]\n",
    "\n",
    "PHI_TCposition_jtwc = philippine_data_extraction(LON[:,:,0],LAT[:,:,0])[1] #dict (tc index and position index)\n",
    "PHI_TCposition_jtwc_after2014 = philippine_data_extraction(LON[:,:,0],LAT[:,:,0],True)[1]\n",
    "PHI_TCposition_cma = philippine_data_extraction(LON[:,:,1],LAT[:,:,1])[1] #dict (tc index and position index)\n",
    "PHI_TCposition_cma_after2014 = philippine_data_extraction(LON[:,:,1],LAT[:,:,1],True)[1]\n",
    "PHI_TCposition_wmo = philippine_data_extraction(LON[:,:,2],LAT[:,:,2])[1] #dict (tc index and position index)\n",
    "PHI_TCposition_wmo_after2014 = philippine_data_extraction(LON[:,:,2],LAT[:,:,2],True)[1]\n",
    "\n",
    "landfallTC_PHI_jtwc_N, landfallTC_PHI_jtwc_S, PHI_TCposition_jtwc_N, PHI_TCposition_jtwc_S = philippine_data_extraction(LON[:,:,0],LAT[:,:,0],False, True)\n",
    "landfallTC_PHI_jtwc_N_after2014, landfallTC_PHI_jtwc_S_after2014, PHI_TCposition_jtwc_N_after2014, PHI_TCposition_jtwc_S_after2014 = philippine_data_extraction(LON[:,:,0],LAT[:,:,0],True, True)\n",
    "landfallTC_PHI_cma_N, landfallTC_PHI_cma_S, PHI_TCposition_cma_N, PHI_TCposition_cma_S = philippine_data_extraction(LON[:,:,1],LAT[:,:,1],False, True)\n",
    "landfallTC_PHI_cma_N_after2014, landfallTC_PHI_cma_S_after2014, PHI_TCposition_cma_N_after2014, PHI_TCposition_cma_S_after2014 = philippine_data_extraction(LON[:,:,1],LAT[:,:,1],True, True)\n",
    "landfallTC_PHI_wmo_N, landfallTC_PHI_wmo_S, PHI_TCposition_wmo_N, PHI_TCposition_wmo_S = philippine_data_extraction(LON[:,:,2],LAT[:,:,2],False, True)\n",
    "landfallTC_PHI_wmo_N_after2014, landfallTC_PHI_wmo_S_after2014, PHI_TCposition_wmo_N_after2014, PHI_TCposition_wmo_S_after2014 = philippine_data_extraction(LON[:,:,2],LAT[:,:,2],True, True)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract GD data\n",
    "\n",
    "tic = time.time() #Expect runtime ~2min\n",
    "\n",
    "extremeG_N = [117.4, 24.2]\n",
    "extremeG_S = [109.8, 19.9]\n",
    "extremeG_E = [117.7, 22.9]\n",
    "extremeG_W = [109.4, 22.2]\n",
    "\n",
    "m_top_G = (extremeG_N[1]-extremeG_W[1])/(extremeG_N[0]-extremeG_W[0])\n",
    "m_bot_G = (extremeG_S[1]-extremeG_E[1])/(extremeG_S[0]-extremeG_E[0])\n",
    "m_left_G = (extremeG_S[1]-extremeG_W[1])/(extremeG_S[0]-extremeG_W[0])\n",
    "m_right_G = (extremeG_N[1]-extremeG_E[1])/(extremeG_N[0]-extremeG_E[0])\n",
    "\n",
    "c_top_G = extremeG_N[1]-m_top_G*extremeG_N[0]\n",
    "c_bot_G = extremeG_S[1]-m_bot_G*extremeG_S[0]\n",
    "c_left_G = extremeG_S[1]-m_left_G*extremeG_S[0]\n",
    "c_right_G = extremeG_N[1]-m_right_G*extremeG_N[0]\n",
    "\n",
    "def guangdong_landmask_points(landmask_LON,landmask_LAT):\n",
    "\n",
    "    landmask_points = []\n",
    "\n",
    "    for i in range(17200,17900): \n",
    "        for i2 in range(6500,7000):\n",
    "            equation_top = m_top_G * landmask_LON[i,i2] + c_top_G\n",
    "            equation_bot = m_bot_G * landmask_LON[i,i2] + c_bot_G \n",
    "            equation_left = m_left_G * landmask_LON[i,i2] + c_left_G\n",
    "            equation_right  = m_right_G * landmask_LON[i,i2] + c_right_G\n",
    "    \n",
    "            if landmask_LAT[i,i2] <= equation_top and landmask_LAT[i,i2] <= equation_right and landmask_LAT[i,i2] >= equation_bot and landmask_LAT[i,i2] >= equation_left:\n",
    "                landmask_points.append(i)\n",
    "                landmask_points.append(i2)\n",
    "        \n",
    "    return landmask_points\n",
    "\n",
    "def guangdong_data_extraction(LON,LAT,after2014=False): \n",
    "    guangdong_data = []\n",
    "    GD_TCposition = {}\n",
    "    \n",
    "    for i in range (len(LON)):\n",
    "        GD_TCposition[str(i)] = []\n",
    "        for i2 in range (len(LON[i])):\n",
    "            equation_top = m_top_G * LON[i,i2] + c_top_G\n",
    "            equation_bot = m_bot_G * LON[i,i2] + c_bot_G \n",
    "            equation_left = m_left_G * LON[i,i2] + c_left_G \n",
    "            equation_right  = m_right_G * LON[i,i2] + c_right_G\n",
    "            \n",
    "            if after2014 == True:\n",
    "                if i in TCinseason and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                    guangdong_data.append((i))\n",
    "                    GD_TCposition[str(i)].append(i2)\n",
    "            else:\n",
    "                if LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                    guangdong_data.append((i))\n",
    "                    GD_TCposition[str(i)].append(i2)\n",
    "            \n",
    "    return np.unique(guangdong_data), GD_TCposition\n",
    "\n",
    "landmask_in_area_GD = np.asarray(guangdong_landmask_points(landmask_LON,landmask_LAT))\n",
    "landmask_in_area_GD = landmask_in_area_GD.reshape(int(len(landmask_in_area_GD)/2),2)\n",
    "\n",
    "\n",
    "z_coastline_GD = []\n",
    "z_land_GD = []\n",
    "for i in range(len(landmask_in_area_GD)):\n",
    "    if z[landmask_in_area_GD[i,1],landmask_in_area_GD[i,0]] == 0: \n",
    "        z_coastline_GD.append(landmask_in_area_GD[i,0])\n",
    "        z_coastline_GD.append(landmask_in_area_GD[i,1])\n",
    "    elif z[landmask_in_area_GD[i,1],landmask_in_area_GD[i,0]] >= 0:\n",
    "        z_land_GD.append(landmask_in_area_GD[i,0])\n",
    "        z_land_GD.append(landmask_in_area_GD[i,1])\n",
    "        \n",
    "z_coastline_GD = np.asarray(z_coastline_GD).reshape(int(len(z_coastline_GD)/2),2)\n",
    "z_land_GD = np.asarray(z_land_GD).reshape(int(len(z_land_GD)/2),2)\n",
    "\n",
    "z_coastline_coord_GD = np.zeros(z_coastline_GD.shape) #list of coordinates of GD coastline\n",
    "z_coastline_coord_GD[:,0] = landmask_lon[z_coastline_GD[:,0]]\n",
    "z_coastline_coord_GD[:,1] = landmask_lat[z_coastline_GD[:,1]]\n",
    "\n",
    "z_land_coord_GD = np.zeros(z_land_GD.shape)\n",
    "z_land_coord_GD[:,0] = landmask_lon[z_land_GD[:,0]]\n",
    "z_land_coord_GD[:,1] = landmask_lat[z_land_GD[:,1]]\n",
    "        \n",
    "landfallTC_GD_jtwc = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0])[0] #list (index)\n",
    "landfallTC_GD_jtwc_after2014 = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0],True)[0]\n",
    "landfallTC_GD_cma = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1])[0] #list (index)\n",
    "landfallTC_GD_cma_after2014 = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1],True)[0]\n",
    "landfallTC_GD_wmo = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2])[0] #list (index)\n",
    "landfallTC_GD_wmo_after2014 = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2],True)[0]\n",
    "\n",
    "GD_TCposition_jtwc = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0])[1] #dict (tc index & position index)\n",
    "GD_TCposition_jtwc_after2014 = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0],True)[1]\n",
    "GD_TCposition_cma = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1])[1] #dict (tc index & position index)\n",
    "GD_TCposition_cma_after2014 = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1],True)[1]\n",
    "GD_TCposition_wmo = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2])[1] #dict (tc index & position index)\n",
    "GD_TCposition_wmo_after2014 = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2],True)[1]\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "'''\n",
    "Here, we are only looking at the landfall typhoon point and the point before that\n",
    "'''\n",
    "\n",
    "tic = time.time() #Expected runtime ~45s\n",
    "\n",
    "#Gets the data for TCs at first landfall point, and closest point before landfall\n",
    "def get_landfall_data_beforeandafter(area, source, after2014 = False, PHI_NS = False):\n",
    "    #area: if PHI, type '0'; if GD, type '1'\n",
    "    #source: if JTWC, type '0'; if CMA, type '1'; if WMO, type '2'\n",
    "    #after2014: True means only include TC data after 2014\n",
    "    #Separate NS: If you want to separate PHI into Northern and Southern parts, type 'N' or 'S' respectively,\n",
    "    #    otherwise, or for GD, type 'False'\n",
    "    \n",
    "    pres = {}\n",
    "    wind = {}\n",
    "    coord = {}\n",
    "    disttoland = {}\n",
    "    list_of_index = {}\n",
    "    epsilon = 1e-5 #To account for rounding errors when comparing numbers\n",
    "    \n",
    "    if area == 0: #PHI\n",
    "        if source == 0: #jtwc\n",
    "            if PHI_NS == False:\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_jtwc_after2014\n",
    "                    posindex = PHI_TCposition_jtwc_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_jtwc\n",
    "                    posindex = PHI_TCposition_jtwc\n",
    "            elif PHI_NS == 'N':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_jtwc_N_after2014\n",
    "                    posindex = PHI_TCposition_jtwc_N_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_jtwc_N\n",
    "                    posindex = PHI_TCposition_jtwc_N\n",
    "            elif PHI_NS == 'S':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_jtwc_S_after2014\n",
    "                    posindex = PHI_TCposition_jtwc_S_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_jtwc_S\n",
    "                    posindex = PHI_TCposition_jtwc_S\n",
    "        elif source == 1: #cma\n",
    "            if PHI_NS == False:\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_cma_after2014\n",
    "                    posindex = PHI_TCposition_cma_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_cma\n",
    "                    posindex = PHI_TCposition_cma\n",
    "            elif PHI_NS == 'N':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_cma_N_after2014\n",
    "                    posindex = PHI_TCposition_cma_N_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_cma_N\n",
    "                    posindex = PHI_TCposition_cma_N\n",
    "            elif PHI_NS == 'S':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_cma_S_after2014\n",
    "                    posindex = PHI_TCposition_cma_S_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_cma_S\n",
    "                    posindex = PHI_TCposition_cma_S\n",
    "        elif source == 2: #wmo\n",
    "            if PHI_NS == False:\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_wmo_after2014\n",
    "                    posindex = PHI_TCposition_wmo_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_wmo\n",
    "                    posindex = PHI_TCposition_wmo\n",
    "            elif PHI_NS == 'N':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_wmo_N_after2014\n",
    "                    posindex = PHI_TCposition_wmo_N_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_wmo_N\n",
    "                    posindex = PHI_TCposition_wmo_N\n",
    "            elif PHI_NS == 'S':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_wmo_S_after2014\n",
    "                    posindex = PHI_TCposition_wmo_S_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_wmo_S\n",
    "                    posindex = PHI_TCposition_wmo_S\n",
    "            \n",
    "            \n",
    "        landmask_lat = z_land_coord_PHI[:,1]\n",
    "        landmask_lon = z_land_coord_PHI[:,0]\n",
    "        for i in list(tcindex): #Loop over each TC in list\n",
    "            landindexinarea = []\n",
    "            for j in posindex[str(i)]: #Loop over each data point for that TC\n",
    "                TClat = LAT[:,:,source][i][j]\n",
    "                TClon = LON[:,:,source][i][j]\n",
    "                \n",
    "                #Find all land points with same latitude\n",
    "                landpoint_onlat_temp1 = np.where(landmask_lat <= TClat + epsilon)\n",
    "                landpoint_onlat_temp2 = np.where(landmask_lat >= TClat - epsilon)\n",
    "                landpoint_onlat_index = np.intersect1d(landpoint_onlat_temp1,landpoint_onlat_temp2) #Index of points in landmask array where latitude is same as TClat\n",
    "                landpoint_onlat_lon = landmask_lon[landpoint_onlat_index] #Lon of landmask points with same lat as TClat\n",
    "                \n",
    "                if landpoint_onlat_lon.size != 0:\n",
    "                    landpoint_onlat_maxlon = max(landpoint_onlat_lon) #Find easternmost PHI land point on same latitude\n",
    "                    landpoint_onlat_minlon = min(landpoint_onlat_lon) #Find westernmost PHI land point on same latitude\n",
    "                \n",
    "                    #Check whether TC is on land or ocean\n",
    "                    if landpoint_onlat_minlon-epsilon <= TClon <= landpoint_onlat_maxlon+epsilon:\n",
    "                        landindexinarea.append(j)\n",
    "            \n",
    "            landindexinarea = np.asarray(landindexinarea)\n",
    "            if landindexinarea.size != 0:\n",
    "                first_land_index = landindexinarea[0]\n",
    "                if first_land_index == 0:\n",
    "                    indexlist = [first_land_index]\n",
    "                else: \n",
    "                    indexlist = [first_land_index-1, first_land_index]\n",
    "\n",
    "                pres[str(i)] = MIN_PRES[:,:,source][int(i)][indexlist]\n",
    "                pres[str(i)] = [k for k in pres[str(i)] if k >= 0]\n",
    "                if pres[str(i)] == []:\n",
    "                    del pres[str(i)]\n",
    "                wind[str(i)] = MAX_WIND[:,:,source][int(i)][indexlist]\n",
    "                wind[str(i)] = [k for k in wind[str(i)] if k >= 0]\n",
    "                if wind[str(i)] == []:\n",
    "                    del wind[str(i)]\n",
    "                coord[str(i)] = np.array([LAT[:,:,source][int(i),indexlist],LON[:,:,source][int(i),indexlist]]).transpose()\n",
    "                if list(coord[str(i)][0]) == [-3e4,-3e4]: #Remove non-existant data\n",
    "                    coord[str(i)] = np.delete(coord[str(i)],0,0)\n",
    "                disttoland[str(i)] = DIST2LAND[int(i)][indexlist]\n",
    "                list_of_index[str(i)] = indexlist\n",
    "\n",
    "        if source == 1 and (PHI_NS == False or PHI_NS == 'N'):\n",
    "            #Add Mangkhut (to the end of the dict), source: cma\n",
    "            pres[str(len(list(season))+1)] = [910.0, 925.0] #Mangkhut\n",
    "            wind[str(len(list(season))+1)] = [65*1.944, 58*1.944] #Change m/s to knots\n",
    "            coord[str(len(list(season))+1)] = np.array([[17.8,123.4],[18.1,121.5]])    \n",
    "                \n",
    "\n",
    "    elif area == 1: #GD\n",
    "        if source == 0: #jtwc\n",
    "            if after2014 == True:\n",
    "                tcindex = landfallTC_GD_jtwc_after2014\n",
    "                posindex = GD_TCposition_jtwc_after2014\n",
    "            else:\n",
    "                tcindex = landfallTC_GD_jtwc\n",
    "                posindex = GD_TCposition_jtwc\n",
    "        elif source == 1: #cma\n",
    "            if after2014 == True:\n",
    "                tcindex = landfallTC_GD_cma_after2014\n",
    "                posindex = GD_TCposition_cma_after2014\n",
    "            else:\n",
    "                tcindex = landfallTC_GD_cma\n",
    "                posindex = GD_TCposition_cma\n",
    "        elif source == 2: #wmo\n",
    "            if after2014 == True:\n",
    "                tcindex = landfallTC_GD_wmo_after2014\n",
    "                posindex = GD_TCposition_wmo_after2014\n",
    "            else:\n",
    "                tcindex = landfallTC_GD_wmo\n",
    "                posindex = GD_TCposition_wmo\n",
    "\n",
    "        for i in list(tcindex):\n",
    "            distlist = DIST2LAND[int(i)][DIST2LAND[int(i)]>=0]\n",
    "            landindexes = np.where(distlist == 0)\n",
    "            landindexinarea = np.intersect1d(posindex[str(i)],landindexes)\n",
    "\n",
    "            if landindexinarea.size != 0:\n",
    "                first_land_index = landindexinarea[0]\n",
    "                if first_land_index == 0:\n",
    "                    indexlist = [first_land_index]\n",
    "                else: \n",
    "                    indexlist = [first_land_index-1, first_land_index]\n",
    "\n",
    "                pres[str(i)] = MIN_PRES[:,:,source][int(i)][indexlist]\n",
    "                pres[str(i)] = [k for k in pres[str(i)] if k >= 0] #Remove non-existant data\n",
    "                if pres[str(i)] == []:\n",
    "                    del pres[str(i)]\n",
    "                wind[str(i)] = MAX_WIND[:,:,source][int(i)][indexlist]\n",
    "                wind[str(i)] = [k for k in wind[str(i)] if k >= 0]\n",
    "                if wind[str(i)] == []:\n",
    "                    del wind[str(i)]\n",
    "                coord[str(i)] = np.array([LAT[:,:,source][int(i),indexlist],LON[:,:,source][int(i),indexlist]]).transpose()\n",
    "                if list(coord[str(i)][0]) == [-3e4,-3e4]: #Remove non-existant data\n",
    "                    coord[str(i)] = np.delete(coord[str(i)],0,0)\n",
    "                disttoland[str(i)] = DIST2LAND[int(i)][indexlist]\n",
    "                list_of_index[str(i)] = indexlist\n",
    "        \n",
    "        if source == 0:\n",
    "            #Add Hato (to the end of the dict), source: jtwc\n",
    "            pres[str(len(list(season)))] = [956.0, 964.0] #Hato\n",
    "            wind[str(len(list(season)))] = [90., 85.] #In knots\n",
    "            coord[str(len(list(season)))] = np.array([[21.5,114.5],[22.2,112.8]])\n",
    "            \n",
    "        elif source == 1:        \n",
    "            #Add Hato and Mangkhut (to the end of the dict), source: cma\n",
    "            pres[str(len(list(season)))] = [950.0, 950.0] #Hato\n",
    "            wind[str(len(list(season)))] = [42*1.944, 45*1.944] #Change m/s to knots\n",
    "            coord[str(len(list(season)))] = np.array([[21.5,114.7],[22.0,113.2]])\n",
    "\n",
    "            pres[str(len(list(season))+1)] = [950.0, 960.0] #Mangkhut\n",
    "            wind[str(len(list(season))+1)] = [48*1.944, 42*1.944]\n",
    "            coord[str(len(list(season))+1)] = np.array([[21.4, 113.8],[21.9, 112.0]])\n",
    "            \n",
    "    return pres, wind, coord, disttoland, list_of_index\n",
    "            \n",
    "##################### READ TILL HERE #################\n",
    "    \n",
    "landfalldata_pres_PHI_jtwc, landfalldata_wind_PHI_jtwc, landfalldata_coord_PHI_jtwc, landfalldata_dist2land_PHI_jtwc, landfalldata_indexlist_PHI_jtwc = get_landfall_data_beforeandafter(0,0)\n",
    "landfalldata_pres_GD_jtwc, landfalldata_wind_GD_jtwc, landfalldata_coord_GD_jtwc, landfalldata_dist2land_GD_jtwc, landfalldata_indexlist_GD_jtwc = get_landfall_data_beforeandafter(1,0)\n",
    "landfalldata_pres_PHI2014_jtwc, landfalldata_wind_PHI2014_jtwc, landfalldata_coord_PHI2014_jtwc, landfalldata_dist2land_PHI2014_jtwc, landfalldata_indexlist_PHI2014_jtwc = get_landfall_data_beforeandafter(0,0,True)\n",
    "landfalldata_pres_GD2014_jtwc, landfalldata_wind_GD2014_jtwc, landfalldata_coord_GD2014_jtwc, landfalldata_dist2land_GD2014_jtwc, landfalldata_indexlist_GD2014_jtwc = get_landfall_data_beforeandafter(1,0,True)\n",
    "\n",
    "landfalldata_pres_PHI_cma, landfalldata_wind_PHI_cma, landfalldata_coord_PHI_cma, landfalldata_dist2land_PHI_cma, landfalldata_indexlist_PHI_cma = get_landfall_data_beforeandafter(0,1)\n",
    "landfalldata_pres_GD_cma, landfalldata_wind_GD_cma, landfalldata_coord_GD_cma, landfalldata_dist2land_GD_cma, landfalldata_indexlist_GD_cma = get_landfall_data_beforeandafter(1,1)\n",
    "landfalldata_pres_PHI2014_cma, landfalldata_wind_PHI2014_cma, landfalldata_coord_PHI2014_cma, landfalldata_dist2land_PHI2014_cma, landfalldata_indexlist_PHI2014_cma = get_landfall_data_beforeandafter(0,1,True)\n",
    "landfalldata_pres_GD2014_cma, landfalldata_wind_GD2014_cma, landfalldata_coord_GD2014_cma, landfalldata_dist2land_GD2014_cma, landfalldata_indexlist_GD2014_cma = get_landfall_data_beforeandafter(1,1,True)\n",
    "\n",
    "landfalldata_pres_PHI_wmo, landfalldata_wind_PHI_wmo, landfalldata_coord_PHI_wmo, landfalldata_dist2land_PHI_wmo, landfalldata_indexlist_PHI_wmo = get_landfall_data_beforeandafter(0,2)\n",
    "landfalldata_pres_GD_wmo, landfalldata_wind_GD_wmo, landfalldata_coord_GD_wmo, landfalldata_dist2land_GD_wmo, landfalldata_indexlist_GD_wmo = get_landfall_data_beforeandafter(1,2)\n",
    "landfalldata_pres_PHI2014_wmo, landfalldata_wind_PHI2014_wmo, landfalldata_coord_PHI2014_wmo, landfalldata_dist2land_PHI2014_wmo, landfalldata_indexlist_PHI2014_wmo = get_landfall_data_beforeandafter(0,2,True)\n",
    "landfalldata_pres_GD2014_wmo, landfalldata_wind_GD2014_wmo, landfalldata_coord_GD2014_wmo, landfalldata_dist2land_GD2014_wmo, landfalldata_indexlist_GD2014_wmo = get_landfall_data_beforeandafter(1,2,True)\n",
    "\n",
    "landfalldata_pres_PHI_N_jtwc, landfalldata_wind_PHI_N_jtwc, landfalldata_coord_PHI_N_jtwc, landfalldata_dist2land_PHI_N_jtwc, landfalldata_indexlist_PHI_N_jtwc = get_landfall_data_beforeandafter(0,0,False,'N')\n",
    "landfalldata_pres_PHI_N2014_jtwc, landfalldata_wind_PHI_N2014_jtwc, landfalldata_coord_PHI_N2014_jtwc, landfalldata_dist2land_PHI_N2014_jtwc, landfalldata_indexlist_PHI_N2014_jtwc = get_landfall_data_beforeandafter(0,0,True,'N')\n",
    "landfalldata_pres_PHI_S_jtwc, landfalldata_wind_PHI_S_jtwc, landfalldata_coord_PHI_S_jtwc, landfalldata_dist2land_PHI_S_jtwc, landfalldata_indexlist_PHI_S_jtwc = get_landfall_data_beforeandafter(0,0,False,'S')\n",
    "landfalldata_pres_PHI_S2014_jtwc, landfalldata_wind_PHI_S2014_jtwc, landfalldata_coord_PHI_S2014_jtwc, landfalldata_dist2land_PHI_S2014_jtwc, landfalldata_indexlist_PHI_S2014_jtwc = get_landfall_data_beforeandafter(0,0,True,'S')\n",
    "\n",
    "landfalldata_pres_PHI_N_cma, landfalldata_wind_PHI_N_cma, landfalldata_coord_PHI_N_cma, landfalldata_dist2land_PHI_N_cma, landfalldata_indexlist_PHI_N_cma = get_landfall_data_beforeandafter(0,1,False,'N')\n",
    "landfalldata_pres_PHI_N2014_cma, landfalldata_wind_PHI_N2014_cma, landfalldata_coord_PHI_N2014_cma, landfalldata_dist2land_PHI_N2014_cma, landfalldata_indexlist_PHI_N2014_cma = get_landfall_data_beforeandafter(0,1,True,'N')\n",
    "landfalldata_pres_PHI_S_cma, landfalldata_wind_PHI_S_cma, landfalldata_coord_PHI_S_cma, landfalldata_dist2land_PHI_S_cma, landfalldata_indexlist_PHI_S_cma = get_landfall_data_beforeandafter(0,1,False,'S')\n",
    "landfalldata_pres_PHI_S2014_cma, landfalldata_wind_PHI_S2014_cma, landfalldata_coord_PHI_S2014_cma, landfalldata_dist2land_PHI_S2014_cma, landfalldata_indexlist_PHI_S2014_cma = get_landfall_data_beforeandafter(0,1,True,'S')\n",
    "\n",
    "landfalldata_pres_PHI_N_wmo, landfalldata_wind_PHI_N_wmo, landfalldata_coord_PHI_N_wmo, landfalldata_dist2land_PHI_N_wmo, landfalldata_indexlist_PHI_N_wmo = get_landfall_data_beforeandafter(0,2,False,'N')\n",
    "landfalldata_pres_PHI_N2014_wmo, landfalldata_wind_PHI_N2014_wmo, landfalldata_coord_PHI_N2014_wmo, landfalldata_dist2land_PHI_N2014_wmo, landfalldata_indexlist_PHI_N2014_wmo = get_landfall_data_beforeandafter(0,2,True,'N')\n",
    "landfalldata_pres_PHI_S_wmo, landfalldata_wind_PHI_S_wmo, landfalldata_coord_PHI_S_wmo, landfalldata_dist2land_PHI_S_wmo, landfalldata_indexlist_PHI_S_wmo = get_landfall_data_beforeandafter(0,2,False,'S')\n",
    "landfalldata_pres_PHI_S2014_wmo, landfalldata_wind_PHI_S2014_wmo, landfalldata_coord_PHI_S2014_wmo, landfalldata_dist2land_PHI_S2014_wmo, landfalldata_indexlist_PHI_S2014_wmo = get_landfall_data_beforeandafter(0,2,True,'S')\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Pressure deficit\n",
    "\n",
    "def pressure_deficit(area,source,separate_PHI = False, intersect = False):\n",
    "    #separate_PHI: 'N','S' or False\n",
    "    #intersect: 'True' if only using data of TCs appearing in all 3 agencies (to compare like to like events), 'False' otherwise\n",
    "    \n",
    "    pressure_dict = get_landfall_data_beforeandafter(area,source,False,separate_PHI)[0]\n",
    "    pres_def_before_list = []\n",
    "    pres_def_after_list = []\n",
    "    \n",
    "    if intersect == True:\n",
    "        key_a = list(get_landfall_data_beforeandafter(area,0,False,separate_PHI)[0].keys())\n",
    "        key_b = list(get_landfall_data_beforeandafter(area,1,False,separate_PHI)[0].keys())\n",
    "        key_c = list(get_landfall_data_beforeandafter(area,2,False,separate_PHI)[0].keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a,key_b),key_c) #Intersected list of TCs\n",
    "    else:\n",
    "        key_intersect_list = list(pressure_dict.keys())\n",
    "    \n",
    "    for key in key_intersect_list:\n",
    "        if len(pressure_dict[key]) == 1: \n",
    "            pres_def_after = 1010 - pressure_dict[key][0]\n",
    "            pres_def_after_list.append(pres_def_after)\n",
    "        else: \n",
    "            pres_def_before = 1010 - pressure_dict[key][0]\n",
    "            pres_def_after = 1010 - pressure_dict[key][1]\n",
    "            pres_def_before_list.append(pres_def_before)\n",
    "            pres_def_after_list.append(pres_def_after)\n",
    "    return pres_def_before_list, pres_def_after_list #pressure_deficit(area)[0] for the first list and pressure_deficit(area)[1] for the second list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating probability of pressure deficit with log-normal fit\n",
    "def presdef_probability(area, source, binsize, separate_PHI=False, intersect = False):\n",
    "    #binsize: range of data grouped into a single data point\n",
    "    x_range = list(range(0,101,binsize))\n",
    "    before_list, after_list = pressure_deficit(area, source, separate_PHI, intersect)\n",
    "    #this returns all the pres deficits for the typhoons just before reaching lands (-1 typhoon), and just reach the lands (0 typhoon)\n",
    "\n",
    "    prob_before = [] #Distribution before landfall\n",
    "    prob_after = [] #Distribution after landfall\n",
    "    for i in range(len(x_range)-1) : \n",
    "        count_before = 0 \n",
    "        count_after = 0\n",
    "        for j in range(len(after_list)):\n",
    "            if i < len(x_range)-1 and x_range[i+1] > after_list[j] >= x_range[i]: # to make sure that it only includes one range each time but not more than one\n",
    "                count_after = count_after + 1 \n",
    "        for j in range(len(before_list)):\n",
    "            if i < len(x_range)-1 and x_range[i+1] > before_list[j] >= x_range[i]:\n",
    "                count_before = count_before + 1 \n",
    "        prob_before.append((count_before/len(before_list))/(100/len(x_range)))\n",
    "        prob_after.append((count_after/len(after_list))/(100/len(x_range)))\n",
    "    \n",
    "    prob_before = np.asarray(prob_before)\n",
    "    prob_after = np.asarray(prob_after)\n",
    "    \n",
    "    #Plot figure for before landfall\n",
    "    plt.figure()\n",
    "    plt.xlabel('Pressure deficit (hPa)')\n",
    "    plt.ylabel('Probability')\n",
    "    x_axis = list(np.arange(binsize/2,101,binsize))\n",
    "    plt.scatter(x_axis, prob_before,color = 'k')\n",
    "    s, loc, scale = lognorm.fit(before_list, loc=0) #Fit log-normal\n",
    "    mu, var, skew = lognorm.stats(s, loc, scale, moments='mvs') #Get log-normal statistics\n",
    "    std = np.sqrt(var)\n",
    "    x = np.arange(0, 101, 1)\n",
    "    p = lognorm.pdf(x, s, loc, scale)\n",
    "    p = np.asarray(p)\n",
    "    zeroindexlist = np.where(p == 0)\n",
    "    p[zeroindexlist] = 1e-80 #Make zero to a very small number for chi-square test\n",
    "    \n",
    "    x_at_datapt_index = [i for i in range(len(x)) if x[i] in x_axis] #Find index in x where there is a data point in x_axis\n",
    "    p_mse = p[x_at_datapt_index]\n",
    "    p_chisq = p[x_at_datapt_index]\n",
    "    chisq, pvalue = chisquare(prob_before*100/len(x_range)*len(before_list),p_chisq*100/len(x_range)*len(before_list), ddof=2) #Chi-sq test\n",
    "#    print(str(source), chisq, pvalue)\n",
    "    rmserr = np.sqrt(mean_squared_error(prob_before, p_mse))\n",
    "\n",
    "    samplesize = len(before_list)\n",
    "    \n",
    "    plt.plot(x, p, 'b-')\n",
    "    \n",
    "    #Plot title\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Northern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Southern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 1:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Northern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Southern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 2: \n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Northern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in the Southern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "    else: \n",
    "        if source == 0:\n",
    "            plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in Guangdong \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in Guangdong \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Probability distribution of central pressure deficit of typhoons before their landfalls in Guangdong \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "    plt.xlim([0,100])\n",
    "    plt.ylim([0,0.05])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Plot figure for after landfall\n",
    "    plt.figure()\n",
    "    plt.xlabel('Pressure deficit (hPa)')\n",
    "    plt.ylabel('Probability')\n",
    "    x_axis = list(np.arange(binsize/2,101,binsize))\n",
    "    plt.scatter(x_axis, prob_after,color = 'k')\n",
    "    s, loc, scale = lognorm.fit(after_list, loc=0)\n",
    "    mu, var, skew = lognorm.stats(s, loc, scale, moments='mvs')\n",
    "    std = np.sqrt(var)\n",
    "    \n",
    "    x = np.arange(0, 101, 1)\n",
    "    p = lognorm.pdf(x, s, loc, scale)\n",
    "    p = np.asarray(p)\n",
    "    zeroindexlist = np.where(p == 0)\n",
    "    p[zeroindexlist] = 1e-80 #Make zero to a very small number for chi-square test\n",
    "    \n",
    "    x_at_datapt_index = [i for i in range(len(x)) if x[i] in x_axis] #Find index in x where there is a data point in x_axis\n",
    "    p_mse = p[x_at_datapt_index]\n",
    "    p_chisq = p[x_at_datapt_index]#*(100/len(x_range))\n",
    "    chisq, pvalue = chisquare(prob_after*100/len(x_range)*len(after_list),p_chisq*100/len(x_range)*len(after_list), ddof=2)\n",
    "#    print(str(source), chisq, pvalue)\n",
    "\n",
    "    rmserr = np.sqrt(mean_squared_error(prob_after, p_mse))\n",
    "\n",
    "    samplesize = len(after_list)\n",
    "    plt.plot(x, p, 'b-')\n",
    "\n",
    "#     print(prob_after*100/len(x_range)*len(after_list))\n",
    "#     print(p_chisq*100/len(x_range)*len(after_list))\n",
    "    \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Northern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Southern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 1:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Northern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Southern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 2:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Northern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in the Southern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "    \n",
    "    else: \n",
    "        if source == 0:\n",
    "            plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in Guangdong \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in Guangdong \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "        elif source == 2: \n",
    "            plt.title('Probability distribution of central pressure deficit of typhoons at their landfalls in Guangdong \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ' , RMS error = ' + str(rmserr),fontsize='small')\n",
    "    plt.xlim([0,100])\n",
    "    plt.ylim([0,0.05])\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    return prob_before, prob_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# presdef_probability(area=0,source=0,binsize=10)\n",
    "# presdef_probability(0,1,10)\n",
    "# presdef_probability(0,2,10)\n",
    "# presdef_probability(1,0,10, False,False)\n",
    "# presdef_probability(1,1,10, False,False)\n",
    "# presdef_probability(1,2,10, False,False)\n",
    "# presdef_probability(0,0,10,'N')\n",
    "# presdef_probability(0,0,10,'S')\n",
    "# presdef_probability(0,1,10,'N')\n",
    "# presdef_probability(0,1,10,'S')\n",
    "#presdef_probability(0,2,10,'N')\n",
    "#presdef_probability(0,2,10,'S')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "'''\n",
    "calculating probability of max wind speed with log-normal fit\n",
    "'''\n",
    "def wind_speed(area, source, separate_PHI=False, intersect = False, pd_wind_int = False):\n",
    "    #pd_wind_int: 'True' if same TCs for plotting pd prob (in above) and wind prob, 'False' otherwise\n",
    "    windspeed_dict = get_landfall_data_beforeandafter(area, source, False,separate_PHI)[1]\n",
    "    windspeed_before_list = []\n",
    "    windspeed_after_list = []\n",
    "    \n",
    "    if pd_wind_int == True:\n",
    "        pressure_dict = get_landfall_data_beforeandafter(area, source, False,separate_PHI)[0]\n",
    "        key_a = list(pressure_dict.keys())\n",
    "        key_b = list(windspeed_dict.keys())\n",
    "        key_intersect_list = np.intersect1d(key_a,key_b)\n",
    "    \n",
    "    elif intersect == True:\n",
    "        key_a = list(get_landfall_data_beforeandafter(area,0,False,separate_PHI)[1].keys())\n",
    "        key_b = list(get_landfall_data_beforeandafter(area,1,False,separate_PHI)[1].keys())\n",
    "        key_c = list(get_landfall_data_beforeandafter(area,2,False,separate_PHI)[1].keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a,key_b),key_c)\n",
    "    else:\n",
    "        key_intersect_list = list(windspeed_dict.keys())\n",
    "        \n",
    "    \n",
    "    for key in key_intersect_list:\n",
    "        if len(windspeed_dict[key]) == 1: \n",
    "            windspeed_after_list. append(windspeed_dict[key][0])\n",
    "        else: \n",
    "            windspeed_before_list.append(windspeed_dict[key][0])\n",
    "            windspeed_after_list.append(windspeed_dict[key][1])\n",
    "\n",
    "    return windspeed_before_list, windspeed_after_list #before landfall, after landfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "'''\n",
    "calculating probability of max wind speed \n",
    "'''\n",
    "def wind_probability(area, source, separate_PHI = False, fitnorm = False, intersect = False, pd_wind_int = False):\n",
    "    #fitnorm: 'True' if fitting normal function, 'False' if fitting log-normal\n",
    "    x_range = list(range(0,131,10))\n",
    "    b, a = wind_speed(area, source, separate_PHI, intersect, pd_wind_int)\n",
    "    b = [i for i in b if i != 0] #Remove 0 values as they are actually missing data\n",
    "    a = [j for j in a if j != 0]\n",
    "    before_list = [int(i) for i in b]\n",
    "    after_list = [int(j) for j in a]\n",
    "    \n",
    "\n",
    "    \n",
    "    prob_before = []\n",
    "    prob_after = []\n",
    "    for i in range(len(x_range)-1) : \n",
    "        count_before = 0 \n",
    "        count_after = 0\n",
    "        for j in range(len(after_list)):\n",
    "            if i < len(x_range)-1 and x_range[i+1] > after_list[j] >= x_range[i]: # to make sure that it only includes one range each time but not more than one\n",
    "                count_after = count_after + 1 \n",
    "        for j in range(len(before_list)):\n",
    "            if i < len(x_range)-1 and x_range[i+1] > before_list[j] >= x_range[i]:\n",
    "                count_before = count_before + 1 \n",
    "        prob_before.append((count_before/len(before_list))/(130/len(x_range)))\n",
    "        prob_after.append((count_after/len(after_list))/(130/len(x_range)))\n",
    "        \n",
    "    prob_before = np.asarray(prob_before)\n",
    "    prob_after = np.asarray(prob_after)\n",
    "        \n",
    "    #Plot before landfall\n",
    "    plt.figure()\n",
    "    plt.xlabel('Maximum Wind Speed (kt)')\n",
    "    plt.ylabel('Probability') \n",
    "    plt.ylim(0,0.06)\n",
    "    x_axis = list(np.arange(5,130,10))\n",
    "    plt.scatter(x_axis, prob_before,color = 'k')\n",
    "\n",
    "    x = np.arange(0, 131, 1)\n",
    "    \n",
    "    if fitnorm == True:\n",
    "        mu, std = norm.fit(after_list)\n",
    "        p = norm.pdf(x, mu,std)\n",
    "        skew = 0\n",
    "    else:\n",
    "        s, loc, scale = lognorm.fit(before_list, loc = 0)\n",
    "        mu, var, skew = lognorm.stats(s, loc, scale, moments='mvs')\n",
    "        std = np.sqrt(var)\n",
    "        p = lognorm.pdf(x, s, loc, scale)\n",
    "    p = np.asarray(p)\n",
    "    zeroindexlist = np.where(p == 0)\n",
    "    p[zeroindexlist] = 1e-80 #Make zero to a very small number for chi-square test\n",
    "    \n",
    "    x_at_datapt_index = [i for i in range(len(x)) if x[i] in x_axis] #Find index in x where there is a data point in x_axis\n",
    "    p_mse = p[x_at_datapt_index]\n",
    "    chisq, pvalue = chisquare(prob_before*130/len(x_range)*len(before_list), p_mse*130/len(x_range)*len(before_list), ddof=2) #Perform chi-sq test\n",
    "#    print(str(source), chisq, pvalue)\n",
    "\n",
    "    rmserr = np.sqrt(mean_squared_error(prob_before, p_mse))\n",
    "    \n",
    "    samplesize = len(before_list)\n",
    "    plt.plot(x, p,'b-')\n",
    "    \n",
    "    #Plot title\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Northern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Southern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 1:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Northern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Southern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 2:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Northern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Southern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "    \n",
    "    else: \n",
    "        if source == 0:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons before their landfalls in Guangdong \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons before their landfalls in Guangdong \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons before their landfalls in Guangdong \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Plot after landfall\n",
    "    plt.figure()\n",
    "    plt.xlabel('Maximum Wind Speed (kt)')  \n",
    "    plt.ylabel('Probability') \n",
    "    plt.ylim(0,0.06)\n",
    "    x_axis = list(np.arange(5,130,10))\n",
    "    plt.scatter(x_axis, prob_after,color = 'r')\n",
    "    \n",
    "    x = np.arange(0, 131, 1)\n",
    "    if fitnorm == True:\n",
    "        mu, std = norm.fit(after_list)\n",
    "        p = norm.pdf(x, mu,std)\n",
    "        skew = 0\n",
    "    else:\n",
    "        s, loc, scale = lognorm.fit(after_list, loc = 0)\n",
    "        mu, var, skew = lognorm.stats(s, loc, scale, moments='mvs')\n",
    "        std = np.sqrt(var)\n",
    "        p = lognorm.pdf(x, s, loc, scale)\n",
    "    p = np.asarray(p)\n",
    "    zeroindexlist = np.where(p == 0)\n",
    "    p[zeroindexlist] = 1e-80 #Make zero to a very small number for chi-square test\n",
    "    \n",
    "    x_at_datapt_index = [i for i in range(len(x)) if x[i] in x_axis] #Find index in x where there is a data point in x_axis\n",
    "    p_mse = p[x_at_datapt_index]\n",
    "    chisq, pvalue = chisquare(prob_after*130/len(x_range)*len(after_list), p_mse*130/len(x_range)*len(after_list), ddof=2)\n",
    "#    print(str(source), chisq, pvalue)\n",
    "\n",
    "    rmserr = np.sqrt(mean_squared_error(prob_after, p_mse))\n",
    "\n",
    "    samplesize = len(after_list)\n",
    "    plt.plot(x, p, 'b-')\n",
    "    \n",
    "    print(prob_after*130/len(x_range)*len(after_list))\n",
    "    print(p_mse*130/len(x_range)*len(after_list))\n",
    "\n",
    "    \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Northern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Southern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "        elif source == 1:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Northern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Southern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "        elif source == 2: \n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Northern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Southern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "    else: \n",
    "        if source == 0:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons at their landfalls in Guangdong \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons at their landfalls in Guangdong \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons at their landfalls in Guangdong \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "    plt.show()\n",
    "    \n",
    "    return prob_before, prob_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# wind_probability(0,0,False)\n",
    "# wind_probability(0,1,False)\n",
    "# wind_probability(0,2,False)\n",
    "# wind_probability(1,0,False,False,False,True)\n",
    "# wind_probability(1,0,False,False,False,False)\n",
    "# wind_probability(1,1,False,False,False,True)\n",
    "# wind_probability(1,2,False,False,False,True)\n",
    "# wind_probability(0, 0,'N')\n",
    "# wind_probability(0, 1,'N')\n",
    "# wind_probability(0, 2,'N')\n",
    "# wind_probability(0, 0,'S')\n",
    "# wind_probability(0, 1,'S')\n",
    "# wind_probability(0, 2,'S')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise TC coordinates\n",
    "#Plots the coastline and the landfall TC coordinates of whole area\n",
    "def plot_points(area, source, after2014 = False, PHI_NS = False): \n",
    "    if area == 0: #PHI\n",
    "        landcoord = z_land_coord_PHI\n",
    "        if source == 0:\n",
    "            if after2014 == True:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI2014_jtwc #List of coordinates of TC centre\n",
    "                    keys = landfalldata_coord_PHI2014_jtwc.keys() #Keys of dict (TC indexes)\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N2014_jtwc\n",
    "                    keys = landfalldata_coord_PHI_N2014_jtwc.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S2014_jtwc\n",
    "                    keys = landfalldata_coord_PHI_S2014_jtwc.keys()\n",
    "            elif after2014 == False:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI_jtwc\n",
    "                    keys = landfalldata_coord_PHI_jtwc.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N_jtwc\n",
    "                    keys = landfalldata_coord_PHI_N_jtwc.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S_jtwc\n",
    "                    keys = landfalldata_coord_PHI_S_jtwc.keys()\n",
    "                    \n",
    "        elif source == 1:\n",
    "            if after2014 == True:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI2014_cma\n",
    "                    keys = landfalldata_coord_PHI2014_cma.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N2014_cma\n",
    "                    keys = landfalldata_coord_PHI_N2014_cma.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S2014_cma\n",
    "                    keys = landfalldata_coord_PHI_S2014_cma.keys()\n",
    "            elif after2014 == False:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI_cma\n",
    "                    keys = landfalldata_coord_PHI_cma.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N_cma\n",
    "                    keys = landfalldata_coord_PHI_N_cma.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S_cma\n",
    "                    keys = landfalldata_coord_PHI_S_cma.keys()\n",
    "        elif source == 2:\n",
    "            if after2014 == True:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI2014_wmo\n",
    "                    keys = landfalldata_coord_PHI2014_wmo.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N2014_wmo\n",
    "                    keys = landfalldata_coord_PHI_N2014_wmo.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S2014_wmo\n",
    "                    keys = landfalldata_coord_PHI_S2014_wmo.keys()\n",
    "            elif after2014 == False:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI_wmo\n",
    "                    keys = landfalldata_coord_PHI_wmo.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N_wmo\n",
    "                    keys = landfalldata_coord_PHI_N_wmo.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S_wmo\n",
    "                    keys = landfalldata_coord_PHI_S_wmo.keys()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    elif area == 1: #GD\n",
    "        landcoord = z_land_coord_GD\n",
    "        if source == 0:\n",
    "            if after2014 == True:\n",
    "                coordlist = landfalldata_coord_GD2014_jtwc\n",
    "                keys = landfalldata_coord_GD2014_jtwc.keys()\n",
    "            elif after2014 == False:\n",
    "                coordlist = landfalldata_coord_GD_jtwc\n",
    "                keys = landfalldata_coord_GD_jtwc.keys()\n",
    "        elif source == 1:\n",
    "            if after2014 == True:\n",
    "                coordlist = landfalldata_coord_GD2014_cma\n",
    "                keys = landfalldata_coord_GD2014_cma.keys()\n",
    "            elif after2014 == False:\n",
    "                coordlist = landfalldata_coord_GD_cma\n",
    "                keys = landfalldata_coord_GD_cma.keys()\n",
    "        elif source == 2:\n",
    "            if after2014 == True:\n",
    "                coordlist = landfalldata_coord_GD2014_wmo\n",
    "                keys = landfalldata_coord_GD2014_wmo.keys()\n",
    "            elif after2014 == False:\n",
    "                coordlist = landfalldata_coord_GD_wmo\n",
    "                keys = landfalldata_coord_GD_wmo.keys()    \n",
    "    color = iter(cm.rainbow(np.linspace(0,1,len(keys))))\n",
    "    plt.figure()  \n",
    "    if area == 0: \n",
    "        if source == 0:\n",
    "            if PHI_NS == False:\n",
    "                plt.title('Tracks of typhoons with landfall in the Philippines, source: JTWC') \n",
    "            elif PHI_NS == 'N':\n",
    "                plt.title('Tracks of typhoons with landfall in the Northern Philippines, source: JTWC') \n",
    "            elif PHI_NS == 'S':\n",
    "                plt.title('Tracks of typhoons with landfall in the Southern Philippines, source: JTWC')\n",
    "        elif source == 1:\n",
    "            if PHI_NS == False:\n",
    "                plt.title('Tracks of typhoons with landfall in the Philippines, source: CMA') \n",
    "            elif PHI_NS == 'N':\n",
    "                plt.title('Tracks of typhoons with landfall in the Northern Philippines, source: CMA') \n",
    "            elif PHI_NS == 'S':\n",
    "                plt.title('Tracks of typhoons with landfall in the Southern Philippines, source: CMA')\n",
    "        elif source == 2:\n",
    "            if PHI_NS == False:\n",
    "                plt.title('Tracks of typhoons with landfall in the Philippines, source: WMO') \n",
    "            elif PHI_NS == 'N':\n",
    "                plt.title('Tracks of typhoons with landfall in the Northern Philippines, source: WMO') \n",
    "            elif PHI_NS == 'S':\n",
    "                plt.title('Tracks of typhoons with landfall in the Southern Philippines, source: WMO')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Tracks of typhoons with landfall in Guangdong, source: JTWC')\n",
    "        elif source == 1:\n",
    "            plt.title('Tracks of typhoons with landfall in Guangdong, source: CMA')\n",
    "        elif source == 2:   \n",
    "            plt.title('Tracks of typhoons with landfall in Guangdong, source: WMO')\n",
    "    plt.xlabel('Longitude (E)') \n",
    "    plt.ylabel('Latitude (N)')\n",
    "    plt.scatter(landcoord[:,0],landcoord[:,1],color = 'k', s=5)\n",
    "    if after2014 == True:\n",
    "        size = 20\n",
    "    else:\n",
    "        size = 5\n",
    "    for index in list(keys):\n",
    "        c=next(color)\n",
    "        plt.scatter(coordlist[index][:,1],coordlist[index][:,0],color = c,s=size, label = index)\n",
    "    if after2014 == False:\n",
    "        plt.legend(fontsize=4)\n",
    "    else:\n",
    "        plt.legend(fontsize='x-small')\n",
    "    plt.axis('equal')\n",
    "\n",
    "\n",
    "#Plots the coastline and the landfall TC coordinates of individual TC\n",
    "def plot_points_landfall_indiv(source, tcindex):\n",
    "    plt.figure()\n",
    "    plt.title(str(tcindex))\n",
    "    if source == 0:\n",
    "        coorddictPHI = landfalldata_coord_PHI_jtwc\n",
    "        coorddictGD = landfalldata_coord_GD_jtwc\n",
    "    else:\n",
    "        coorddictPHI = landfalldata_coord_PHI_cma\n",
    "        coorddictGD = landfalldata_coord_GD_cma\n",
    "    if str(tcindex) in landfalldata_coord_PHI:\n",
    "        plt.scatter(z_land_coord_PHI[:,0],z_land_coord_PHI[:,1],color = 'k')\n",
    "        plt.scatter(coorddictPHI[str(tcindex)][:,1],coorddictPHI[str(tcindex)][:,0], color = 'r')\n",
    "    if str(tcindex) in landfalldata_coord_GD:\n",
    "        plt.scatter(z_land_coord_GD[:,0],z_land_coord_GD[:,1],color = 'k')\n",
    "        plt.scatter(coorddictGD[str(tcindex)][:,1],coorddictGD[str(tcindex)][:,0], color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_points(0, 0, True, False)\n",
    "plot_points(0, 1, True, False)\n",
    "plot_points(0, 2, True, False)\n",
    "plot_points(0, 0, True, 'N')\n",
    "plot_points(0, 1, True, 'N')\n",
    "plot_points(0, 0, True, 'S')\n",
    "plot_points(0, 1, True, 'S')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_points(0, 0, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_points(1, 1, True)\n",
    "#plot_points(1, 1, True)\n",
    "#plot_points(1, 0, False)\n",
    "#plot_points(1, 1, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "'''\n",
    "extract dates of typhoon for rainfall data\n",
    "'''\n",
    "\n",
    "time_units = ibt.variables['source_time'].getncattr('units')\n",
    "\n",
    "#Change dates of TCs to common understandable format\n",
    "def getdates(tcindex): \n",
    "    datelist = list(num2date(time_record,time_units)[tcindex])\n",
    "\n",
    "    return datelist #returns a list in (year, month, day, hour, minute, second) format\n",
    "\n",
    "#Get dates of TCs at landfall\n",
    "def getdates_landfall(area, after2014 = False):\n",
    "    landfall_dates = {}\n",
    "    if after2014 == True:\n",
    "        indexlist = get_landfall_data_beforeandafter(area, True)[4]\n",
    "    else:\n",
    "        indexlist = get_landfall_data_beforeandafter(area, False)[4]\n",
    "        \n",
    "    for key in indexlist.keys():\n",
    "        print(key)\n",
    "        landfall_dates[key] = list(num2date(time_record,time_units)[int(key), indexlist[key]])\n",
    "    return landfall_dates\n",
    "\n",
    "#WARNING: Extremely long runtime, dates are pasted in cell below so code does not have to be rerun again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tic = time.time()\n",
    "#landfallTC_dates_GD_2014 = getdates_landfall(1, after2014 = True)\n",
    "landfallTC_dates_GD = getdates_landfall(1, after2014 = False)\n",
    "print(landfallTC_dates_GD)\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "\n",
    "'''For GD:\n",
    "{'12594': [datetime.datetime(2014, 6, 15, 6, 0), datetime.datetime(2014, 6, 15, 12, 0)],\n",
    " '12600': [datetime.datetime(2014, 7, 18, 6, 0), datetime.datetime(2014, 7, 18, 12, 0)], \n",
    " '12621': [datetime.datetime(2014, 9, 8, 0, 0), datetime.datetime(2014, 9, 8, 6, 0)], \n",
    " '12624': [datetime.datetime(2014, 9, 16, 0, 0), datetime.datetime(2014, 9, 16, 6, 0)], \n",
    " '12688': [datetime.datetime(2015, 7, 9, 0, 0), datetime.datetime(2015, 7, 9, 6, 0)], \n",
    " '12733': [datetime.datetime(2015, 10, 4, 0, 0), datetime.datetime(2015, 10, 4, 6, 0)], \n",
    " '12776': [datetime.datetime(2016, 5, 27, 6, 0), datetime.datetime(2016, 5, 27, 12, 0)], \n",
    " '12793': [datetime.datetime(2016, 8, 1, 18, 0), datetime.datetime(2016, 8, 2, 0, 0)], \n",
    " '12837': [datetime.datetime(2016, 10, 21, 0, 0), datetime.datetime(2016, 10, 21, 6, 0)]\n",
    " '12861': [datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 23, 6, 0)\n",
    " '12862': [datetime.datetime(2018, 9, 16, 6, 0), datetime.datetime(2016, 9, 16, 12, 0)}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''For GD: {\n",
    "'4872': [datetime.datetime(1945, 7, 7, 12, 0), datetime.datetime(1945, 7, 7, 18, 0)], \n",
    "'4968': [datetime.datetime(1946, 7, 18, 12, 0), datetime.datetime(1946, 7, 18, 18, 0)], \n",
    "'4981': [datetime.datetime(1946, 9, 12, 6, 0), datetime.datetime(1946, 9, 12, 12, 0)], \n",
    "'5066': [datetime.datetime(1947, 8, 13, 0, 0), datetime.datetime(1947, 8, 13, 6, 0)], \n",
    "'5087': [datetime.datetime(1947, 10, 7, 6, 0), datetime.datetime(1947, 10, 7, 12, 0)], \n",
    "'5156': [datetime.datetime(1948, 6, 10, 6, 0), datetime.datetime(1948, 6, 10, 12, 0)], \n",
    "'5164': [datetime.datetime(1948, 7, 27, 6, 0), datetime.datetime(1948, 7, 27, 12, 0)], \n",
    "'5173': [datetime.datetime(1948, 9, 3, 0, 0), datetime.datetime(1948, 9, 3, 6, 0)], \n",
    "'5183': [datetime.datetime(1948, 9, 26, 18, 0), datetime.datetime(1948, 9, 27, 0, 0)], \n",
    "'5252': [datetime.datetime(1949, 7, 10, 6, 0), datetime.datetime(1949, 7, 10, 12, 0)], \n",
    "'5275': [datetime.datetime(1949, 9, 8, 0, 0), datetime.datetime(1949, 9, 8, 6, 0)], \n",
    "'5285': [datetime.datetime(1949, 9, 14, 18, 0), datetime.datetime(1949, 9, 15, 0, 0)], \n",
    "'5504': [datetime.datetime(1951, 9, 22, 0, 0), datetime.datetime(1951, 9, 22, 6, 0)], \n",
    "'5563': [datetime.datetime(1952, 6, 13, 12, 0), datetime.datetime(1952, 6, 13, 18, 0)], \n",
    "'5596': [datetime.datetime(1952, 9, 13, 6, 0), datetime.datetime(1952, 9, 13, 12, 0)], \n",
    "'5684': [datetime.datetime(1953, 9, 1, 12, 0), datetime.datetime(1953, 9, 1, 18, 0)], \n",
    "'5693': [datetime.datetime(1953, 9, 19, 6, 0), datetime.datetime(1953, 9, 19, 12, 0)], \n",
    "'5769': [datetime.datetime(1954, 8, 29, 12, 0), datetime.datetime(1954, 8, 29, 18, 0)], \n",
    "'5852': [datetime.datetime(1955, 6, 5, 12, 0), datetime.datetime(1955, 6, 5, 18, 0)], \n",
    "'6078': [datetime.datetime(1957, 7, 16, 6, 0), datetime.datetime(1957, 7, 16, 12, 0)], \n",
    "'6085': [datetime.datetime(1957, 8, 20, 12, 0), datetime.datetime(1957, 8, 20, 18, 0)], \n",
    "'6111': [datetime.datetime(1957, 10, 15, 6, 0), datetime.datetime(1957, 10, 15, 12, 0)], \n",
    "'6287': [datetime.datetime(1959, 7, 5, 18, 0), datetime.datetime(1959, 7, 6, 0, 0)], \n",
    "'6318': [datetime.datetime(1959, 9, 10, 18, 0), datetime.datetime(1959, 9, 11, 0, 0)], \n",
    "'6382': [datetime.datetime(1960, 6, 8, 18, 0), datetime.datetime(1960, 6, 9, 0, 0)], \n",
    "'6385': [datetime.datetime(1960, 6, 29, 18, 0), datetime.datetime(1960, 6, 30, 0, 0)], \n",
    "'6399': [datetime.datetime(1960, 8, 9, 0, 0), datetime.datetime(1960, 8, 9, 6, 0)], \n",
    "'6413': [datetime.datetime(1960, 8, 25, 0, 0), datetime.datetime(1960, 8, 25, 6, 0)], \n",
    "'6492': [datetime.datetime(1961, 5, 19, 0, 0), datetime.datetime(1961, 5, 19, 6, 0)], \n",
    "'6504': [datetime.datetime(1961, 7, 1, 18, 0), datetime.datetime(1961, 7, 2, 0, 0)], \n",
    "'6513': [datetime.datetime(1961, 7, 14, 18, 0), datetime.datetime(1961, 7, 15, 0, 0)], \n",
    "'6515': [datetime.datetime(1961, 7, 19, 6, 0), datetime.datetime(1961, 7, 19, 12, 0)], \n",
    "'6542': [datetime.datetime(1961, 9, 9, 12, 0), datetime.datetime(1961, 9, 9, 18, 0)], \n",
    "'6552': [datetime.datetime(1961, 9, 29, 0, 0), datetime.datetime(1961, 9, 29, 6, 0)], \n",
    "'6640': [datetime.datetime(1962, 8, 10, 12, 0), datetime.datetime(1962, 8, 10, 18, 0)], \n",
    "'6648': [datetime.datetime(1962, 9, 1, 6, 0), datetime.datetime(1962, 9, 1, 12, 0)], \n",
    "'6666': [datetime.datetime(1962, 10, 3, 12, 0), datetime.datetime(1962, 10, 3, 18, 0)], \n",
    "'6748': [datetime.datetime(1963, 6, 30, 18, 0), datetime.datetime(1963, 7, 1, 0, 0)], \n",
    "'6757': [datetime.datetime(1963, 7, 22, 12, 0), datetime.datetime(1963, 7, 22, 18, 0)], \n",
    "'6854': [datetime.datetime(1964, 5, 28, 0, 0), datetime.datetime(1964, 5, 28, 6, 0)], \n",
    "'6872': [datetime.datetime(1964, 8, 8, 12, 0), datetime.datetime(1964, 8, 8, 18, 0)], \n",
    "'6892': [datetime.datetime(1964, 9, 5, 6, 0), datetime.datetime(1964, 9, 5, 12, 0)], \n",
    "'6911': [datetime.datetime(1964, 10, 12, 18, 0), datetime.datetime(1964, 10, 13, 0, 0)], \n",
    "'6988': [datetime.datetime(1965, 6, 4, 6, 0), datetime.datetime(1965, 6, 4, 12, 0)], \n",
    "'7003': [datetime.datetime(1965, 7, 23, 0, 0), datetime.datetime(1965, 7, 23, 6, 0)], \n",
    "'7030': [datetime.datetime(1965, 9, 5, 6, 0), datetime.datetime(1965, 9, 5, 12, 0)], \n",
    "'7044': [datetime.datetime(1965, 9, 27, 12, 0), datetime.datetime(1965, 9, 27, 18, 0)], \n",
    "'7104': [datetime.datetime(1966, 7, 13, 12, 0), datetime.datetime(1966, 7, 13, 18, 0)], \n",
    "'7105': [datetime.datetime(1966, 7, 17, 12, 0), datetime.datetime(1966, 7, 17, 18, 0)], \n",
    "'7112': [datetime.datetime(1966, 7, 26, 0, 0), datetime.datetime(1966, 7, 26, 6, 0)], \n",
    "'7128': [datetime.datetime(1966, 9, 3, 18, 0), datetime.datetime(1966, 9, 4, 0, 0)], \n",
    "'7233': [datetime.datetime(1967, 6, 30, 0, 0), datetime.datetime(1967, 6, 30, 6, 0)], \n",
    "'7259': [datetime.datetime(1967, 8, 16, 6, 0), datetime.datetime(1967, 8, 16, 12, 0)], \n",
    "'7264': [datetime.datetime(1967, 8, 21, 6, 0), datetime.datetime(1967, 8, 21, 12, 0)], \n",
    "'7321': [datetime.datetime(1967, 11, 7, 18, 0), datetime.datetime(1967, 11, 8, 0, 0)], \n",
    "'7405': [datetime.datetime(1968, 8, 21, 12, 0), datetime.datetime(1968, 8, 21, 18, 0)], \n",
    "'7418': [datetime.datetime(1968, 9, 8, 12, 0), datetime.datetime(1968, 9, 8, 18, 0)], \n",
    "'7433': [datetime.datetime(1968, 10, 1, 0, 0), datetime.datetime(1968, 10, 1, 6, 0)], \n",
    "'7513': [datetime.datetime(1969, 7, 28, 0, 0), datetime.datetime(1969, 7, 28, 6, 0)], \n",
    "'7643': [datetime.datetime(1970, 7, 16, 0, 0), datetime.datetime(1970, 7, 16, 6, 0)], \n",
    "'7662': [datetime.datetime(1970, 8, 9, 0, 0), datetime.datetime(1970, 8, 9, 6, 0)], \n",
    "'7691': [datetime.datetime(1970, 9, 13, 18, 0), datetime.datetime(1970, 9, 14, 0, 0)], \n",
    "'7712': [datetime.datetime(1970, 10, 17, 6, 0), datetime.datetime(1970, 10, 17, 12, 0)], \n",
    "'7775': [datetime.datetime(1971, 5, 3, 18, 0), datetime.datetime(1971, 5, 4, 0, 0)], \n",
    "'7791': [datetime.datetime(1971, 6, 27, 18, 0), datetime.datetime(1971, 6, 28, 0, 0)], \n",
    "'7802': [datetime.datetime(1971, 7, 22, 0, 0), datetime.datetime(1971, 7, 22, 6, 0)], \n",
    "'7816': [datetime.datetime(1971, 8, 16, 18, 0), datetime.datetime(1971, 8, 17, 0, 0)], \n",
    "'7930': [datetime.datetime(1972, 6, 5, 6, 0), datetime.datetime(1972, 6, 5, 12, 0)], \n",
    "'7935': [datetime.datetime(1972, 6, 27, 0, 0), datetime.datetime(1972, 6, 27, 6, 0)], \n",
    "'8003': [datetime.datetime(1972, 11, 8, 6, 0), datetime.datetime(1972, 11, 8, 12, 0)], \n",
    "'8083': [datetime.datetime(1973, 7, 17, 0, 0), datetime.datetime(1973, 7, 17, 6, 0)], \n",
    "'8095': [datetime.datetime(1973, 8, 12, 6, 0), datetime.datetime(1973, 8, 12, 12, 0)], \n",
    "'8101': [datetime.datetime(1973, 8, 21, 12, 0), datetime.datetime(1973, 8, 21, 18, 0)], \n",
    "'8109': [datetime.datetime(1973, 9, 6, 6, 0), datetime.datetime(1973, 9, 6, 12, 0)], \n",
    "'8196': [datetime.datetime(1974, 6, 8, 0, 0), datetime.datetime(1974, 6, 8, 6, 0)], \n",
    "'8213': [datetime.datetime(1974, 7, 22, 6, 0), datetime.datetime(1974, 7, 22, 12, 0)], \n",
    "'8250': [datetime.datetime(1974, 9, 6, 6, 0), datetime.datetime(1974, 9, 6, 12, 0)], \n",
    "'8284': [datetime.datetime(1974, 12, 2, 0, 0), datetime.datetime(1974, 12, 2, 6, 0)], \n",
    "'8390': [datetime.datetime(1975, 9, 23, 6, 0), datetime.datetime(1975, 9, 23, 12, 0)], \n",
    "'8399': [datetime.datetime(1975, 10, 5, 18, 0), datetime.datetime(1975, 10, 6, 0, 0)], \n",
    "'8402': [datetime.datetime(1975, 10, 14, 12, 0), datetime.datetime(1975, 10, 14, 18, 0)], \n",
    "'8498': [datetime.datetime(1976, 7, 25, 18, 0), datetime.datetime(1976, 7, 26, 0, 0)], \n",
    "'8507': [datetime.datetime(1976, 8, 6, 12, 0), datetime.datetime(1976, 8, 6, 18, 0)], \n",
    "'8520': [datetime.datetime(1976, 8, 23, 18, 0), datetime.datetime(1976, 8, 24, 0, 0)], \n",
    "'8534': [datetime.datetime(1976, 9, 19, 18, 0), datetime.datetime(1976, 9, 20, 0, 0)], \n",
    "'8644': [datetime.datetime(1977, 9, 24, 18, 0), datetime.datetime(1977, 9, 25, 0, 0)], \n",
    "'8729': [datetime.datetime(1978, 7, 29, 18, 0), datetime.datetime(1978, 7, 30, 0, 0)], \n",
    "'8744': [datetime.datetime(1978, 8, 27, 6, 0), datetime.datetime(1978, 8, 27, 12, 0)], \n",
    "'8850': [datetime.datetime(1979, 7, 6, 0, 0), datetime.datetime(1979, 7, 6, 6, 0)], \n",
    "'8861': [datetime.datetime(1979, 8, 2, 0, 0), datetime.datetime(1979, 8, 2, 6, 0)], \n",
    "'8863': [datetime.datetime(1979, 7, 29, 0, 0), datetime.datetime(1979, 7, 29, 6, 0)], \n",
    "'8888': [datetime.datetime(1979, 9, 23, 12, 0), datetime.datetime(1979, 9, 23, 18, 0)], \n",
    "'8958': [datetime.datetime(1980, 5, 23, 18, 0), datetime.datetime(1980, 5, 24, 0, 0)], \n",
    "'8965': [datetime.datetime(1980, 7, 11, 12, 0), datetime.datetime(1980, 7, 11, 18, 0)], \n",
    "'8967': [datetime.datetime(1980, 7, 22, 6, 0), datetime.datetime(1980, 7, 22, 12, 0)], \n",
    "'8968': [datetime.datetime(1980, 7, 19, 0, 0), datetime.datetime(1980, 7, 19, 6, 0)], \n",
    "'8972': [datetime.datetime(1980, 7, 27, 6, 0), datetime.datetime(1980, 7, 27, 12, 0)], \n",
    "'9075': [datetime.datetime(1981, 7, 6, 18, 0), datetime.datetime(1981, 7, 7, 0, 0)], \n",
    "'9112': [datetime.datetime(1981, 9, 21, 18, 0), datetime.datetime(1981, 9, 22, 0, 0)], \n",
    "'9194': [datetime.datetime(1982, 7, 17, 0, 0), datetime.datetime(1982, 7, 17, 6, 0)], \n",
    "'9217': [datetime.datetime(1982, 9, 14, 18, 0), datetime.datetime(1982, 9, 15, 0, 0)],\n",
    "'9283': [datetime.datetime(1983, 7, 13, 12, 0), datetime.datetime(1983, 7, 13, 18, 0)],\n",
    "'9304': [datetime.datetime(1983, 9, 9, 0, 0), datetime.datetime(1983, 9, 9, 6, 0)],\n",
    "'9314': [datetime.datetime(1983, 9, 30, 0, 0), datetime.datetime(1983, 9, 30, 6, 0)],\n",
    "'9319': [datetime.datetime(1983, 10, 13, 12, 0), datetime.datetime(1983, 10, 13, 18, 0)],\n",
    "'9386': [datetime.datetime(1984, 6, 25, 6, 0), datetime.datetime(1984, 6, 25, 12, 0)],\n",
    "'9391': [datetime.datetime(1984, 7, 9, 0, 0), datetime.datetime(1984, 7, 9, 6, 0)],\n",
    "'9406': [datetime.datetime(1984, 8, 21, 0, 0), datetime.datetime(1984, 8, 21, 6, 0)],\n",
    "'9509': [datetime.datetime(1985, 6, 24, 0, 0), datetime.datetime(1985, 6, 24, 6, 0)],\n",
    "'9542': [datetime.datetime(1985, 9, 5, 18, 0), datetime.datetime(1985, 9, 6, 0, 0)],\n",
    "'9554': [datetime.datetime(1985, 9, 21, 18, 0), datetime.datetime(1985, 9, 22, 0, 0)],\n",
    "'9634': [datetime.datetime(1986, 7, 11, 6, 0), datetime.datetime(1986, 7, 11, 12, 0)],\n",
    "'9728': [datetime.datetime(1987, 6, 19, 0, 0), datetime.datetime(1987, 6, 19, 6, 0)],\n",
    "'9782': [datetime.datetime(1987, 10, 28, 0, 0), datetime.datetime(1987, 10, 28, 6, 0)],\n",
    "'9830': [datetime.datetime(1988, 7, 19, 6, 0), datetime.datetime(1988, 7, 19, 12, 0)],\n",
    "'9874': [datetime.datetime(1988, 9, 21, 18, 0), datetime.datetime(1988, 9, 22, 0, 0)],\n",
    "'9944': [datetime.datetime(1989, 5, 20, 12, 0), datetime.datetime(1989, 5, 20, 18, 0)],\n",
    "'9961': [datetime.datetime(1989, 7, 18, 0, 0), datetime.datetime(1989, 7, 18, 6, 0)],\n",
    "'10069': [datetime.datetime(1990, 6, 17, 18, 0), datetime.datetime(1990, 6, 18, 0, 0)],\n",
    "'10074': [datetime.datetime(1990, 6, 29, 6, 0), datetime.datetime(1990, 6, 29, 12, 0)],\n",
    "'10083': [datetime.datetime(1990, 7, 30, 18, 0), datetime.datetime(1990, 7, 31, 0, 0)],\n",
    "'10191': [datetime.datetime(1991, 7, 19, 6, 0), datetime.datetime(1991, 7, 19, 12, 0)],\n",
    "'10192': [datetime.datetime(1991, 7, 24, 0, 0), datetime.datetime(1991, 7, 24, 6, 0)],\n",
    "'10212': [datetime.datetime(1991, 9, 6, 12, 0), datetime.datetime(1991, 9, 6, 18, 0)],\n",
    "'10302': [datetime.datetime(1992, 7, 18, 0, 0), datetime.datetime(1992, 7, 18, 6, 0)],\n",
    "'10318': [datetime.datetime(1992, 8, 18, 18, 0), datetime.datetime(1992, 8, 19, 0, 0)],\n",
    "'10417': [datetime.datetime(1993, 6, 27, 12, 0), datetime.datetime(1993, 6, 27, 18, 0)],\n",
    "'10436': [datetime.datetime(1993, 8, 20, 18, 0), datetime.datetime(1993, 8, 21, 0, 0)],\n",
    "'10449': [datetime.datetime(1993, 9, 13, 18, 0), datetime.datetime(1993, 9, 14, 0, 0)],\n",
    "'10452': [datetime.datetime(1993, 9, 17, 0, 0), datetime.datetime(1993, 9, 17, 6, 0)],\n",
    "'10454': [datetime.datetime(1993, 9, 26, 6, 0), datetime.datetime(1993, 9, 26, 12, 0)],\n",
    "'10466': [datetime.datetime(1993, 11, 4, 12, 0), datetime.datetime(1993, 11, 4, 18, 0)],\n",
    "'10518': [datetime.datetime(1994, 6, 8, 6, 0), datetime.datetime(1994, 6, 8, 12, 0)],\n",
    "'10520': [datetime.datetime(1994, 6, 24, 18, 0), datetime.datetime(1994, 6, 25, 0, 0)],\n",
    "'10524': [datetime.datetime(1994, 7, 4, 6, 0), datetime.datetime(1994, 7, 4, 12, 0)],\n",
    "'10553': [datetime.datetime(1994, 8, 27, 12, 0), datetime.datetime(1994, 8, 27, 18, 0)],\n",
    "'10636': [datetime.datetime(1995, 7, 31, 0, 0), datetime.datetime(1995, 7, 31, 6, 0)],\n",
    "'10640': [datetime.datetime(1995, 8, 12, 0, 0), datetime.datetime(1995, 8, 12, 6, 0)],\n",
    "'10645': [datetime.datetime(1995, 8, 19, 12, 0), datetime.datetime(1995, 8, 19, 18, 0)],\n",
    "'10653': [datetime.datetime(1995, 8, 31, 0, 0), datetime.datetime(1995, 8, 31, 6, 0)],\n",
    "'10657': [datetime.datetime(1995, 9, 7, 0, 0), datetime.datetime(1995, 9, 7, 6, 0)],\n",
    "'10669': [datetime.datetime(1995, 10, 3, 0, 0), datetime.datetime(1995, 10, 3, 6, 0)],\n",
    "'10675': [datetime.datetime(1995, 10, 14, 6, 0), datetime.datetime(1995, 10, 14, 12, 0)],\n",
    "'10779': [datetime.datetime(1996, 9, 20, 0, 0), datetime.datetime(1996, 9, 20, 6, 0)],\n",
    "'10881': [datetime.datetime(1997, 8, 2, 6, 0), datetime.datetime(1997, 8, 2, 12, 0)],\n",
    "'10891': [datetime.datetime(1997, 8, 22, 0, 0), datetime.datetime(1997, 8, 22, 6, 0)],\n",
    "'10980': [datetime.datetime(1998, 8, 10, 18, 0), datetime.datetime(1998, 8, 11, 0, 0)],\n",
    "'10996': [datetime.datetime(1998, 9, 13, 6, 0), datetime.datetime(1998, 9, 13, 12, 0)],\n",
    "'11074': [datetime.datetime(1999, 5, 2, 12, 0), datetime.datetime(1999, 5, 2, 18, 0)],\n",
    "'11077': [datetime.datetime(1999, 6, 6, 12, 0), datetime.datetime(1999, 6, 6, 18, 0)],\n",
    "'11092': [datetime.datetime(1999, 7, 27, 0, 0), datetime.datetime(1999, 7, 27, 6, 0)],\n",
    "'11106': [datetime.datetime(1999, 8, 22, 6, 0), datetime.datetime(1999, 8, 22, 12, 0)],\n",
    "'11115': [datetime.datetime(1999, 9, 3, 18, 0), datetime.datetime(1999, 9, 4, 0, 0)],\n",
    "'11119': [datetime.datetime(1999, 9, 16, 6, 0), datetime.datetime(1999, 9, 16, 12, 0)],\n",
    "'11190': [datetime.datetime(2000, 7, 17, 0, 0), datetime.datetime(2000, 7, 17, 6, 0)],\n",
    "'11218': [datetime.datetime(2000, 8, 31, 18, 0), datetime.datetime(2000, 9, 1, 0, 0)],\n",
    "'11290': [datetime.datetime(2001, 7, 5, 18, 0), datetime.datetime(2001, 7, 6, 0, 0)], \n",
    "'11298': [datetime.datetime(2001, 7, 25, 18, 0), datetime.datetime(2001, 7, 26, 0, 0)],\n",
    "'11318': [datetime.datetime(2001, 9, 20, 0, 0), datetime.datetime(2001, 9, 20, 6, 0)],\n",
    "'11410': [datetime.datetime(2002, 8, 4, 18, 0), datetime.datetime(2002, 8, 5, 0, 0)],\n",
    "'11417': [datetime.datetime(2002, 8, 19, 6, 0), datetime.datetime(2002, 8, 19, 12, 0)],\n",
    "'11431': [datetime.datetime(2002, 9, 11, 18, 0), datetime.datetime(2002, 9, 12, 0, 0)],\n",
    "'11508': [datetime.datetime(2003, 7, 24, 0, 0), datetime.datetime(2003, 7, 24, 6, 0)],\n",
    "'11520': [datetime.datetime(2003, 8, 24, 18, 0), datetime.datetime(2003, 8, 25, 0, 0)],\n",
    "'11528': [datetime.datetime(2003, 9, 2, 6, 0), datetime.datetime(2003, 9, 2, 12, 0)],\n",
    "'11605': [datetime.datetime(2004, 7, 16, 6, 0), datetime.datetime(2004, 7, 16, 12, 0)],\n",
    "'11623': [datetime.datetime(2004, 8, 26, 0, 0), datetime.datetime(2004, 8, 26, 6, 0)],\n",
    "'11725': [datetime.datetime(2005, 8, 13, 0, 0), datetime.datetime(2005, 8, 13, 6, 0)],\n",
    "'11810': [datetime.datetime(2006, 5, 17, 12, 0), datetime.datetime(2006, 5, 17, 18, 0)],\n",
    "'11814': [datetime.datetime(2006, 6, 28, 18, 0), datetime.datetime(2006, 6, 29, 0, 0)],\n",
    "'11826': [datetime.datetime(2006, 8, 3, 6, 0), datetime.datetime(2006, 8, 3, 12, 0)],\n",
    "'11842': [datetime.datetime(2006, 8, 24, 18, 0), datetime.datetime(2006, 8, 25, 0, 0)],\n",
    "'11850': [datetime.datetime(2006, 9, 13, 6, 0), datetime.datetime(2006, 9, 13, 12, 0)],\n",
    "'11999': [datetime.datetime(2008, 4, 19, 0, 0), datetime.datetime(2008, 4, 19, 6, 0)],\n",
    "'12012': [datetime.datetime(2008, 6, 24, 18, 0), datetime.datetime(2008, 6, 25, 0, 0)],\n",
    "'12025': [datetime.datetime(2008, 8, 6, 6, 0), datetime.datetime(2008, 8, 6, 12, 0)],\n",
    "'12034': [datetime.datetime(2008, 8, 22, 6, 0), datetime.datetime(2008, 8, 22, 12, 0)],\n",
    "'12048': [datetime.datetime(2008, 9, 23, 18, 0), datetime.datetime(2008, 9, 24, 0, 0)],\n",
    "'12052': [datetime.datetime(2008, 10, 4, 6, 0), datetime.datetime(2008, 10, 4, 12, 0)],\n",
    "'12110': [datetime.datetime(2009, 6, 26, 12, 0), datetime.datetime(2009, 6, 26, 18, 0)],\n",
    "'12114': [datetime.datetime(2009, 7, 11, 18, 0), datetime.datetime(2009, 7, 12, 0, 0)],\n",
    "'12118': [datetime.datetime(2009, 7, 18, 12, 0), datetime.datetime(2009, 7, 18, 18, 0)],\n",
    "'12121': [datetime.datetime(2009, 8, 5, 0, 0), datetime.datetime(2009, 8, 5, 6, 0)],\n",
    "'12146': [datetime.datetime(2009, 9, 14, 18, 0), datetime.datetime(2009, 9, 15, 0, 0)],\n",
    "'12215': [datetime.datetime(2010, 7, 22, 0, 0), datetime.datetime(2010, 7, 22, 6, 0)],\n",
    "'12238': [datetime.datetime(2010, 9, 20, 0, 0), datetime.datetime(2010, 9, 20, 6, 0)],\n",
    "'12245': [datetime.datetime(2010, 10, 5, 12, 0), datetime.datetime(2010, 10, 5, 18, 0)],\n",
    "'12294': [datetime.datetime(2011, 6, 10, 18, 0), datetime.datetime(2011, 6, 11, 0, 0)],\n",
    "'12296': [datetime.datetime(2011, 6, 23, 6, 0), datetime.datetime(2011, 6, 23, 12, 0)],\n",
    "'12393': [datetime.datetime(2012, 6, 29, 18, 0), datetime.datetime(2012, 6, 30, 0, 0)],\n",
    "'12399': [datetime.datetime(2012, 7, 23, 18, 0), datetime.datetime(2012, 7, 24, 0, 0)],\n",
    "'12408': [datetime.datetime(2012, 8, 17, 0, 0), datetime.datetime(2012, 8, 17, 6, 0)],\n",
    "'12485': [datetime.datetime(2013, 7, 1, 18, 0), datetime.datetime(2013, 7, 2, 0, 0)],\n",
    "'12498': [datetime.datetime(2013, 8, 14, 6, 0), datetime.datetime(2013, 8, 14, 12, 0)],\n",
    "'12520': [datetime.datetime(2013, 9, 22, 6, 0), datetime.datetime(2013, 9, 22, 12, 0)],\n",
    "'12594': [datetime.datetime(2014, 6, 15, 6, 0), datetime.datetime(2014, 6, 15, 12, 0)],\n",
    "'12600': [datetime.datetime(2014, 7, 18, 6, 0), datetime.datetime(2014, 7, 18, 12, 0)],\n",
    "'12621': [datetime.datetime(2014, 9, 8, 0, 0), datetime.datetime(2014, 9, 8, 6, 0)],\n",
    "'12624': [datetime.datetime(2014, 9, 16, 0, 0), datetime.datetime(2014, 9, 16, 6, 0)],\n",
    "'12688': [datetime.datetime(2015, 7, 9, 0, 0), datetime.datetime(2015, 7, 9, 6, 0)],\n",
    "'12733': [datetime.datetime(2015, 10, 4, 0, 0), datetime.datetime(2015, 10, 4, 6, 0)],\n",
    "'12776': [datetime.datetime(2016, 5, 27, 6, 0), datetime.datetime(2016, 5, 27, 12, 0)],\n",
    "'12793': [datetime.datetime(2016, 8, 1, 18, 0), datetime.datetime(2016, 8, 2, 0, 0)],\n",
    "'12837': [datetime.datetime(2016, 10, 21, 0, 0), datetime.datetime(2016, 10, 21, 6, 0)]}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tic = time.time()\n",
    "#landfallTC_dates_PHI_2014 = getdates_landfall(0, after2014 = True)\n",
    "landfallTC_dates_PHI = getdates_landfall(0, after2014 = False)\n",
    "print(landfallTC_dates_PHI)\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "\n",
    "'''For PHI:\n",
    "{'12566': [datetime.datetime(2014, 1, 31, 12, 0), datetime.datetime(2014, 1, 31, 18, 0)],\n",
    "'12580': [datetime.datetime(2014, 3, 22, 6, 0), datetime.datetime(2014, 3, 22, 12, 0)],\n",
    "'12600': [datetime.datetime(2014, 7, 15, 6, 0), datetime.datetime(2014, 7, 15, 12, 0)],\n",
    "'12624': [datetime.datetime(2014, 9, 14, 6, 0), datetime.datetime(2014, 9, 14, 12, 0)],\n",
    "'12627': [datetime.datetime(2014, 9, 19, 0, 0), datetime.datetime(2014, 9, 19, 6, 0)],\n",
    "'12645': [datetime.datetime(2014, 11, 26, 6, 0), datetime.datetime(2014, 11, 26, 12, 0)],\n",
    "'12646': [datetime.datetime(2014, 12, 6, 12, 0), datetime.datetime(2014, 12, 6, 18, 0)],\n",
    "'12649': [datetime.datetime(2014, 12, 28, 18, 0), datetime.datetime(2014, 12, 29, 0, 0)],\n",
    "'12651': [datetime.datetime(2015, 1, 17, 6, 0), datetime.datetime(2015, 1, 17, 12, 0)],\n",
    "'12669': [datetime.datetime(2015, 4, 5, 0, 0), datetime.datetime(2015, 4, 5, 6, 0)],\n",
    "'12688': [datetime.datetime(2015, 7, 4, 18, 0), datetime.datetime(2015, 7, 5, 0, 0)],\n",
    "'12733': [datetime.datetime(2015, 10, 1, 12, 0), datetime.datetime(2015, 10, 1, 18, 0)],\n",
    "'12738': [datetime.datetime(2015, 10, 17, 18, 0), datetime.datetime(2015, 10, 18, 0, 0)],\n",
    "'12754': [datetime.datetime(2015, 12, 14, 6, 0), datetime.datetime(2015, 12, 14, 12, 0)],\n",
    "'12836': [datetime.datetime(2016, 10, 15, 18, 0), datetime.datetime(2016, 10, 16, 0, 0)],\n",
    "'12837': [datetime.datetime(2016, 10, 19, 12, 0), datetime.datetime(2016, 10, 19, 18, 0)],\n",
    "'12846': [datetime.datetime(2016, 11, 24, 12, 0), datetime.datetime(2016, 11, 24, 18, 0)],\n",
    "'12852': [datetime.datetime(2016, 12, 25, 12, 0), datetime.datetime(2016, 12, 25, 18, 0)]\n",
    "'12862': [datetime.datetime(2018, 9, 14, 16, 0), datetime.datetime(2016, 9, 14, 22, 0)}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''For PHI: {\n",
    "'4883': [datetime.datetime(1945, 8, 5, 18, 0), datetime.datetime(1945, 8, 6, 0, 0)], \n",
    "'4903': [datetime.datetime(1945, 9, 21, 6, 0)], \n",
    "'4912': [datetime.datetime(1945, 11, 4, 0, 0), datetime.datetime(1945, 11, 4, 6, 0)], \n",
    "'4953': [datetime.datetime(1946, 4, 4, 0, 0), datetime.datetime(1946, 4, 4, 6, 0)],\n",
    "'4968': [datetime.datetime(1946, 7, 16, 6, 0), datetime.datetime(1946, 7, 16, 12, 0)],\n",
    "'4981': [datetime.datetime(1946, 9, 10, 12, 0), datetime.datetime(1946, 9, 10, 18, 0)],\n",
    "'5039': [datetime.datetime(1947, 3, 19, 18, 0), datetime.datetime(1947, 3, 20, 0, 0)],\n",
    "'5081': [datetime.datetime(1947, 9, 23, 0, 0), datetime.datetime(1947, 9, 23, 6, 0)],\n",
    "'5087': [datetime.datetime(1947, 10, 5, 12, 0), datetime.datetime(1947, 10, 5, 18, 0)],\n",
    "'5099': [datetime.datetime(1947, 10, 30, 0, 0), datetime.datetime(1947, 10, 30, 6, 0)],\n",
    "'5103': [datetime.datetime(1947, 11, 7, 12, 0), datetime.datetime(1947, 11, 7, 18, 0)],\n",
    "'5105': [datetime.datetime(1947, 11, 14, 18, 0), datetime.datetime(1947, 11, 15, 0, 0)],\n",
    "'5110': [datetime.datetime(1947, 11, 30, 0, 0)],\n",
    "'5114': [datetime.datetime(1947, 12, 25, 12, 0), datetime.datetime(1947, 12, 25, 18, 0)],\n",
    "'5164': [datetime.datetime(1948, 7, 24, 18, 0), datetime.datetime(1948, 7, 25, 0, 0)],\n",
    "'5173': [datetime.datetime(1948, 8, 31, 12, 0), datetime.datetime(1948, 8, 31, 18, 0)],\n",
    "'5183': [datetime.datetime(1948, 9, 24, 12, 0), datetime.datetime(1948, 9, 24, 18, 0)],\n",
    "'5205': [datetime.datetime(1948, 11, 29, 6, 0), datetime.datetime(1948, 11, 29, 12, 0)],\n",
    "'5207': [datetime.datetime(1948, 12, 8, 6, 0), datetime.datetime(1948, 12, 8, 12, 0)],\n",
    "'5210': [datetime.datetime(1948, 12, 14, 0, 0), datetime.datetime(1948, 12, 14, 6, 0)],\n",
    "'5215': [datetime.datetime(1949, 1, 20, 12, 0), datetime.datetime(1949, 1, 20, 18, 0)],\n",
    "'5252': [datetime.datetime(1949, 7, 6, 6, 0), datetime.datetime(1949, 7, 6, 12, 0)],\n",
    "'5309': [datetime.datetime(1949, 11, 1, 6, 0), datetime.datetime(1949, 11, 1, 12, 0)],\n",
    "'5313': [datetime.datetime(1949, 11, 11, 0, 0), datetime.datetime(1949, 11, 11, 6, 0)],\n",
    "'5315': [datetime.datetime(1949, 12, 4, 0, 0), datetime.datetime(1949, 12, 4, 6, 0)],\n",
    "'5316': [datetime.datetime(1949, 12, 11, 12, 0), datetime.datetime(1949, 12, 11, 18, 0)],\n",
    "'5401': [datetime.datetime(1950, 10, 1, 12, 0), datetime.datetime(1950, 10, 1, 18, 0)],\n",
    "'5427': [datetime.datetime(1950, 11, 20, 0, 0), datetime.datetime(1950, 11, 20, 6, 0)],\n",
    "'5434': [datetime.datetime(1950, 12, 29, 12, 0), datetime.datetime(1950, 12, 29, 18, 0)],\n",
    "'5459': [datetime.datetime(1951, 5, 4, 12, 0), datetime.datetime(1951, 5, 4, 18, 0)],\n",
    "'5481': [datetime.datetime(1951, 7, 29, 18, 0), datetime.datetime(1951, 7, 30, 0, 0)],\n",
    "'5495': [datetime.datetime(1951, 9, 1, 0, 0), datetime.datetime(1951, 9, 1, 6, 0)],\n",
    "'5506': [datetime.datetime(1951, 9, 24, 0, 0), datetime.datetime(1951, 9, 24, 6, 0)],\n",
    "'5521': [datetime.datetime(1951, 11, 20, 6, 0), datetime.datetime(1951, 11, 20, 12, 0)],\n",
    "'5527': [datetime.datetime(1951, 12, 9, 6, 0), datetime.datetime(1951, 12, 9, 12, 0)],\n",
    "'5568': [datetime.datetime(1952, 7, 2, 0, 0), datetime.datetime(1952, 7, 2, 6, 0)],\n",
    "'5588': [datetime.datetime(1952, 8, 25, 6, 0), datetime.datetime(1952, 8, 25, 12, 0)],\n",
    "'5593': [datetime.datetime(1952, 9, 4, 0, 0), datetime.datetime(1952, 9, 4, 6, 0)],\n",
    "'5609': [datetime.datetime(1952, 10, 21, 12, 0), datetime.datetime(1952, 10, 21, 18, 0)],\n",
    "'5617': [datetime.datetime(1952, 10, 27, 0, 0), datetime.datetime(1952, 10, 27, 6, 0)],\n",
    "'5624': [datetime.datetime(1952, 11, 24, 18, 0), datetime.datetime(1952, 11, 25, 0, 0)],\n",
    "'5636': [datetime.datetime(1952, 12, 20, 12, 0), datetime.datetime(1952, 12, 20, 18, 0)],\n",
    "'5664': [datetime.datetime(1953, 6, 3, 18, 0), datetime.datetime(1953, 6, 4, 0, 0)],\n",
    "'5667': [datetime.datetime(1953, 6, 25, 12, 0), datetime.datetime(1953, 6, 25, 18, 0)],\n",
    "'5679': [datetime.datetime(1953, 8, 11, 18, 0), datetime.datetime(1953, 8, 12, 0, 0)],\n",
    "'5712': [datetime.datetime(1953, 10, 27, 6, 0), datetime.datetime(1953, 10, 27, 12, 0)],\n",
    "'5715': [datetime.datetime(1953, 11, 16, 12, 0), datetime.datetime(1953, 11, 16, 18, 0)],\n",
    "'5735': [datetime.datetime(1954, 3, 3, 12, 0), datetime.datetime(1954, 3, 3, 18, 0)],\n",
    "'5743': [datetime.datetime(1954, 5, 6, 12, 0), datetime.datetime(1954, 5, 6, 18, 0)],\n",
    "'5800': [datetime.datetime(1954, 10, 7, 18, 0), datetime.datetime(1954, 10, 8, 0, 0)],\n",
    "'5813': [datetime.datetime(1954, 11, 8, 0, 0), datetime.datetime(1954, 11, 8, 6, 0)],\n",
    "'5818': [datetime.datetime(1954, 11, 29, 6, 0), datetime.datetime(1954, 11, 29, 12, 0)],\n",
    "'5826': [datetime.datetime(1955, 1, 4, 12, 0), datetime.datetime(1955, 1, 4, 18, 0)],\n",
    "'5892': [datetime.datetime(1955, 9, 23, 0, 0), datetime.datetime(1955, 9, 23, 6, 0)],\n",
    "'5915': [datetime.datetime(1955, 11, 29, 6, 0), datetime.datetime(1955, 11, 29, 12, 0)],\n",
    "'5958': [datetime.datetime(1956, 4, 9, 0, 0)],\n",
    "'5959': [datetime.datetime(1956, 4, 21, 6, 0), datetime.datetime(1956, 4, 21, 12, 0)],\n",
    "'5979': [datetime.datetime(1956, 7, 5, 6, 0), datetime.datetime(1956, 7, 5, 12, 0)],\n",
    "'5991': [datetime.datetime(1956, 8, 10, 0, 0), datetime.datetime(1956, 8, 10, 6, 0)],\n",
    "'6000': [datetime.datetime(1956, 8, 28, 12, 0), datetime.datetime(1956, 8, 28, 18, 0)],\n",
    "'6014': [datetime.datetime(1956, 9, 18, 6, 0), datetime.datetime(1956, 9, 18, 12, 0)],\n",
    "'6021': [datetime.datetime(1956, 10, 20, 18, 0), datetime.datetime(1956, 10, 21, 0, 0)],\n",
    "'6028': [datetime.datetime(1956, 11, 15, 6, 0), datetime.datetime(1956, 11, 15, 12, 0)],\n",
    "'6037': [datetime.datetime(1956, 11, 28, 18, 0), datetime.datetime(1956, 11, 29, 0, 0)],\n",
    "'6038': [datetime.datetime(1956, 12, 8, 18, 0), datetime.datetime(1956, 12, 9, 0, 0)],\n",
    "'6044': [datetime.datetime(1957, 1, 6, 0, 0), datetime.datetime(1957, 1, 6, 6, 0)],\n",
    "'6078': [datetime.datetime(1957, 7, 14, 12, 0), datetime.datetime(1957, 7, 14, 18, 0)],\n",
    "'6102': [datetime.datetime(1957, 9, 20, 6, 0), datetime.datetime(1957, 9, 20, 12, 0)],\n",
    "'6111': [datetime.datetime(1957, 10, 12, 6, 0), datetime.datetime(1957, 10, 12, 12, 0)],\n",
    "'6118': [datetime.datetime(1957, 11, 11, 18, 0), datetime.datetime(1957, 11, 12, 0, 0)],\n",
    "'6229': [datetime.datetime(1958, 10, 20, 18, 0), datetime.datetime(1958, 10, 21, 0, 0)],\n",
    "'6318': [datetime.datetime(1959, 9, 7, 18, 0), datetime.datetime(1959, 9, 8, 0, 0)],\n",
    "'6334': [datetime.datetime(1959, 10, 6, 0, 0), datetime.datetime(1959, 10, 6, 6, 0)],\n",
    "'6347': [datetime.datetime(1959, 11, 16, 0, 0), datetime.datetime(1959, 11, 16, 6, 0)], \n",
    "'6352': [datetime.datetime(1959, 12, 18, 0, 0), datetime.datetime(1959, 12, 18, 6, 0)], \n",
    "'6354': [datetime.datetime(1959, 12, 30, 18, 0), datetime.datetime(1959, 12, 31, 0, 0)], \n",
    "'6374': [datetime.datetime(1960, 4, 21, 18, 0), datetime.datetime(1960, 4, 22, 0, 0)], \n",
    "'6377': [datetime.datetime(1960, 5, 27, 6, 0), datetime.datetime(1960, 5, 27, 12, 0)], \n",
    "'6385': [datetime.datetime(1960, 6, 25, 18, 0), datetime.datetime(1960, 6, 26, 0, 0)], \n",
    "'6419': [datetime.datetime(1960, 9, 1, 12, 0), datetime.datetime(1960, 9, 1, 18, 0)], \n",
    "'6432': [datetime.datetime(1960, 10, 6, 6, 0), datetime.datetime(1960, 10, 6, 12, 0)], \n",
    "'6435': [datetime.datetime(1960, 10, 13, 6, 0), datetime.datetime(1960, 10, 13, 12, 0)], \n",
    "'6515': [datetime.datetime(1961, 7, 17, 6, 0), datetime.datetime(1961, 7, 17, 12, 0)], \n",
    "'6619': [datetime.datetime(1962, 5, 16, 12, 0), datetime.datetime(1962, 5, 16, 18, 0)], \n",
    "'6640': [datetime.datetime(1962, 8, 7, 18, 0), datetime.datetime(1962, 8, 8, 0, 0)], \n",
    "'6665': [datetime.datetime(1962, 9, 23, 18, 0), datetime.datetime(1962, 9, 24, 0, 0)], \n",
    "'6681': [datetime.datetime(1962, 11, 6, 0, 0), datetime.datetime(1962, 11, 6, 6, 0)], \n",
    "'6684': [datetime.datetime(1962, 11, 27, 0, 0), datetime.datetime(1962, 11, 27, 6, 0)], \n",
    "'6748': [datetime.datetime(1963, 6, 27, 18, 0), datetime.datetime(1963, 6, 28, 0, 0)], \n",
    "'6757': [datetime.datetime(1963, 7, 20, 6, 0), datetime.datetime(1963, 7, 20, 12, 0)], \n",
    "'6765': [datetime.datetime(1963, 8, 12, 18, 0), datetime.datetime(1963, 8, 13, 0, 0)], \n",
    "'6857': [datetime.datetime(1964, 6, 29, 12, 0), datetime.datetime(1964, 6, 29, 18, 0)], \n",
    "'6864': [datetime.datetime(1964, 7, 17, 18, 0), datetime.datetime(1964, 7, 18, 0, 0)], \n",
    "'6872': [datetime.datetime(1964, 8, 6, 18, 0), datetime.datetime(1964, 8, 7, 0, 0)], \n",
    "'6907': [datetime.datetime(1964, 9, 28, 18, 0), datetime.datetime(1964, 9, 29, 0, 0)], \n",
    "'6910': [datetime.datetime(1964, 10, 4, 18, 0), datetime.datetime(1964, 10, 5, 0, 0)], \n",
    "'6911': [datetime.datetime(1964, 10, 9, 0, 0), datetime.datetime(1964, 10, 9, 6, 0)], \n",
    "'6917': [datetime.datetime(1964, 10, 21, 0, 0), datetime.datetime(1964, 10, 21, 6, 0)], \n",
    "'6928': [datetime.datetime(1964, 11, 19, 0, 0), datetime.datetime(1964, 11, 19, 6, 0)], \n",
    "'6932': [datetime.datetime(1964, 11, 26, 18, 0), datetime.datetime(1964, 11, 27, 0, 0)], \n",
    "'6937': [datetime.datetime(1964, 12, 14, 12, 0), datetime.datetime(1964, 12, 14, 18, 0)], \n",
    "'6954': [datetime.datetime(1965, 1, 23, 0, 0), datetime.datetime(1965, 1, 23, 6, 0)], \n",
    "'6977': [datetime.datetime(1965, 3, 7, 0, 0), datetime.datetime(1965, 3, 7, 6, 0)], \n",
    "'7000': [datetime.datetime(1965, 7, 13, 6, 0), datetime.datetime(1965, 7, 13, 12, 0)], \n",
    "'7003': [datetime.datetime(1965, 7, 19, 0, 0), datetime.datetime(1965, 7, 19, 6, 0)], \n",
    "'7037': [datetime.datetime(1965, 9, 14, 0, 0), datetime.datetime(1965, 9, 14, 6, 0)], \n",
    "'7094': [datetime.datetime(1966, 5, 15, 12, 0), datetime.datetime(1966, 5, 15, 18, 0)], \n",
    "'7168': [datetime.datetime(1966, 10, 31, 6, 0), datetime.datetime(1966, 10, 31, 12, 0)], \n",
    "'7177': [datetime.datetime(1966, 11, 19, 12, 0), datetime.datetime(1966, 11, 19, 18, 0)],\n",
    "'7186': [datetime.datetime(1966, 12, 18, 18, 0), datetime.datetime(1966, 12, 19, 0, 0)], \n",
    "'7190': [datetime.datetime(1966, 12, 26, 12, 0), datetime.datetime(1966, 12, 26, 18, 0)], \n",
    "'7210': [datetime.datetime(1967, 3, 3, 0, 0), datetime.datetime(1967, 3, 3, 6, 0)], \n",
    "'7219': [datetime.datetime(1967, 4, 8, 0, 0), datetime.datetime(1967, 4, 8, 6, 0)], \n",
    "'7264': [datetime.datetime(1967, 8, 19, 0, 0), datetime.datetime(1967, 8, 19, 6, 0)],\n",
    "'7311': [datetime.datetime(1967, 10, 16, 18, 0), datetime.datetime(1967, 10, 17, 0, 0)],\n",
    "'7321': [datetime.datetime(1967, 11, 3, 12, 0), datetime.datetime(1967, 11, 3, 18, 0)], \n",
    "'7324': [datetime.datetime(1967, 11, 7, 0, 0), datetime.datetime(1967, 11, 7, 6, 0)], \n",
    "'7398': [datetime.datetime(1968, 8, 10, 0, 0), datetime.datetime(1968, 8, 10, 6, 0)], \n",
    "'7405': [datetime.datetime(1968, 8, 19, 0, 0), datetime.datetime(1968, 8, 19, 6, 0)], \n",
    "'7433': [datetime.datetime(1968, 9, 28, 6, 0), datetime.datetime(1968, 9, 28, 12, 0)], \n",
    "'7457': [datetime.datetime(1968, 11, 18, 12, 0), datetime.datetime(1968, 11, 18, 18, 0)], \n",
    "'7459': [datetime.datetime(1968, 11, 23, 12, 0), datetime.datetime(1968, 11, 23, 18, 0)], \n",
    "'7460': [datetime.datetime(1968, 11, 29, 6, 0), datetime.datetime(1968, 11, 29, 12, 0)], \n",
    "'7498': [datetime.datetime(1969, 4, 23, 12, 0), datetime.datetime(1969, 4, 23, 18, 0)], \n",
    "'7510': [datetime.datetime(1969, 7, 8, 12, 0), datetime.datetime(1969, 7, 8, 18, 0)], \n",
    "'7636': [datetime.datetime(1970, 6, 29, 18, 0), datetime.datetime(1970, 6, 30, 0, 0)], \n",
    "'7643': [datetime.datetime(1970, 7, 13, 18, 0), datetime.datetime(1970, 7, 14, 0, 0)], \n",
    "'7662': [datetime.datetime(1970, 8, 6, 18, 0), datetime.datetime(1970, 8, 7, 0, 0)], \n",
    "'7691': [datetime.datetime(1970, 9, 11, 0, 0), datetime.datetime(1970, 9, 11, 6, 0)], \n",
    "'7712': [datetime.datetime(1970, 10, 13, 0, 0), datetime.datetime(1970, 10, 13, 6, 0)], \n",
    "'7714': [datetime.datetime(1970, 10, 18, 6, 0), datetime.datetime(1970, 10, 18, 12, 0)], \n",
    "'7721': [datetime.datetime(1970, 10, 31, 18, 0), datetime.datetime(1970, 11, 1, 0, 0)], \n",
    "'7727': [datetime.datetime(1970, 11, 18, 18, 0), datetime.datetime(1970, 11, 19, 0, 0)], \n",
    "'7775': [datetime.datetime(1971, 4, 24, 0, 0), datetime.datetime(1971, 4, 24, 6, 0)], \n",
    "'7781': [datetime.datetime(1971, 5, 25, 18, 0), datetime.datetime(1971, 5, 26, 0, 0)], \n",
    "'7786': [datetime.datetime(1971, 6, 15, 6, 0), datetime.datetime(1971, 6, 15, 12, 0)], \n",
    "'7791': [datetime.datetime(1971, 6, 24, 18, 0), datetime.datetime(1971, 6, 25, 0, 0)], \n",
    "'7792': [datetime.datetime(1971, 7, 2, 18, 0), datetime.datetime(1971, 7, 3, 0, 0)], \n",
    "'7800': [datetime.datetime(1971, 7, 14, 0, 0), datetime.datetime(1971, 7, 14, 6, 0)], \n",
    "'7816': [datetime.datetime(1971, 8, 13, 12, 0), datetime.datetime(1971, 8, 13, 18, 0)], \n",
    "'7854': [datetime.datetime(1971, 9, 26, 18, 0), datetime.datetime(1971, 9, 27, 0, 0)], \n",
    "'7859': [datetime.datetime(1971, 10, 3, 6, 0), datetime.datetime(1971, 10, 3, 12, 0)], \n",
    "'7861': [datetime.datetime(1971, 10, 10, 12, 0), datetime.datetime(1971, 10, 10, 18, 0)], \n",
    "'7866': [datetime.datetime(1971, 10, 9, 18, 0), datetime.datetime(1971, 10, 10, 0, 0)], \n",
    "'7868': [datetime.datetime(1971, 10, 20, 0, 0), datetime.datetime(1971, 10, 20, 6, 0)], \n",
    "'7896': [datetime.datetime(1972, 1, 7, 12, 0), datetime.datetime(1972, 1, 7, 18, 0)], \n",
    "'7935': [datetime.datetime(1972, 6, 24, 12, 0), datetime.datetime(1972, 6, 24, 18, 0)], \n",
    "'7940': [datetime.datetime(1972, 7, 5, 0, 0), datetime.datetime(1972, 7, 5, 6, 0)], \n",
    "'7972': [datetime.datetime(1972, 8, 30, 12, 0)], \n",
    "'7976': [datetime.datetime(1972, 9, 9, 18, 0), datetime.datetime(1972, 9, 10, 0, 0)], \n",
    "'8003': [datetime.datetime(1972, 11, 4, 18, 0), datetime.datetime(1972, 11, 5, 0, 0)], \n",
    "'8014': [datetime.datetime(1972, 12, 3, 0, 0), datetime.datetime(1972, 12, 3, 6, 0)], \n",
    "'8075': [datetime.datetime(1973, 6, 29, 18, 0), datetime.datetime(1973, 6, 30, 0, 0)], \n",
    "'8114': [datetime.datetime(1973, 9, 11, 12, 0), datetime.datetime(1973, 9, 11, 18, 0)], \n",
    "'8131': [datetime.datetime(1973, 10, 15, 12, 0), datetime.datetime(1973, 10, 15, 18, 0)], \n",
    "'8142': [datetime.datetime(1973, 11, 19, 12, 0), datetime.datetime(1973, 11, 19, 18, 0)], \n",
    "'8194': [datetime.datetime(1974, 6, 10, 0, 0), datetime.datetime(1974, 6, 10, 6, 0)], \n",
    "'8213': [datetime.datetime(1974, 7, 20, 0, 0), datetime.datetime(1974, 7, 20, 6, 0)], \n",
    "'8267': [datetime.datetime(1974, 10, 10, 18, 0), datetime.datetime(1974, 10, 11, 0, 0)], \n",
    "'8269': [datetime.datetime(1974, 10, 16, 6, 0), datetime.datetime(1974, 10, 16, 12, 0)], \n",
    "'8275': [datetime.datetime(1974, 10, 27, 18, 0), datetime.datetime(1974, 10, 28, 0, 0)], \n",
    "'8278': [datetime.datetime(1974, 11, 1, 0, 0), datetime.datetime(1974, 11, 1, 6, 0)], '8280': [datetime.datetime(1974, 11, 6, 18, 0), datetime.datetime(1974, 11, 7, 0, 0)], '8282': [datetime.datetime(1974, 11, 12, 18, 0), datetime.datetime(1974, 11, 13, 0, 0)], '8284': [datetime.datetime(1974, 11, 28, 0, 0), datetime.datetime(1974, 11, 28, 6, 0)], '8292': [datetime.datetime(1974, 12, 20, 6, 0), datetime.datetime(1974, 12, 20, 12, 0)], '8305': [datetime.datetime(1975, 1, 24, 6, 0), datetime.datetime(1975, 1, 24, 12, 0)], '8330': [datetime.datetime(1975, 4, 21, 18, 0), datetime.datetime(1975, 4, 22, 0, 0)], '8389': [datetime.datetime(1975, 9, 17, 18, 0), datetime.datetime(1975, 9, 18, 0, 0)], '8415': [datetime.datetime(1975, 11, 1, 12, 0), datetime.datetime(1975, 11, 1, 18, 0)], '8435': [datetime.datetime(1975, 12, 27, 0, 0), datetime.datetime(1975, 12, 27, 6, 0)], '8477': [datetime.datetime(1976, 5, 20, 18, 0), datetime.datetime(1976, 5, 21, 0, 0)], '8487': [datetime.datetime(1976, 6, 25, 0, 0), datetime.datetime(1976, 6, 25, 6, 0)], '8520': [datetime.datetime(1976, 8, 22, 6, 0), datetime.datetime(1976, 8, 22, 12, 0)], '8561': [datetime.datetime(1976, 12, 4, 12, 0), datetime.datetime(1976, 12, 4, 18, 0)], '8612': [datetime.datetime(1977, 7, 16, 18, 0), datetime.datetime(1977, 7, 17, 0, 0)], '8639': [datetime.datetime(1977, 9, 15, 12, 0), datetime.datetime(1977, 9, 15, 18, 0)], '8664': [datetime.datetime(1977, 11, 13, 12, 0), datetime.datetime(1977, 11, 13, 18, 0)], '8674': [datetime.datetime(1978, 1, 1, 18, 0), datetime.datetime(1978, 1, 2, 0, 0)], '8708': [datetime.datetime(1978, 4, 19, 18, 0), datetime.datetime(1978, 4, 20, 0, 0)], '8717': [datetime.datetime(1978, 6, 26, 18, 0), datetime.datetime(1978, 6, 27, 0, 0)], '8744': [datetime.datetime(1978, 8, 23, 12, 0), datetime.datetime(1978, 8, 23, 18, 0)], '8771': [datetime.datetime(1978, 9, 26, 12, 0), datetime.datetime(1978, 9, 26, 18, 0)], '8777': [datetime.datetime(1978, 10, 9, 12, 0), datetime.datetime(1978, 10, 9, 18, 0)], '8785': [datetime.datetime(1978, 10, 26, 12, 0), datetime.datetime(1978, 10, 26, 18, 0)], '8798': [datetime.datetime(1978, 11, 19, 18, 0), datetime.datetime(1978, 11, 20, 0, 0)], '8835': [datetime.datetime(1979, 4, 15, 6, 0), datetime.datetime(1979, 4, 15, 12, 0)], '8839': [datetime.datetime(1979, 5, 10, 18, 0), datetime.datetime(1979, 5, 11, 0, 0)], '8888': [datetime.datetime(1979, 9, 17, 18, 0), datetime.datetime(1979, 9, 18, 0, 0)], '8897': [datetime.datetime(1979, 10, 1, 6, 0), datetime.datetime(1979, 10, 1, 12, 0)], '8906': [datetime.datetime(1979, 11, 6, 6, 0), datetime.datetime(1979, 11, 6, 12, 0)], '8908': [datetime.datetime(1979, 11, 13, 12, 0), datetime.datetime(1979, 11, 13, 18, 0)], '8918': [datetime.datetime(1979, 12, 21, 6, 0), datetime.datetime(1979, 12, 21, 12, 0)], '8945': [datetime.datetime(1980, 3, 23, 12, 0), datetime.datetime(1980, 3, 23, 18, 0)], '8957': [datetime.datetime(1980, 5, 24, 6, 0), datetime.datetime(1980, 5, 24, 12, 0)], '8961': [datetime.datetime(1980, 6, 23, 0, 0), datetime.datetime(1980, 6, 23, 6, 0)], '8967': [datetime.datetime(1980, 7, 20, 12, 0), datetime.datetime(1980, 7, 20, 18, 0)], '8968': [datetime.datetime(1980, 7, 15, 18, 0), datetime.datetime(1980, 7, 16, 0, 0)], '8972': [datetime.datetime(1980, 7, 25, 0, 0), datetime.datetime(1980, 7, 25, 6, 0)], '8980': [datetime.datetime(1980, 8, 15, 0, 0), datetime.datetime(1980, 8, 15, 6, 0)], '9011': [datetime.datetime(1980, 11, 4, 12, 0), datetime.datetime(1980, 11, 4, 18, 0)], '9012': [datetime.datetime(1980, 10, 28, 18, 0), datetime.datetime(1980, 10, 29, 0, 0)], '9074': [datetime.datetime(1981, 6, 30, 6, 0), datetime.datetime(1981, 6, 30, 12, 0)], '9075': [datetime.datetime(1981, 7, 3, 18, 0), datetime.datetime(1981, 7, 4, 0, 0)], '9124': [datetime.datetime(1981, 10, 11, 18, 0), datetime.datetime(1981, 10, 12, 0, 0)], '9134': [datetime.datetime(1981, 11, 19, 12, 0), datetime.datetime(1981, 11, 19, 18, 0)], '9136': [datetime.datetime(1981, 11, 24, 6, 0), datetime.datetime(1981, 11, 24, 12, 0)], '9148': [datetime.datetime(1981, 12, 25, 6, 0), datetime.datetime(1981, 12, 25, 12, 0)], '9168': [datetime.datetime(1982, 3, 19, 6, 0), datetime.datetime(1982, 3, 19, 12, 0)], '9171': [datetime.datetime(1982, 3, 25, 12, 0), datetime.datetime(1982, 3, 25, 18, 0)], '9194': [datetime.datetime(1982, 7, 15, 0, 0), datetime.datetime(1982, 7, 15, 6, 0)], '9209': [datetime.datetime(1982, 8, 19, 18, 0), datetime.datetime(1982, 8, 20, 0, 0)], '9217': [datetime.datetime(1982, 9, 8, 6, 0), datetime.datetime(1982, 9, 8, 12, 0)], '9234': [datetime.datetime(1982, 10, 14, 6, 0), datetime.datetime(1982, 10, 14, 12, 0)], '9247': [datetime.datetime(1982, 12, 7, 6, 0), datetime.datetime(1982, 12, 7, 12, 0)], '9249': [datetime.datetime(1982, 12, 8, 0, 0), datetime.datetime(1982, 12, 8, 6, 0)], '9278': [datetime.datetime(1983, 6, 21, 12, 0), datetime.datetime(1983, 6, 21, 18, 0)], '9281': [datetime.datetime(1983, 7, 14, 6, 0), datetime.datetime(1983, 7, 14, 12, 0)], '9283': [datetime.datetime(1983, 7, 9, 12, 0), datetime.datetime(1983, 7, 9, 18, 0)], '9319': [datetime.datetime(1983, 10, 10, 18, 0), datetime.datetime(1983, 10, 11, 0, 0)], '9336': [datetime.datetime(1983, 11, 24, 6, 0), datetime.datetime(1983, 11, 24, 12, 0)], '9391': [datetime.datetime(1984, 7, 5, 18, 0), datetime.datetime(1984, 7, 6, 0, 0)], '9415': [datetime.datetime(1984, 8, 28, 12, 0), datetime.datetime(1984, 8, 28, 18, 0)], '9416': [datetime.datetime(1984, 9, 1, 12, 0), datetime.datetime(1984, 9, 1, 18, 0)], '9450': [datetime.datetime(1984, 11, 4, 18, 0), datetime.datetime(1984, 11, 5, 0, 0)], '9542': [datetime.datetime(1985, 9, 3, 0, 0), datetime.datetime(1985, 9, 3, 6, 0)], '9564': [datetime.datetime(1985, 10, 12, 0, 0), datetime.datetime(1985, 10, 12, 6, 0)], '9567': [datetime.datetime(1985, 10, 18, 12, 0), datetime.datetime(1985, 10, 18, 18, 0)], '9570': [datetime.datetime(1985, 10, 23, 6, 0), datetime.datetime(1985, 10, 23, 12, 0)], '9634': [datetime.datetime(1986, 7, 8, 18, 0), datetime.datetime(1986, 7, 9, 0, 0)], '9673': [datetime.datetime(1986, 10, 11, 0, 0), datetime.datetime(1986, 10, 11, 6, 0)], '9675': [datetime.datetime(1986, 10, 18, 12, 0), datetime.datetime(1986, 10, 18, 18, 0)], '9677': [datetime.datetime(1986, 11, 7, 12, 0), datetime.datetime(1986, 11, 7, 18, 0)], '9679': [datetime.datetime(1986, 11, 12, 6, 0), datetime.datetime(1986, 11, 12, 12, 0)], '9689': [datetime.datetime(1986, 12, 21, 6, 0), datetime.datetime(1986, 12, 21, 12, 0)], '9692': [datetime.datetime(1986, 12, 31, 6, 0), datetime.datetime(1986, 12, 31, 12, 0)], '9744': [datetime.datetime(1987, 8, 12, 6, 0), datetime.datetime(1987, 8, 12, 12, 0)], '9745': [datetime.datetime(1987, 8, 18, 0, 0), datetime.datetime(1987, 8, 18, 6, 0)], '9787': [datetime.datetime(1987, 11, 14, 12, 0), datetime.datetime(1987, 11, 14, 18, 0)], '9789': [datetime.datetime(1987, 11, 25, 12, 0), datetime.datetime(1987, 11, 25, 18, 0)], '9790': [datetime.datetime(1987, 11, 21, 0, 0), datetime.datetime(1987, 11, 21, 6, 0)], '9794': [datetime.datetime(1987, 12, 15, 18, 0), datetime.datetime(1987, 12, 16, 0, 0)], '9800': [datetime.datetime(1988, 1, 16, 0, 0), datetime.datetime(1988, 1, 16, 6, 0)], '9826': [datetime.datetime(1988, 6, 27, 6, 0), datetime.datetime(1988, 6, 27, 12, 0)], '9874': [datetime.datetime(1988, 9, 19, 12, 0), datetime.datetime(1988, 9, 19, 18, 0)], '9888': [datetime.datetime(1988, 10, 20, 12, 0), datetime.datetime(1988, 10, 20, 18, 0)], '9892': [datetime.datetime(1988, 10, 24, 0, 0), datetime.datetime(1988, 10, 24, 6, 0)], '9894': [datetime.datetime(1988, 11, 1, 18, 0), datetime.datetime(1988, 11, 2, 0, 0)], '9896': [datetime.datetime(1988, 11, 7, 0, 0), datetime.datetime(1988, 11, 7, 6, 0)], '9910': [datetime.datetime(1989, 1, 21, 6, 0), datetime.datetime(1989, 1, 21, 12, 0)], '9944': [datetime.datetime(1989, 5, 16, 12, 0), datetime.datetime(1989, 5, 16, 18, 0)], '9948': [datetime.datetime(1989, 6, 6, 0, 0), datetime.datetime(1989, 6, 6, 6, 0)], '9956': [datetime.datetime(1989, 7, 8, 6, 0), datetime.datetime(1989, 7, 8, 12, 0)], '9961': [datetime.datetime(1989, 7, 15, 18, 0), datetime.datetime(1989, 7, 16, 0, 0)], '9968': [datetime.datetime(1989, 7, 19, 18, 0), datetime.datetime(1989, 7, 20, 0, 0)], '10010': [datetime.datetime(1989, 10, 5, 12, 0), datetime.datetime(1989, 10, 5, 18, 0)], '10015': [datetime.datetime(1989, 10, 10, 12, 0), datetime.datetime(1989, 10, 10, 18, 0)], '10017': [datetime.datetime(1989, 10, 19, 0, 0), datetime.datetime(1989, 10, 19, 6, 0)], '10025': [datetime.datetime(1989, 11, 21, 18, 0), datetime.datetime(1989, 11, 22, 0, 0)], '10061': [datetime.datetime(1990, 5, 13, 6, 0), datetime.datetime(1990, 5, 13, 12, 0)], '10069': [datetime.datetime(1990, 6, 14, 6, 0), datetime.datetime(1990, 6, 14, 12, 0)], '10074': [datetime.datetime(1990, 6, 27, 0, 0), datetime.datetime(1990, 6, 27, 6, 0)], '10103': [datetime.datetime(1990, 8, 26, 6, 0), datetime.datetime(1990, 8, 26, 12, 0)], '10133': [datetime.datetime(1990, 10, 10, 12, 0), datetime.datetime(1990, 10, 10, 18, 0)], '10144': [datetime.datetime(1990, 11, 12, 12, 0), datetime.datetime(1990, 11, 12, 18, 0)], '10145': [datetime.datetime(1990, 11, 8, 6, 0)], '10147': [datetime.datetime(1990, 12, 4, 6, 0), datetime.datetime(1990, 12, 4, 12, 0)], '10164': [datetime.datetime(1991, 3, 12, 18, 0), datetime.datetime(1991, 3, 13, 0, 0)], '10173': [datetime.datetime(1991, 4, 24, 6, 0), datetime.datetime(1991, 4, 24, 12, 0)], '10181': [datetime.datetime(1991, 6, 15, 0, 0), datetime.datetime(1991, 6, 15, 6, 0)], '10188': [datetime.datetime(1991, 7, 9, 0, 0), datetime.datetime(1991, 7, 9, 6, 0)], '10192': [datetime.datetime(1991, 7, 22, 0, 0), datetime.datetime(1991, 7, 22, 6, 0)], '10200': [datetime.datetime(1991, 8, 12, 6, 0), datetime.datetime(1991, 8, 12, 12, 0)], '10212': [datetime.datetime(1991, 9, 1, 12, 0), datetime.datetime(1991, 9, 1, 18, 0)], '10233': [datetime.datetime(1991, 10, 27, 6, 0), datetime.datetime(1991, 10, 27, 12, 0)], '10238': [datetime.datetime(1991, 11, 12, 18, 0), datetime.datetime(1991, 11, 13, 0, 0)], '10241': [datetime.datetime(1991, 11, 4, 18, 0), datetime.datetime(1991, 11, 5, 0, 0)], '10246': [datetime.datetime(1991, 11, 16, 6, 0), datetime.datetime(1991, 11, 16, 12, 0)], '10293': [datetime.datetime(1992, 6, 22, 6, 0), datetime.datetime(1992, 6, 22, 12, 0)], '10299': [datetime.datetime(1992, 7, 11, 0, 0), datetime.datetime(1992, 7, 11, 6, 0)], '10302': [datetime.datetime(1992, 7, 15, 0, 0), datetime.datetime(1992, 7, 15, 6, 0)], '10305': [datetime.datetime(1992, 7, 19, 18, 0), datetime.datetime(1992, 7, 20, 0, 0)], '10362': [datetime.datetime(1992, 10, 25, 18, 0), datetime.datetime(1992, 10, 26, 0, 0)], '10373': [datetime.datetime(1992, 11, 10, 18, 0), datetime.datetime(1992, 11, 11, 0, 0)], '10401': [datetime.datetime(1993, 3, 1, 0, 0), datetime.datetime(1993, 3, 1, 6, 0)], '10408': [datetime.datetime(1993, 4, 13, 6, 0), datetime.datetime(1993, 4, 13, 12, 0)], '10410': [datetime.datetime(1993, 4, 27, 18, 0), datetime.datetime(1993, 4, 28, 0, 0)], '10417': [datetime.datetime(1993, 6, 25, 18, 0), datetime.datetime(1993, 6, 26, 0, 0)], '10418': [datetime.datetime(1993, 6, 19, 0, 0), datetime.datetime(1993, 6, 19, 6, 0)], '10422': [datetime.datetime(1993, 7, 7, 18, 0), datetime.datetime(1993, 7, 8, 0, 0)], '10441': [datetime.datetime(1993, 8, 21, 18, 0), datetime.datetime(1993, 8, 22, 0, 0)], '10449': [datetime.datetime(1993, 9, 8, 6, 0), datetime.datetime(1993, 9, 8, 12, 0)], '10452': [datetime.datetime(1993, 9, 15, 6, 0), datetime.datetime(1993, 9, 15, 12, 0)], '10454': [datetime.datetime(1993, 9, 20, 0, 0), datetime.datetime(1993, 9, 20, 6, 0)], '10458': [datetime.datetime(1993, 10, 4, 0, 0), datetime.datetime(1993, 10, 4, 6, 0)], '10463': [datetime.datetime(1993, 10, 7, 6, 0), datetime.datetime(1993, 10, 7, 12, 0)], '10466': [datetime.datetime(1993, 11, 1, 0, 0), datetime.datetime(1993, 11, 1, 6, 0)], '10473': [datetime.datetime(1993, 11, 18, 12, 0), datetime.datetime(1993, 11, 18, 18, 0)], '10474': [datetime.datetime(1993, 11, 20, 0, 0), datetime.datetime(1993, 11, 20, 6, 0)], '10476': [datetime.datetime(1993, 12, 5, 6, 0), datetime.datetime(1993, 12, 5, 12, 0)], '10478': [datetime.datetime(1993, 12, 9, 18, 0), datetime.datetime(1993, 12, 10, 0, 0)], '10481': [datetime.datetime(1993, 12, 26, 0, 0), datetime.datetime(1993, 12, 26, 6, 0)], '10485': [datetime.datetime(1994, 1, 5, 12, 0), datetime.datetime(1994, 1, 5, 18, 0)], '10511': [datetime.datetime(1994, 4, 3, 18, 0), datetime.datetime(1994, 4, 4, 0, 0)], '10517': [datetime.datetime(1994, 5, 24, 0, 0), datetime.datetime(1994, 5, 24, 6, 0)], '10520': [datetime.datetime(1994, 6, 22, 12, 0), datetime.datetime(1994, 6, 22, 18, 0)], '10524': [datetime.datetime(1994, 7, 1, 18, 0), datetime.datetime(1994, 7, 2, 0, 0)], '10532': [datetime.datetime(1994, 7, 19, 0, 0), datetime.datetime(1994, 7, 19, 6, 0)], '10553': [datetime.datetime(1994, 8, 24, 12, 0), datetime.datetime(1994, 8, 24, 18, 0)], '10563': [datetime.datetime(1994, 9, 10, 0, 0), datetime.datetime(1994, 9, 10, 6, 0)], '10583': [datetime.datetime(1994, 10, 20, 18, 0), datetime.datetime(1994, 10, 21, 0, 0)], '10595': [datetime.datetime(1994, 12, 21, 12, 0), datetime.datetime(1994, 12, 21, 18, 0)], '10625': [datetime.datetime(1995, 6, 1, 12, 0), datetime.datetime(1995, 6, 1, 18, 0)], '10635': [datetime.datetime(1995, 7, 27, 0, 0), datetime.datetime(1995, 7, 27, 6, 0)], '10645': [datetime.datetime(1995, 8, 13, 6, 0)], '10657': [datetime.datetime(1995, 9, 3, 18, 0), datetime.datetime(1995, 9, 4, 0, 0)], '10659': [datetime.datetime(1995, 9, 7, 0, 0), datetime.datetime(1995, 9, 7, 6, 0)], '10661': [datetime.datetime(1995, 9, 11, 18, 0), datetime.datetime(1995, 9, 12, 0, 0)], '10668': [datetime.datetime(1995, 9, 25, 6, 0), datetime.datetime(1995, 9, 25, 12, 0)], '10669': [datetime.datetime(1995, 9, 29, 6, 0), datetime.datetime(1995, 9, 29, 12, 0)], '10674': [datetime.datetime(1995, 10, 3, 6, 0)], '10675': [datetime.datetime(1995, 10, 7, 6, 0), datetime.datetime(1995, 10, 7, 12, 0)], '10681': [datetime.datetime(1995, 10, 23, 6, 0), datetime.datetime(1995, 10, 23, 12, 0)], '10682': [datetime.datetime(1995, 11, 2, 6, 0), datetime.datetime(1995, 11, 2, 12, 0)], '10683': [datetime.datetime(1995, 10, 28, 0, 0), datetime.datetime(1995, 10, 28, 6, 0)], '10691': [datetime.datetime(1995, 12, 4, 6, 0), datetime.datetime(1995, 12, 4, 12, 0)], '10713': [datetime.datetime(1996, 2, 29, 6, 0), datetime.datetime(1996, 2, 29, 12, 0)], '10721': [datetime.datetime(1996, 4, 6, 18, 0), datetime.datetime(1996, 4, 7, 0, 0)], '10758': [datetime.datetime(1996, 8, 19, 12, 0), datetime.datetime(1996, 8, 19, 18, 0)], '10788': [datetime.datetime(1996, 10, 17, 12, 0), datetime.datetime(1996, 10, 17, 18, 0)], '10789': [datetime.datetime(1996, 10, 11, 18, 0), datetime.datetime(1996, 10, 12, 0, 0)], '10799': [datetime.datetime(1996, 11, 5, 18, 0), datetime.datetime(1996, 11, 6, 0, 0)], '10805': [datetime.datetime(1996, 11, 8, 0, 0), datetime.datetime(1996, 11, 8, 6, 0)], '10810': [datetime.datetime(1996, 12, 1, 6, 0), datetime.datetime(1996, 12, 1, 12, 0)], '10853': [datetime.datetime(1997, 5, 26, 0, 0), datetime.datetime(1997, 5, 26, 6, 0)], '10916': [datetime.datetime(1997, 10, 19, 18, 0), datetime.datetime(1997, 10, 20, 0, 0)], '10921': [datetime.datetime(1997, 10, 29, 12, 0), datetime.datetime(1997, 10, 29, 18, 0)], '10928': [datetime.datetime(1997, 11, 16, 6, 0), datetime.datetime(1997, 11, 16, 12, 0)], '10980': [datetime.datetime(1998, 8, 7, 18, 0), datetime.datetime(1998, 8, 8, 0, 0)], '10999': [datetime.datetime(1998, 9, 18, 12, 0), datetime.datetime(1998, 9, 18, 18, 0)], '11016': [datetime.datetime(1998, 10, 14, 0, 0), datetime.datetime(1998, 10, 14, 6, 0)], '11020': [datetime.datetime(1998, 10, 21, 6, 0), datetime.datetime(1998, 10, 21, 12, 0)], '11035': [datetime.datetime(1998, 12, 10, 6, 0), datetime.datetime(1998, 12, 10, 12, 0)], '11039': [datetime.datetime(1998, 12, 17, 0, 0)], '11071': [datetime.datetime(1999, 4, 9, 18, 0), datetime.datetime(1999, 4, 10, 0, 0)], '11073': [datetime.datetime(1999, 4, 21, 0, 0)], '11106': [datetime.datetime(1999, 8, 20, 0, 0), datetime.datetime(1999, 8, 20, 6, 0)], '11128': [datetime.datetime(1999, 10, 5, 0, 0), datetime.datetime(1999, 10, 5, 6, 0)], '11133': [datetime.datetime(1999, 10, 15, 18, 0), datetime.datetime(1999, 10, 16, 0, 0)], '11139': [datetime.datetime(1999, 11, 8, 0, 0), datetime.datetime(1999, 11, 8, 6, 0)], '11178': [datetime.datetime(2000, 5, 17, 12, 0), datetime.datetime(2000, 5, 17, 18, 0)], '11188': [datetime.datetime(2000, 7, 4, 12, 0), datetime.datetime(2000, 7, 4, 18, 0)], '11191': [datetime.datetime(2000, 7, 14, 0, 0), datetime.datetime(2000, 7, 14, 6, 0)], '11194': [datetime.datetime(2000, 7, 22, 18, 0), datetime.datetime(2000, 7, 23, 0, 0)], '11224': [datetime.datetime(2000, 9, 11, 0, 0), datetime.datetime(2000, 9, 11, 6, 0)], '11245': [datetime.datetime(2000, 10, 27, 12, 0), datetime.datetime(2000, 10, 27, 18, 0)], '11249': [datetime.datetime(2000, 11, 2, 0, 0), datetime.datetime(2000, 11, 2, 6, 0)], '11254': [datetime.datetime(2000, 11, 29, 18, 0), datetime.datetime(2000, 11, 30, 0, 0)], '11268': [datetime.datetime(2001, 2, 18, 0, 0), datetime.datetime(2001, 2, 18, 6, 0)], '11281': [datetime.datetime(2001, 5, 7, 12, 0), datetime.datetime(2001, 5, 7, 18, 0)], '11350': [datetime.datetime(2001, 11, 6, 12, 0), datetime.datetime(2001, 11, 6, 18, 0)], '11360': [datetime.datetime(2001, 12, 5, 0, 0), datetime.datetime(2001, 12, 5, 6, 0)], '11382': [datetime.datetime(2002, 3, 21, 6, 0), datetime.datetime(2002, 3, 21, 12, 0)], '11406': [datetime.datetime(2002, 7, 18, 18, 0), datetime.datetime(2002, 7, 19, 0, 0)], '11416': [datetime.datetime(2002, 8, 13, 0, 0), datetime.datetime(2002, 8, 13, 6, 0)], '11496': [datetime.datetime(2003, 5, 26, 18, 0), datetime.datetime(2003, 5, 27, 0, 0)], '11508': [datetime.datetime(2003, 7, 22, 0, 0), datetime.datetime(2003, 7, 22, 6, 0)], '11509': [datetime.datetime(2003, 7, 16, 18, 0), datetime.datetime(2003, 7, 17, 0, 0)], '11520': [datetime.datetime(2003, 8, 22, 6, 0), datetime.datetime(2003, 8, 22, 12, 0)], '11554': [datetime.datetime(2003, 10, 23, 12, 0), datetime.datetime(2003, 10, 23, 18, 0)], '11556': [datetime.datetime(2003, 10, 31, 18, 0), datetime.datetime(2003, 11, 1, 0, 0)], '11559': [datetime.datetime(2003, 11, 13, 12, 0), datetime.datetime(2003, 11, 13, 18, 0)], '11567': [datetime.datetime(2003, 12, 27, 12, 0), datetime.datetime(2003, 12, 27, 18, 0)], '11591': [datetime.datetime(2004, 5, 16, 18, 0), datetime.datetime(2004, 5, 17, 0, 0)], '11597': [datetime.datetime(2004, 6, 9, 0, 0), datetime.datetime(2004, 6, 9, 6, 0)], '11660': [datetime.datetime(2004, 11, 19, 12, 0), datetime.datetime(2004, 11, 19, 18, 0)], '11694': [datetime.datetime(2005, 3, 16, 12, 0), datetime.datetime(2005, 3, 16, 18, 0)], '11775': [datetime.datetime(2005, 11, 10, 12, 0), datetime.datetime(2005, 11, 10, 18, 0)], '11776': [datetime.datetime(2005, 11, 20, 0, 0), datetime.datetime(2005, 11, 20, 6, 0)], '11785': [datetime.datetime(2005, 12, 15, 18, 0), datetime.datetime(2005, 12, 16, 0, 0)], '11810': [datetime.datetime(2006, 5, 11, 12, 0), datetime.datetime(2006, 5, 11, 18, 0)], '11814': [datetime.datetime(2006, 6, 24, 12, 0), datetime.datetime(2006, 6, 24, 18, 0)], '11826': [datetime.datetime(2006, 7, 31, 6, 0), datetime.datetime(2006, 7, 31, 12, 0)], '11861': [datetime.datetime(2006, 9, 27, 6, 0), datetime.datetime(2006, 9, 27, 12, 0)], '11872': [datetime.datetime(2006, 10, 29, 12, 0), datetime.datetime(2006, 10, 29, 18, 0)], '11875': [datetime.datetime(2006, 11, 10, 18, 0), datetime.datetime(2006, 11, 11, 0, 0)], '11880': [datetime.datetime(2006, 11, 30, 0, 0), datetime.datetime(2006, 11, 30, 6, 0)], '11883': [datetime.datetime(2006, 12, 9, 0, 0), datetime.datetime(2006, 12, 9, 6, 0)], '11965': [datetime.datetime(2007, 11, 4, 12, 0), datetime.datetime(2007, 11, 4, 18, 0)], '11971': [datetime.datetime(2007, 11, 19, 0, 0), datetime.datetime(2007, 11, 19, 6, 0)], '11972': [datetime.datetime(2007, 11, 25, 18, 0), datetime.datetime(2007, 11, 26, 0, 0)], '11983': [datetime.datetime(2008, 1, 12, 6, 0)], '11999': [datetime.datetime(2008, 4, 13, 0, 0), datetime.datetime(2008, 4, 13, 6, 0)], '12005': [datetime.datetime(2008, 5, 17, 6, 0), datetime.datetime(2008, 5, 17, 12, 0)], '12012': [datetime.datetime(2008, 6, 20, 0, 0), datetime.datetime(2008, 6, 20, 6, 0)], '12052': [datetime.datetime(2008, 9, 30, 12, 0), datetime.datetime(2008, 9, 30, 18, 0)], '12068': [datetime.datetime(2008, 11, 5, 12, 0), datetime.datetime(2008, 11, 5, 18, 0)], '12072': [datetime.datetime(2008, 11, 14, 18, 0)], '12103': [datetime.datetime(2009, 5, 1, 0, 0), datetime.datetime(2009, 5, 1, 6, 0)], '12104': [datetime.datetime(2009, 5, 7, 6, 0), datetime.datetime(2009, 5, 7, 12, 0)], '12107': [datetime.datetime(2009, 6, 15, 12, 0), datetime.datetime(2009, 6, 15, 18, 0)], '12110': [datetime.datetime(2009, 6, 23, 6, 0), datetime.datetime(2009, 6, 23, 12, 0)], '12150': [datetime.datetime(2009, 9, 26, 0, 0), datetime.datetime(2009, 9, 26, 6, 0)], '12153': [datetime.datetime(2009, 10, 3, 0, 0), datetime.datetime(2009, 10, 3, 6, 0)], '12164': [datetime.datetime(2009, 10, 30, 12, 0), datetime.datetime(2009, 10, 30, 18, 0)], '12170': [datetime.datetime(2009, 11, 24, 12, 0), datetime.datetime(2009, 11, 24, 18, 0)], '12213': [datetime.datetime(2010, 7, 13, 12, 0), datetime.datetime(2010, 7, 13, 18, 0)], '12215': [datetime.datetime(2010, 7, 18, 0, 0), datetime.datetime(2010, 7, 18, 6, 0)], '12249': [datetime.datetime(2010, 10, 18, 0, 0), datetime.datetime(2010, 10, 18, 6, 0)], '12290': [datetime.datetime(2011, 5, 7, 18, 0), datetime.datetime(2011, 5, 8, 0, 0)], '12294': [datetime.datetime(2011, 6, 8, 0, 0)], '12308': [datetime.datetime(2011, 7, 25, 18, 0), datetime.datetime(2011, 7, 26, 0, 0)], '12339': [datetime.datetime(2011, 9, 26, 18, 0), datetime.datetime(2011, 9, 27, 0, 0)], '12341': [datetime.datetime(2011, 10, 1, 0, 0), datetime.datetime(2011, 10, 1, 6, 0)], '12345': [datetime.datetime(2011, 10, 11, 6, 0), datetime.datetime(2011, 10, 11, 12, 0)], '12358': [datetime.datetime(2011, 12, 16, 6, 0), datetime.datetime(2011, 12, 16, 12, 0)], '12408': [datetime.datetime(2012, 8, 14, 18, 0), datetime.datetime(2012, 8, 15, 0, 0)], '12439': [datetime.datetime(2012, 10, 24, 0, 0), datetime.datetime(2012, 10, 24, 6, 0)], '12448': [datetime.datetime(2012, 12, 3, 18, 0), datetime.datetime(2012, 12, 4, 0, 0)], '12452': [datetime.datetime(2012, 12, 25, 12, 0), datetime.datetime(2012, 12, 25, 18, 0)], '12456': [datetime.datetime(2013, 1, 2, 12, 0), datetime.datetime(2013, 1, 2, 18, 0)], '12485': [datetime.datetime(2013, 6, 28, 18, 0), datetime.datetime(2013, 6, 29, 0, 0)], '12490': [datetime.datetime(2013, 7, 16, 18, 0), datetime.datetime(2013, 7, 17, 0, 0)], '12498': [datetime.datetime(2013, 8, 11, 18, 0), datetime.datetime(2013, 8, 12, 0, 0)], '12531': [datetime.datetime(2013, 10, 11, 12, 0), datetime.datetime(2013, 10, 11, 18, 0)], '12541': [datetime.datetime(2013, 10, 31, 6, 0), datetime.datetime(2013, 10, 31, 12, 0)], '12542': [datetime.datetime(2013, 11, 4, 0, 0), datetime.datetime(2013, 11, 4, 6, 0)], '12544': [datetime.datetime(2013, 11, 7, 18, 0), datetime.datetime(2013, 11, 8, 0, 0)], '12546': [datetime.datetime(2013, 11, 12, 0, 0), datetime.datetime(2013, 11, 12, 6, 0)], '12566': [datetime.datetime(2014, 1, 31, 12, 0), datetime.datetime(2014, 1, 31, 18, 0)], '12580': [datetime.datetime(2014, 3, 22, 6, 0), datetime.datetime(2014, 3, 22, 12, 0)], '12600': [datetime.datetime(2014, 7, 15, 6, 0), datetime.datetime(2014, 7, 15, 12, 0)], '12624': [datetime.datetime(2014, 9, 14, 6, 0), datetime.datetime(2014, 9, 14, 12, 0)], '12627': [datetime.datetime(2014, 9, 19, 0, 0), datetime.datetime(2014, 9, 19, 6, 0)], '12645': [datetime.datetime(2014, 11, 26, 6, 0), datetime.datetime(2014, 11, 26, 12, 0)], '12646': [datetime.datetime(2014, 12, 6, 12, 0), datetime.datetime(2014, 12, 6, 18, 0)], '12649': [datetime.datetime(2014, 12, 28, 18, 0), datetime.datetime(2014, 12, 29, 0, 0)], '12651': [datetime.datetime(2015, 1, 17, 6, 0), datetime.datetime(2015, 1, 17, 12, 0)], '12669': [datetime.datetime(2015, 4, 5, 0, 0), datetime.datetime(2015, 4, 5, 6, 0)], '12688': [datetime.datetime(2015, 7, 4, 18, 0), datetime.datetime(2015, 7, 5, 0, 0)], '12733': [datetime.datetime(2015, 10, 1, 12, 0), datetime.datetime(2015, 10, 1, 18, 0)], '12738': [datetime.datetime(2015, 10, 17, 18, 0), datetime.datetime(2015, 10, 18, 0, 0)], '12754': [datetime.datetime(2015, 12, 14, 6, 0), datetime.datetime(2015, 12, 14, 12, 0)], '12836': [datetime.datetime(2016, 10, 15, 18, 0), datetime.datetime(2016, 10, 16, 0, 0)], '12837': [datetime.datetime(2016, 10, 19, 12, 0), datetime.datetime(2016, 10, 19, 18, 0)], '12846': [datetime.datetime(2016, 11, 24, 12, 0), datetime.datetime(2016, 11, 24, 18, 0)], '12852': [datetime.datetime(2016, 12, 25, 12, 0), datetime.datetime(2016, 12, 25, 18, 0)]}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "'''\n",
    "Probability of landfall in GD and PHI \n",
    "'''\n",
    "tic = time.time() #WARNING: Expected runtime ~30min\n",
    "\n",
    "#Creates a dictionary recording data\n",
    "def landfall_probability(area, source):\n",
    "    yeardict = {}\n",
    "    yeardicttotal = {}\n",
    "    \n",
    "    if source == 0:\n",
    "        startyear = 1945\n",
    "    elif source == 1:\n",
    "        startyear = 1949\n",
    "    elif source == 2: \n",
    "        startyear = 1951\n",
    "        \n",
    "    for i in range(startyear, 2017): #No data before startyear, and 2017 data not complete\n",
    "        yeardict[str(i)] = []\n",
    "        yeardicttotal[str(i)] = []\n",
    "    for tcindex in range(len(list(season))):\n",
    "        if tcindex%100 == 0: #Just to check whether code is running + progress\n",
    "            print(tcindex)\n",
    "        i = list(season)[tcindex] #i is the year\n",
    "        if i in list(range(startyear,2017)):\n",
    "            yeardicttotal[str(i)].append(tcindex)\n",
    "            if area == 0:\n",
    "                if source == 0:\n",
    "                    if str(tcindex) in landfalldata_coord_PHI_jtwc.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 1:\n",
    "                    if str(tcindex) in landfalldata_coord_PHI_cma.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 2:\n",
    "                    if str(tcindex) in landfalldata_coord_PHI_wmo.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "            else:\n",
    "                if source == 0:\n",
    "                    if str(tcindex) in landfalldata_coord_GD_jtwc.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 1:\n",
    "                    if str(tcindex) in landfalldata_coord_GD_cma.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 2:\n",
    "                    if str(tcindex) in landfalldata_coord_GD_wmo.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "\n",
    "    landfall_number_list = []\n",
    "    landfall_number_list_total = []\n",
    "    landfall_counts = {}\n",
    "    landfall_counts_total = {}\n",
    "    for year in yeardict.keys():\n",
    "        landfall_number_list.append(len(yeardict[year])) #Append the number of landfalls in year\n",
    "#        landfall_number_list_total.append(len(yeardicttotal[year]))\n",
    "    for n in range(max(landfall_number_list)+1):\n",
    "        landfall_counts[str(n)] = landfall_number_list.count(n)\n",
    "#        landfall_counts_total[str(n)] = landfall_number_list_total.count(n)\n",
    "        \n",
    "#     print(yeardict, landfall_number_list)\n",
    "    return landfall_counts #, yeardict, yeardicttotal\n",
    "    \n",
    "landfall_no_PHI_jtwc = landfall_probability(0,0)\n",
    "landfall_no_PHI_cma = landfall_probability(0,1)\n",
    "landfall_no_PHI_wmo = landfall_probability(0,2)\n",
    "landfall_no_GD_jtwc = landfall_probability(1,0)\n",
    "landfall_no_GD_cma = landfall_probability(1,1)\n",
    "landfall_no_GD_wmo = landfall_probability(1,2)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(landfall_no_PHI_wmo)\n",
    "print(landfall_no_GD_wmo)\n",
    "'''\n",
    "No. of landfalls in each year:\n",
    "PHI WMO:[6, 9, 5, 6, 3, 7, 6, 3, 5, 5, 2, 6, 5, 13, 4, 4, 7, 6, 3, 9, 13, 7, 5, \n",
    "11, 3, 4, 5, 6, 6, 6, 7, 8, 5, 3, 5, 8, 5, 8, 8, 4, 8, 4, 10, 6, 7, 5, 2, 6, 5, \n",
    "5, 3, 0, 6, 4, 3, 9, 4, 5, 7, 3, 6, 3, 9, 7, 7, 4]\n",
    "\n",
    "GD WMO: [2, 3, 2, 3, 1, 0, 5, 2, 2, 3, 6, 2, 2, 6, 4, 3, 5, 3, 1, 4, 4, 2, 3, \n",
    "3, 5, 4, 1, 3, 4, 2, 3, 3, 4, 4, 3, 4, 2, 4, 2, 3, 4, 3, 6, 3, 6, 1, 2, 1, 6, \n",
    "1, 4, 4, 3, 2, 1, 3, 1, 6, 5, 3, 2, 3, 3, 3, 2, 2]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_func(x,mu): #Define Poisson distribution for curve fitting\n",
    "    P = np.exp(-mu) * mu**x/factorial(x)\n",
    "    return P\n",
    "\n",
    "#Plot landfall probability\n",
    "def landfall_prob_plot(area, source):\n",
    "    plt.figure()\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            keys = landfall_no_PHI_jtwc.keys()\n",
    "            values = landfall_no_PHI_jtwc.values()\n",
    "            startyear = 1945 #Year which data starts to exist\n",
    "        elif source == 1:\n",
    "            keys = landfall_no_PHI_cma.keys()\n",
    "            values = landfall_no_PHI_cma.values()\n",
    "            startyear = 1949\n",
    "        elif source == 2:\n",
    "            keys = landfall_no_PHI_wmo.keys()\n",
    "            values = landfall_no_PHI_wmo.values()\n",
    "            startyear = 1951\n",
    "    else: \n",
    "        if source == 0:\n",
    "            keys = landfall_no_GD_jtwc.keys()\n",
    "            values = landfall_no_GD_jtwc.values()\n",
    "            startyear = 1945\n",
    "        elif source == 1:\n",
    "            keys = landfall_no_GD_cma.keys()\n",
    "            values = landfall_no_GD_cma.values()\n",
    "            startyear = 1949\n",
    "        elif source == 2:\n",
    "            keys = landfall_no_GD_wmo.keys()\n",
    "            values = landfall_no_GD_wmo.values()\n",
    "            startyear = 1951\n",
    "            \n",
    "    plt.xlabel('Number of landfalls per year')  \n",
    "    plt.ylabel('Probability') #(number of years/total number of years)')\n",
    "        \n",
    "    prob = np.asarray(list(values)) / (2017 - startyear)\n",
    "    k = np.asarray(list(keys),dtype=int)\n",
    "    plt.scatter(k, prob,color = 'r')\n",
    "    thesum = 0\n",
    "    for i in range(len(values)):\n",
    "        thesum += np.asarray(list(keys),dtype=int)[i]*list(values)[i]\n",
    "        \n",
    "    mu = thesum / (2017-startyear)\n",
    "#    mu = curve_fit(poisson_func,k,prob)[0][0]\n",
    "\n",
    "    pmf = poisson.pmf(k,mu) #Plot Poisson distribution\n",
    "    \n",
    "    chisq, pvalue = chisquare(np.array(list(values)),pmf*(2017 - startyear),ddof=1) #Find chi-sq and p-value using chi-square test\n",
    "#    print(chisq, pvalue)\n",
    "#    print(list(values))\n",
    "#    print(pmf*sum(list(values)))\n",
    "#    print(prob, pmf)\n",
    "    rmserr = np.sqrt(mean_squared_error(prob, pmf))\n",
    "\n",
    "    plt.plot(k,pmf,color='b')\n",
    "    \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Probability of typhoons with landfalls in the Philippines \\n source: JTWC, sample size = ' + str(thesum) + '\\n mean = ' + str(mu) + ', RMS error = ' + str(rmserr))\n",
    "        elif source == 1:\n",
    "            plt.title('Probability of typhoons with landfalls in the Philippines \\n source: CMA, sample size = ' + str(thesum) + '\\n mean = ' + str(mu) + ', RMS error = ' + str(rmserr))\n",
    "        elif source == 2:\n",
    "            plt.title('Probability of typhoons with landfalls in the Philippines \\n source: WMO, sample size = ' + str(thesum) + '\\n mean = ' + str(mu) + ', RMS error = ' + str(rmserr))\n",
    "\n",
    "\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Probability of typhoons with landfalls in Guangdong \\n source: JTWC, sample size = ' + str(thesum) + '\\n mean = ' + str(mu) + ', RMS error = ' + str(rmserr))\n",
    "        elif source == 1:\n",
    "            plt.title('Probability of typhoons with landfalls in Guangdong \\n source: CMA, sample size = ' + str(thesum) + '\\n mean = ' + str(mu) + ', RMS error = ' + str(rmserr))\n",
    "        elif source == 2:\n",
    "            plt.title('Probability of typhoons with landfalls in Guangdong \\n source: WMO, sample size = ' + str(thesum) + '\\n mean = ' + str(mu) + ', RMS error = ' + str(rmserr))\n",
    "\n",
    "tic = time.time()\n",
    "            \n",
    "landfall_prob_plot(0,0)\n",
    "landfall_prob_plot(0,1)\n",
    "landfall_prob_plot(0,2)\n",
    "landfall_prob_plot(1,0)\n",
    "landfall_prob_plot(1,1)\n",
    "landfall_prob_plot(1,2)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get daily rainfall amount from .nc file\n",
    "def getfile(tcindex, area):\n",
    "    filedirectory = 'IMERG/'+ str(tcindex) + str(area)\n",
    "\n",
    "    totalprecipitation = np.zeros((450,379))\n",
    "    \n",
    "    #Sum daily rainfall amount from each file\n",
    "    for file in os.listdir(filedirectory):\n",
    "        if file.endswith('.nc'):\n",
    "            nc_imerg = 'IMERG/' + str(tcindex) + str(area) + '/' + file\n",
    "            imerg = Dataset(nc_imerg)\n",
    "\n",
    "            precipitationCal = imerg.variables['precipitationCal'][:] #Rainfall\n",
    "            lat_rainfall = imerg.variables['lat'][:] #Latitude range\n",
    "            lon_rainfall = imerg.variables['lon'][:] #Longitude range\n",
    "            totalprecipitation += precipitationCal\n",
    "        \n",
    "    return totalprecipitation, lat_rainfall, lon_rainfall\n",
    "\n",
    "lat_rainfall = getfile(12733,1)[1]\n",
    "lon_rainfall = getfile(12733,1)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time() #Expected runtime ~15s\n",
    "\n",
    "#Generate land mask for plotting rainfall contour map\n",
    "def land_rainfall_contour(area):\n",
    "    \n",
    "    if area == 0:\n",
    "        z_land_coord = z_land_coord_PHI\n",
    "    else:\n",
    "        extremeG_N = [118.3, 28.3]\n",
    "        extremeG_S = [107.4, 18.9]\n",
    "        extremeG_E = [120.0, 23.5]\n",
    "        extremeG_W = [105.7, 25.5]\n",
    "\n",
    "        m_top_G = (extremeG_N[1]-extremeG_W[1])/(extremeG_N[0]-extremeG_W[0])\n",
    "        m_bot_G = (extremeG_S[1]-extremeG_E[1])/(extremeG_S[0]-extremeG_E[0])\n",
    "        m_left_G = (extremeG_S[1]-extremeG_W[1])/(extremeG_S[0]-extremeG_W[0])\n",
    "        m_right_G = (extremeG_N[1]-extremeG_E[1])/(extremeG_N[0]-extremeG_E[0])\n",
    "\n",
    "        c_top_G = extremeG_N[1]-m_top_G*extremeG_N[0]\n",
    "        c_bot_G = extremeG_S[1]-m_bot_G*extremeG_S[0]\n",
    "        c_left_G = extremeG_S[1]-m_left_G*extremeG_S[0]\n",
    "        c_right_G = extremeG_N[1]-m_right_G*extremeG_N[0]\n",
    "\n",
    "        landmask_points = []\n",
    "\n",
    "        for i in range(17100,18100): \n",
    "#             if i%50 == 0:\n",
    "#                 print(i)\n",
    "            for i2 in range(6500,7150):\n",
    "                equation_top = m_top_G * landmask_LON[i,i2] + c_top_G\n",
    "                equation_bot = m_bot_G * landmask_LON[i,i2] + c_bot_G \n",
    "                equation_left = m_left_G * landmask_LON[i,i2] + c_left_G\n",
    "                equation_right  = m_right_G * landmask_LON[i,i2] + c_right_G\n",
    "\n",
    "                if landmask_LAT[i,i2] <= equation_top and landmask_LAT[i,i2] <= equation_right and landmask_LAT[i,i2] >= equation_bot and landmask_LAT[i,i2] >= equation_left:\n",
    "                    landmask_points.append(i)\n",
    "                    landmask_points.append(i2)\n",
    "        \n",
    "        landmask_points = np.asarray(landmask_points)\n",
    "        landmask_points = landmask_points.reshape(int(len(landmask_points)/2),2)\n",
    "        \n",
    "        \n",
    "        z_land = []\n",
    "        for i in range(len(landmask_points)):\n",
    "#             if i%50 == 0:\n",
    "#                 print(i)\n",
    "            if z[landmask_points[i,1],landmask_points[i,0]] >= 0:\n",
    "                z_land.append(landmask_points[i,0])\n",
    "                z_land.append(landmask_points[i,1])\n",
    "\n",
    "        z_land = np.asarray(z_land).reshape(int(len(z_land)/2),2)\n",
    "\n",
    "        z_land_coord = np.zeros(z_land.shape)\n",
    "        z_land_coord[:,0] = landmask_lon[z_land[:,0]]\n",
    "        z_land_coord[:,1] = landmask_lat[z_land[:,1]]\n",
    "    \n",
    "        \n",
    "    return z_land_coord\n",
    "\n",
    "landforrainfall_PHI = land_rainfall_contour(0) #Generate for PHI\n",
    "landforrainfall_GD = land_rainfall_contour(1) #Generate for GD\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "#Plot rainfall contour\n",
    "def rainfall_contour(tcindex, area, source):\n",
    "    totalprecipitation, lat_rainfall, lon_rainfall = getfile(tcindex, area)\n",
    "    LATrainfall, LONrainfall = np.meshgrid(lat_rainfall,lon_rainfall)\n",
    "    \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            coords = landfalldata_coord_PHI2014_jtwc[str(tcindex)] #TC coord (before & after)\n",
    "        elif source == 1:\n",
    "            coords = landfalldata_coord_PHI2014_cma[str(tcindex)]\n",
    "        elif source == 2:\n",
    "            coords = landfalldata_coord_PHI2014_wmo[str(tcindex)]\n",
    "    else:\n",
    "        if source == 0:\n",
    "            coords = landfalldata_coord_GD2014_jtwc[str(tcindex)] #TC coord (before & after)\n",
    "        elif source == 1:\n",
    "            coords = landfalldata_coord_GD2014_cma[str(tcindex)]\n",
    "        elif source == 2:\n",
    "            coords = landfalldata_coord_GD2014_wmo[str(tcindex)]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(landforrainfall_PHI[:,0],landforrainfall_PHI[:,1],color='k',alpha=0.6)\n",
    "    plt.scatter(landforrainfall_GD[:,0],landforrainfall_GD[:,1],color='k', alpha=0.6)\n",
    "\n",
    "    plt.contourf(LONrainfall, LATrainfall, totalprecipitation, cmap = 'jet', alpha=0.6) #Contour plot of rainfall\n",
    "    plt.colorbar()\n",
    "    plt.scatter(coords[:,1],coords[:,0],color='r', alpha= 0.5)\n",
    "    \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall contour map of ' + str(tcindex) + ' when it makes landfall in the Philippines \\n source: JTWC')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall contour map of ' + str(tcindex) + ' when it makes landfall in the Philippines \\n source: CMA')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall contour map of ' + str(tcindex) + ' when it makes landfall in the Philippines \\n source: WMO')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall contour map of ' + str(tcindex) + ' when it makes landfall in Guangdong \\n source: JTWC')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall contour map of ' + str(tcindex) + ' when it makes landfall in Guangdong \\n source: CMA')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall contour map of ' + str(tcindex) + ' when it makes landfall in Guangdong \\n source: WMO')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     ax.plot_surface(LONrainfall,LATrainfall,totalprecipitation)\n",
    "    \n",
    "rainfall_contour(12862,0,1)\n",
    "rainfall_contour(12862,1,1)\n",
    "\n",
    "toc=time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rainfall distribution within (radius)km of TC centre\n",
    "def rainfall_distribution(area, source, tcindex, only_on_land = False, radius = 500):\n",
    "    totalprecipitation, lat_rainfall, lon_rainfall = getfile(tcindex, area)\n",
    "    epsilon = 1e-5 #Very small number to compare numbers with rounding error\n",
    "    dist_list = []\n",
    "    rainfall_list = []\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            coords = landfalldata_coord_PHI2014_jtwc[str(tcindex)]\n",
    "        elif source == 1:\n",
    "            coords = landfalldata_coord_PHI2014_cma[str(tcindex)]\n",
    "        elif source == 2:\n",
    "            coords = landfalldata_coord_PHI2014_wmo[str(tcindex)]            \n",
    "        land = landforrainfall_PHI\n",
    "    else:\n",
    "        if source == 0:\n",
    "            coords = landfalldata_coord_GD2014_jtwc[str(tcindex)]\n",
    "        elif source == 1:\n",
    "            coords = landfalldata_coord_GD2014_cma[str(tcindex)]\n",
    "        elif source == 2:\n",
    "            coords = landfalldata_coord_GD2014_wmo[str(tcindex)]\n",
    "        land = landforrainfall_GD\n",
    "    landfall_coords_lon = coords[1][1]\n",
    "    landfall_coords_lat = coords[1][0]\n",
    "    for i in range(len(totalprecipitation)):\n",
    "        for j in range(len(totalprecipitation[0])):\n",
    "            rainfall_lat = lat_rainfall[j]\n",
    "            rainfall_lon = lon_rainfall[i]\n",
    "            dist = gd.geodesic([rainfall_lat, rainfall_lon],[landfall_coords_lat, landfall_coords_lon]).km\n",
    "            if dist <= radius:\n",
    "                if only_on_land == False:\n",
    "                    dist_list.append(dist)\n",
    "                    rainfall_list.append(totalprecipitation[i,j])\n",
    "                else:\n",
    "                    #Find all land points with same latitude\n",
    "                    landpoint_onlat_temp1 = np.where(land[:,1] <= rainfall_lat + epsilon)\n",
    "                    landpoint_onlat_temp2 = np.where(land[:,1] >= rainfall_lat - epsilon)\n",
    "                    landpoint_onlat_index = np.intersect1d(landpoint_onlat_temp1,landpoint_onlat_temp2) #Index of points in landmask array where latitude is same as TClat\n",
    "                    landpoint_onlat_lon = land[landpoint_onlat_index,0] #Lon of landmask points with same lat as TClat\n",
    "\n",
    "                    if landpoint_onlat_lon.size != 0:\n",
    "                        landpoint_onlat_maxlon = max(landpoint_onlat_lon) #Find easternmost land point on same latitude\n",
    "                        landpoint_onlat_minlon = min(landpoint_onlat_lon) #Find westernmost land point on same latitude\n",
    "\n",
    "                        #Check whether TC is on land or ocean\n",
    "                        if landpoint_onlat_minlon-epsilon <= rainfall_lon <= landpoint_onlat_maxlon+epsilon:\n",
    "                            dist_list.append(dist)\n",
    "                            rainfall_list.append(totalprecipitation[i,j])\n",
    "                        \n",
    "    return dist_list, rainfall_list #Distance from TC centre, amount of rainfall\n",
    "\n",
    "#Plot the rainfall distribution of each point\n",
    "def plot_rainfall_distribution(area, source, tcindex, only_on_land = False):\n",
    "    dist_list, rainfall_list = rainfall_distribution(area, source, tcindex, only_on_land)\n",
    "    plt.figure()\n",
    "    if area == 0:\n",
    "        plt.title('Rainfall distribution of ' + str(tcindex) + ' in the Philippines')\n",
    "    else:\n",
    "        plt.title('Rainfall distribution of ' + str(tcindex) + ' in Guangdong')\n",
    "        \n",
    "    plt.xlabel('Distance to TC (km)')\n",
    "    plt.ylabel('Precipitation (mm)')\n",
    "    plt.scatter(dist_list, rainfall_list,color = 'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time() #Expected runtime ~50s\n",
    "#%matplotlib tk\n",
    "plot_rainfall_distribution(1,1,12862)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "#%matplotlib tk\n",
    "plot_rainfall_distribution(1,1,12862, True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input radii of 18m/s wind (R18) data, also known as radii of 34kts wind (R34)\n",
    "\n",
    "r18dict_GD_jtwc = {} #Values in nautical mile, change to km\n",
    "r18dict_GD_jtwc['11290'] = [] #Utor 2001, no data, from bwp0602001.txt\n",
    "r18dict_GD_jtwc['11298'] = []#[float((60+90+120+60)*1.852/4), 'no data']#Yutu 2001, from bwp102001.txt\n",
    "r18dict_GD_jtwc['11318'] = [float((70+70+40+40)*1.852/4), float((85+85+60+60)*1.852/4)] #Nari 2001, from bwp202001.txt\n",
    "r18dict_GD_jtwc['11410'] = [float((60+120+120+70)*1.852/4), float((70+120+120+70)*1.852/4)] #Kammuri 2002, from bwp162002.txt\n",
    "r18dict_GD_jtwc['11417'] = [float((60+70+70+60)*1.852/4), float((60+70+70+60)*1.852/4)] #Vongfong 2002, from bwp202002.txt\n",
    "r18dict_GD_jtwc['11431'] = [] #Hagupit 2002, no data, from bwp232002.txt\n",
    "r18dict_GD_jtwc['11508'] = []#[float((160+160+140+140)*1.852/4), 'no data'] #Imbudo 2003, from bwp092003.txt\n",
    "r18dict_GD_jtwc['11520'] = [float((120+105+100+105)*1.852/4), float((120+105+100+105)*1.852/4)] #Krovanh 2003, from bwp122003.txt\n",
    "r18dict_GD_jtwc['11528'] = [float((190+190+170+160)*1.852/4), float((170+170+145+135)*1.852/4)] #Dujuan 2003, from bwp142004.txt\n",
    "r18dict_GD_jtwc['11605'] = [float((40+40+40+40)*1.852/4), float((40+40+40+40)*1.852/4)] #Kompasu 2004, from bwp122004.txt\n",
    "r18dict_GD_jtwc['11623'] = [float((110+135+135+90)*1.852/4), float((110+135+135+90)*1.852/4)]#Aere 2004, from bwp202004.txt\n",
    "r18dict_GD_jtwc['11725'] = [float((80+80+75+70)*1.852/4), float((80+80+75+70)*1.852/4)] #Sanvu 2005, from bwp102005.txt\n",
    "r18dict_GD_jtwc['11810'] = [float((140+140+120+120)*1.852/4), float((140+140+120+100)*1.852/4)] #Chanchu 2006, from bwp022006.txt\n",
    "r18dict_GD_jtwc['11814'] = [] #Jelawat 2006, no data, from bwp032006.txt\n",
    "r18dict_GD_jtwc['11826'] = [float((140+120+120+105)*1.852/4), float((140+120+100+100)*1.852/4)] #Prapiroon 2006, from bwp072006.txt\n",
    "r18dict_GD_jtwc['11842'] = [] #TD0823 2006, no data, from bwp132006.txt\n",
    "r18dict_GD_jtwc['11850'] = [] #TD0912 2006, no data, from bwp152006.txt\n",
    "r18dict_GD_jtwc['11999'] = [float((70+70+60+60)*1.852/4), float((70+65+60+65)*1.852/4)] #Neoguri 2008, from bwp022008.txt\n",
    "r18dict_GD_jtwc['12012'] = [float((90+90+80+75)*1.852/4), float((90+90+80+75)*1.852/4)] #Fengshen 2008, from bwp072008.txt\n",
    "r18dict_GD_jtwc['12025'] = [float((90+75+75+85)*1.852/4), float((80+70+70+80)*1.852/4)] #Kamuri 2008, from bwp102008.txt\n",
    "r18dict_GD_jtwc['12034'] = [float((55+55+55+55)*1.852/4), float((55+55+55+55)*1.852/4)] #Nuri 2008, from bwp132008.txt\n",
    "r18dict_GD_jtwc['12048'] = [float((155+135+130+155)*1.852/4), float((155+135+130+155)*1.852/4)] #Hagupit 2008, from bwp182008.txt\n",
    "r18dict_GD_jtwc['12052'] = [] #Higos 2008, no data, from bwp212008.txt\n",
    "r18dict_GD_jtwc['12110'] = [] #Nangka 2009, no data, from bwp042009.txt\n",
    "r18dict_GD_jtwc['12114'] = [] #Soudelor 2009, no data, from bwp052009.txt\n",
    "r18dict_GD_jtwc['12118'] = [float((85+70+55+60)*1.852/4), float((85+70+55+60)*1.852/4)] #Molave 2009, from bwp072009.txt\n",
    "r18dict_GD_jtwc['12121'] = [] #Goni 2009, no data, from bwp082009.txt\n",
    "r18dict_GD_jtwc['12146'] = [float((130+75+95+80)*1.852/4), float((130+75+95+80)*1.852/4)] #Koppu 2009, from bwp162009.dat\n",
    "r18dict_GD_jtwc['12215'] = [float((105+95+75+95)*1.852/4), float((105+95+75+95)*1.852/4)] #Chanthu 2010, from bwp042010.txt\n",
    "r18dict_GD_jtwc['12238'] = [float((120+130+100+85)*1.852/4), float((120+130+100+85)*1.852/4)] #Fanapi 2010, from bwp122010.txt\n",
    "r18dict_GD_jtwc['12245'] = [] #Fourteen 2010, no data\n",
    "r18dict_GD_jtwc['12294'] = [] #Sarika 2011, no data\n",
    "r18dict_GD_jtwc['12296'] = [] #Haima 2011, no data\n",
    "r18dict_GD_jtwc['12393'] = []#[float((70+55+55+70)*1.852/4), 'no data'] #Doksuri 2012, from bwp072012.dat\n",
    "r18dict_GD_jtwc['12399'] = [float((110+95+95+119)*1.852/4), float((110+95+95+119)*1.852/4)] #Vincente 2012, from bwp092012.dat\n",
    "r18dict_GD_jtwc['12408'] = [float((80+70+70+90)*1.852/4), float((80+70+70+80)*1.852/4)] #Kai-tak 2012, from bwp142012.dat\n",
    "r18dict_GD_jtwc['12485'] = [float((70+65+60+60)*1.852/4), float((70+65+60+60)*1.852/4)] #Rumbia 2013, from bwp062013.dat\n",
    "r18dict_GD_jtwc['12498'] = [float((125+130+125+110)*1.852/4), float((125+130+125+110)*1.852/4)] #Utor 2013, from bwp112013.dat\n",
    "r18dict_GD_jtwc['12520'] = [float((155+140+160+165)*1.852/4), float((155+140+160+165)*1.852/4)] #Usagi 2013\n",
    "r18dict_GD_jtwc['12594'] = [float((90+90+80+80)*1.852/4), float((90+90+80+80)*1.852/4)] #Hagibis 2014, from bwp072014.dat\n",
    "r18dict_GD_jtwc['12600'] = [float((115+100+100+115)*1.852/4), float((115+100+100+115)*1.852/4)] #Rammasun 2014, from bwp092014.dat\n",
    "r18dict_GD_jtwc['12621'] = [] #Fourteen 2014, from bwp142014.dat, no data\n",
    "r18dict_GD_jtwc['12624'] = [float((155+150+140+150)*1.852/4), float((155+150+140+150)*1.852/4)] #Kalmaegi 2014, from bwp152014.dat\n",
    "r18dict_GD_jtwc['12688'] = [float((75+70+70+75)*1.852/4), float((75+60+60+75)*1.852/4)] #Linfa 2015, from bwp102015.dat\n",
    "r18dict_GD_jtwc['12733'] = [float((135+120+120+135)*1.852/4), float((135+120+120+135)*1.852/4)] #Mujigae 2015, from bwp222015.dat\n",
    "r18dict_GD_jtwc['12776'] = [] #TD0526 2016, from bwp012016.dat, no data\n",
    "r18dict_GD_jtwc['12793'] = [float((150+150+150+150)*1.852/4), float((150+150+150+130)*1.852/4)] #Nida 2016, from bwp062016.dat\n",
    "r18dict_GD_jtwc['12837'] = [float((150+120+120+150)*1.852/4), float((150+120+120+150)*1.852/4)] #Haima 2016, from bwp252016.dat\n",
    "r18dict_GD_jtwc['12861'] = [float((150+115+95+140)*1.852/4), float((100+100+95+95)*1.852/4)] #Hato 2017, from bwp152017.dat\n",
    "r18dict_GD_jtwc['12862'] = [] #Mangkhut 2018, no data\n",
    "\n",
    "r18dict_GD_jtwc_2014 = {}\n",
    "r18dict_GD_jtwc_2014['12594'] = [float((90+90+80+80)*1.852/4), float((90+90+80+80)*1.852/4)] #Hagibis 2014, from bwp072014.dat\n",
    "r18dict_GD_jtwc_2014['12600'] = [float((115+100+100+115)*1.852/4), float((115+100+100+115)*1.852/4)] #Rammasun 2014, from bwp092014.dat\n",
    "r18dict_GD_jtwc_2014['12621'] = [] #Fourteen 2014, from bwp142014.dat, no data\n",
    "r18dict_GD_jtwc_2014['12624'] = [float((155+150+140+150)*1.852/4), float((155+150+140+150)*1.852/4)] #Kalmaegi 2014, from bwp152014.dat\n",
    "r18dict_GD_jtwc_2014['12688'] = [float((75+70+70+75)*1.852/4), float((75+60+60+75)*1.852/4)] #Linfa 2015, from bwp102015.dat\n",
    "r18dict_GD_jtwc_2014['12733'] = [float((135+120+120+135)*1.852/4), float((135+120+120+135)*1.852/4)] #Mujigae 2015, from bwp222015.dat\n",
    "r18dict_GD_jtwc_2014['12776'] = [] #TD0526 2016, from bwp012016.dat, no data\n",
    "r18dict_GD_jtwc_2014['12793'] = [float((150+150+150+150)*1.852/4), float((150+150+150+130)*1.852/4)] #Nida 2016, from bwp062016.dat\n",
    "r18dict_GD_jtwc_2014['12837'] = [float((150+120+120+150)*1.852/4), float((150+120+120+150)*1.852/4)] #Haima 2016, from bwp252016.dat\n",
    "r18dict_GD_jtwc_2014['12861'] = [float((150+115+95+140)*1.852/4), float((100+100+95+95)*1.852/4)] #Hato 2017, from bwp152017.dat\n",
    "r18dict_GD_jtwc_2014['12862'] = [] #Mangkhut 2018, no data\n",
    "\n",
    "r18dict_GD_cma = {} #Values in km\n",
    "r18dict_GD_cma['12594'] = [] #no data\n",
    "r18dict_GD_cma['12600'] = [] #no data\n",
    "r18dict_GD_cma['12621'] = [] #no data\n",
    "r18dict_GD_cma['12624'] = [] #no data\n",
    "r18dict_GD_cma['12688'] = [float((120+150+120+100)/4), float((120+150+120+100)/4)]\n",
    "r18dict_GD_cma['12733'] = [float((200+200+200+200)/4), float((200+200+200+200)/4)]\n",
    "r18dict_GD_cma['12776'] = [] #no data\n",
    "r18dict_GD_cma['12793'] = [float((300+260+260+300)/4), float((260+260+170+170)/4)]\n",
    "r18dict_GD_cma['12837'] = []#[float((380+350+380+320)/4), 'no data']\n",
    "r18dict_GD_cma['12861'] = [float((280+220+260+240)/4), float((280+220+260+240)/4)]\n",
    "r18dict_GD_cma['12862'] = []#[float((400+300+300+250)/4), 'no data']\n",
    "\n",
    "r18dict_PHI_jtwc = {} #Values in nautical mile, change to km\n",
    "r18dict_PHI_jtwc['12566'] = [] #Kajiki 2014, from bwp022014.dat, no data\n",
    "r18dict_PHI_jtwc['12580'] = [] #Four 2014, no data\n",
    "r18dict_PHI_jtwc['12600'] = [float((80+80+85+85)*1.852/4), float((80+80+85+85)*1.852/4)] #Rammasun 2014, from bwp092014.dat\n",
    "r18dict_PHI_jtwc['12624'] = [float((110+120+120+110)*1.852/4),float((110+120+120+110)*1.852/4)] #Kalmaegi 2014, from bwp152014.dat\n",
    "r18dict_PHI_jtwc['12627'] = [float((50+70+55+55)*1.852/4), float((55+40+40+55)*1.852/4)] #Fung-wong 2014, from bwp162014.dat\n",
    "r18dict_PHI_jtwc['12645'] = [] #Sinlaku 2014, from bwp212014.dat, no data\n",
    "r18dict_PHI_jtwc['12646'] = [float((125+110+110+125)*1.852/4), float((125+110+110+125)*1.852/4)] #Hagupit 2014, from bwp222014.dat\n",
    "r18dict_PHI_jtwc['12649'] = ['no data', float((40+40+40+40)*1.852/4)] #Jangmi 2014, from bwp232014.dat\n",
    "r18dict_PHI_jtwc['12651'] = [float((75+70+75+90)*1.852/4), float((75+70+75+80)*1.852/4)] #Mekkhala 2015, from bwp012015.dat\n",
    "r18dict_PHI_jtwc['12669'] = [] #Maysak 2015, from bwp042015.dat, no data\n",
    "r18dict_PHI_jtwc['12688'] = [float((80+65+65+80)*1.852/4), float((80+65+65+80)*1.852/4)] #Linfa 2015, from bwp102015.dat\n",
    "r18dict_PHI_jtwc['12733'] = [] #Mujigae 2015, from bwp222015.dat, no data\n",
    "r18dict_PHI_jtwc['12738'] = [float((110+155+95+85)*1.852/4), float((110+155+95+85)*1.852/4)] #Koppu 2015, from bwp242015.dat\n",
    "r18dict_PHI_jtwc['12754'] = [float((135+75+75+110)*1.852/4), float((135+75+75+110)*1.852/4)] #Melor 2015, bwp282015.dat\n",
    "r18dict_PHI_jtwc['12836'] = [float((150+110+110+150)*1.852/4), float((160+110+120+170)*1.852/4)] #Sarika 2016, from bwp242016.dat\n",
    "r18dict_PHI_jtwc['12837'] = [float((220+200+190+200)*1.852/4), float((230+210+190+200)*1.852/4)] #Haima 2016, from bwp252016.dat\n",
    "r18dict_PHI_jtwc['12846'] = [float((50+50+50+50)*1.852/4), float((50+50+50+50)*1.852/4)] #Tokage 2016, from bwp292016.dat\n",
    "r18dict_PHI_jtwc['12852'] = [float((120+80+90+110)*1.852/4), float((110+80+80+120)*1.852/4)] #Nock-ten 2016\n",
    "r18dict_PHI_jtwc['12862'] = [] #Mangkhut 2018, no data\n",
    "\n",
    "r18dict_PHI_cma = {} #Values in km\n",
    "r18dict_PHI_cma['12566'] = [] #no data\n",
    "r18dict_PHI_cma['12580'] = [] #no data\n",
    "r18dict_PHI_cma['12600'] = [] #no data\n",
    "r18dict_PHI_cma['12624'] = [] #no data\n",
    "r18dict_PHI_cma['12627'] = [] #no data\n",
    "r18dict_PHI_cma['12645'] = [] #no data\n",
    "r18dict_PHI_cma['12646'] = [] #no data\n",
    "r18dict_PHI_cma['12649'] = [] #no data\n",
    "r18dict_PHI_cma['12651'] = [] #no data\n",
    "r18dict_PHI_cma['12669'] = [float((200+150+50+100)/4), float((150+130+70+70)/4)]\n",
    "r18dict_PHI_cma['12688'] = [float((250+220+250+200)/4), float((260+230+260+200)/4)]\n",
    "r18dict_PHI_cma['12733'] = [] #no data\n",
    "r18dict_PHI_cma['12738'] = [float((350+350+350+300)/4), float((350+350+350+300)/4)]\n",
    "r18dict_PHI_cma['12754'] = [float((250+230+200+250)/4), float((250+230+200+250)/4)]\n",
    "r18dict_PHI_cma['12836'] = [float((260+240+200+240)/4), float((230+230+260+260)/4)]\n",
    "r18dict_PHI_cma['12837'] = [float((380+350+380+320)/4), float((380+350+380+320)/4)]\n",
    "r18dict_PHI_cma['12846'] = [] #no data\n",
    "r18dict_PHI_cma['12852'] = [float((280+200+240+280)/4), float((280+220+220+240)/4)]\n",
    "r18dict_PHI_cma['12862'] = [float((600+500+350+500)/4), float((550+480+480+400)/4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot log rain vs log pd\n",
    "def plot_lograin_logpd(area, source, only_on_land = False, intersect = False, same_size_as_r18 = False):\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            pressuredict = landfalldata_pres_PHI2014_jtwc.copy()\n",
    "        elif source == 1:\n",
    "            pressuredict = landfalldata_pres_PHI2014_cma.copy()\n",
    "        elif source == 2:\n",
    "            pressuredict = landfalldata_pres_PHI2014_wmo.copy()\n",
    "        \n",
    "        pressuredict.pop('12566', None) #No rainfall data for 12566\n",
    "        pressuredict.pop('12580', None) #No rainfall data for 12580\n",
    "    else:\n",
    "        if source == 0:\n",
    "            pressuredict = landfalldata_pres_GD2014_jtwc.copy()\n",
    "        elif source == 1:\n",
    "            pressuredict = landfalldata_pres_GD2014_cma.copy()\n",
    "        elif source == 2:\n",
    "            pressuredict = landfalldata_pres_GD2014_wmo.copy()\n",
    "            \n",
    "        pressuredict.pop('12860',None)\n",
    "            \n",
    "    if intersect == True:\n",
    "        if area == 0:\n",
    "            key_a = list(landfalldata_pres_PHI2014_jtwc.keys())\n",
    "            key_b = list(landfalldata_pres_PHI2014_cma.keys())\n",
    "            key_c = list(landfalldata_pres_PHI2014_wmo.keys())\n",
    "        else:\n",
    "            key_a = list(landfalldata_pres_GD2014_jtwc.keys())\n",
    "            key_b = list(landfalldata_pres_GD2014_cma.keys())\n",
    "            key_c = list(landfalldata_pres_GD2014_wmo.keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a, key_b),key_c)\n",
    "        \n",
    "        if '12566' in key_intersect_list:\n",
    "            key_intersect_list = np.delete(key_intersect_list,np.where(key_intersect_list=='12566'))\n",
    "        if '12580' in key_intersect_list:\n",
    "            key_intersect_list = np.delete(key_intersect_list,np.where(key_intersect_list=='12580'))\n",
    "        if '12860' in key_intersect_list:\n",
    "            key_intersect_list = np.delete(key_intersect_list,np.where(key_intersect_list=='12860'))\n",
    "            \n",
    "        print(key_intersect_list)\n",
    "        tcindexes = np.asarray(key_intersect_list)\n",
    "        \n",
    "    else:\n",
    "        print(list(pressuredict.keys()))\n",
    "        tcindexes = np.asarray(list(pressuredict.keys()), dtype=int)\n",
    "    \n",
    "    rainfall_total_list = []\n",
    "    pdlist = []\n",
    "    \n",
    "    if same_size_as_r18 == True:\n",
    "        for tc in tcindexes:\n",
    "            print(tc)\n",
    "            if (source == 0 and str(tc) in list(r18dict_GD_jtwc_2014.keys()) and r18dict_GD_jtwc_2014[str(tc)] != []) or (source == 1 and str(tc) in list(r18dict_GD_cma.keys()) and r18dict_GD_cma[str(tc)] != []):\n",
    "                rainfall_list = rainfall_distribution(area, source, tc, only_on_land)[1]\n",
    "                total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                rainfall_total_list.append(total_rainfall)\n",
    "                pressure = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "                pd = 1011-pressure\n",
    "                pdlist.append(pd)\n",
    "    else:\n",
    "        for tc in tcindexes:\n",
    "            print(tc)\n",
    "            rainfall_list = rainfall_distribution(area, source, tc, only_on_land)[1]\n",
    "            total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "            rainfall_total_list.append(total_rainfall)\n",
    "            pressure = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "            pd = 1011-pressure\n",
    "            pdlist.append(pd)\n",
    "        \n",
    "    pdlist = np.asarray(pdlist)\n",
    "    rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "    \n",
    "    logpdlist = np.log(pdlist)\n",
    "    lograinfalllist = np.log(rainfall_total_list)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(logpdlist, lograinfalllist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(logpdlist, lograinfalllist) #Linear fit\n",
    "    xrange = np.linspace(min(logpdlist),max(logpdlist),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(lograinfalllist)\n",
    "\n",
    "    plt.xlabel('log(pressure deficit)')\n",
    "    if only_on_land == True:\n",
    "        plt.ylabel('log(total volume of rain within 500km on land)')\n",
    "    else:\n",
    "        plt.ylabel('log(total volume of rain within 500km)')\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall against pressure deficit of TC when making landfall in the Philippines, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall against pressure deficit of TC when making landfall in the Philippines, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall against pressure deficit of TC when making landfall in the Philippines, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall against pressure deficit of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall against pressure deficit of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall against pressure deficit of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='x-small')\n",
    "    plt.show()\n",
    "\n",
    "    return logpdlist, lograinfalllist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpd(0, 0, True, True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpd(0, 1, True, True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpd(0, 2, True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpd(1, 0, False, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpd(1, 1, False, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpd(1, 2, False, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot log rain vs log R18\n",
    "def plot_lograin_logr18(area, source, only_on_land = False, intersect = False):\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            r18dict = r18dict_PHI_jtwc.copy()\n",
    "        elif source == 1:\n",
    "            r18dict = r18dict_PHI_cma.copy()\n",
    "    else:\n",
    "        if source == 0:\n",
    "            r18dict = r18dict_GD_jtwc_2014.copy()\n",
    "        elif source == 1:\n",
    "            r18dict = r18dict_GD_cma.copy()\n",
    "\n",
    "    if intersect == True:\n",
    "        if area == 0:\n",
    "            dict_a = r18dict_PHI_jtwc.copy()\n",
    "            dict_b = r18dict_PHI_cma.copy()\n",
    "        else:\n",
    "            dict_a = r18dict_GD_jtwc_2014.copy()\n",
    "            dict_b = r18dict_GD_cma.copy()\n",
    "        for index in list(dict_a.keys()):\n",
    "            if dict_a[index] == []:\n",
    "                dict_a.pop(index,None)\n",
    "        for index in list(dict_b.keys()):\n",
    "            if dict_b[index] == []:\n",
    "                dict_b.pop(index,None)\n",
    "        key_a = list(dict_a.keys())\n",
    "        key_b = list(dict_b.keys())\n",
    "        key_intersect_list = np.intersect1d(key_a, key_b)\n",
    "        print(key_intersect_list)\n",
    "        tcindexes = np.asarray(key_intersect_list)        \n",
    "    else:\n",
    "        print(list(r18dict.keys()))\n",
    "        tcindexes = np.asarray(list(r18dict.keys()), dtype=int)\n",
    "    \n",
    "    rainfall_total_list = []\n",
    "    r18list = []\n",
    "    for tc in tcindexes:\n",
    "        print(tc)\n",
    "        if r18dict[str(tc)] != []:\n",
    "            r18 = r18dict[str(tc)][1] #Get TC R18 after landfall\n",
    "            if type(r18) != str:\n",
    "                r18list.append(r18)\n",
    "                rainfall_list = rainfall_distribution(area, source, tc, only_on_land)[1]\n",
    "                total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                rainfall_total_list.append(total_rainfall)\n",
    "                \n",
    "        \n",
    "    r18list = np.asarray(r18list)\n",
    "    rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "    \n",
    "    logr18list = np.log(r18list)\n",
    "    lograinfalllist = np.log(rainfall_total_list)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(logr18list, lograinfalllist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(logr18list, lograinfalllist) #Linear fit\n",
    "    xrange = np.linspace(min(logr18list),max(logr18list),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(lograinfalllist)\n",
    "    \n",
    "    plt.xlabel('log(R18)')\n",
    "    if only_on_land == True:\n",
    "        plt.ylabel('log(total volume of rain within 500km on land)')\n",
    "    else:\n",
    "        plt.ylabel('log(total volume of rain within 500km)')\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall against R18 of TC when making landfall in the Philippines, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall against R18 of TC when making landfall in the Philippines, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall against R18 of TC when making landfall in the Philippines, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall against R18 of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall against R18 of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall against R18 of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    plt.show()\n",
    "    \n",
    "    return logr18list, lograinfalllist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logr18(0,0,False,True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logr18(0,1,False,True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logr18(1,0,False,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logr18(1,1,False,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot log rain vs (log pd & log r18)\n",
    "def plot_lograin_logpdlogr18(area, source, only_on_land = False, intersect = False):\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            pressuredict = landfalldata_pres_PHI2014_jtwc\n",
    "            r18dict = r18dict_PHI_jtwc\n",
    "        elif source == 1:\n",
    "            pressuredict = landfalldata_pres_PHI2014_cma\n",
    "            r18dict = r18dict_PHI_cma\n",
    "        \n",
    "    else:\n",
    "        if source == 0:\n",
    "            pressuredict = landfalldata_pres_GD2014_jtwc\n",
    "            r18dict = r18dict_GD_jtwc_2014\n",
    "        elif source == 1:\n",
    "            pressuredict = landfalldata_pres_GD2014_cma\n",
    "            r18dict = r18dict_GD_cma\n",
    "            \n",
    "    if intersect == True:\n",
    "        if area == 0:\n",
    "            dict_a = r18dict_PHI_jtwc\n",
    "            dict_b = r18dict_PHI_cma\n",
    "        else:\n",
    "            dict_a = r18dict_GD_jtwc_2014\n",
    "            dict_b = r18dict_GD_cma\n",
    "        for index in list(dict_a.keys()):\n",
    "            if dict_a[index] == []:\n",
    "                dict_a.pop(index,None)\n",
    "        for index in list(dict_b.keys()):\n",
    "            if dict_b[index] == []:\n",
    "                dict_b.pop(index,None)\n",
    "        key_a = list(dict_a.keys())\n",
    "        key_b = list(dict_b.keys())\n",
    "        key_intersect_list = np.intersect1d(key_a, key_b)\n",
    "        print(key_intersect_list)\n",
    "        tcindexes = np.asarray(key_intersect_list)\n",
    "    \n",
    "    else:  \n",
    "        print(list(r18dict.keys()))\n",
    "        tcindexes = np.asarray(list(r18dict.keys()), dtype=int)\n",
    "    \n",
    "    rainfall_total_list = []\n",
    "    r18list = []\n",
    "    pdlist = []\n",
    "    for tc in tcindexes:\n",
    "        print(tc)\n",
    "        if r18dict[str(tc)] != [] and tc != 12566 and tc != 12580: #No rainfall data for 12566 and 12580\n",
    "            r18 = r18dict[str(tc)][1] #Get TC R18 after landfall\n",
    "            if type(r18) != str:\n",
    "                pressure = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "                pd = 1010-pressure\n",
    "                pdlist.append(pd)\n",
    "                r18list.append(r18)\n",
    "                rainfall_list = rainfall_distribution(area, source, tc, only_on_land)[1]\n",
    "                total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                rainfall_total_list.append(total_rainfall)\n",
    "                \n",
    "    pdlist = np.asarray(pdlist)\n",
    "    r18list = np.asarray(r18list)\n",
    "    rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "    \n",
    "    if intersect == False:\n",
    "        if only_on_land == False:\n",
    "            if area == 0:\n",
    "                if source == 0:\n",
    "                    slope_pd = 0.3201 #Use values obtained from previous individual plots\n",
    "                    slope_r18 = 0.1615\n",
    "                elif source == 1:\n",
    "                    slope_pd = 0.2925\n",
    "                    slope_r18 = 1.5331\n",
    "            else:\n",
    "                if source == 0:\n",
    "                    slope_pd = 0.4518\n",
    "                    slope_r18 = 1.7545\n",
    "                elif source == 1:\n",
    "                    slope_pd = 0.8237\n",
    "                    slope_r18 = 1.7018\n",
    "        else:\n",
    "            if area == 0:\n",
    "                if source == 0:\n",
    "                    slope_pd = 0.3703\n",
    "                    slope_r18 = -0.0532\n",
    "                elif source == 1:\n",
    "                    slope_pd = 0.3594\n",
    "                    slope_r18 = 1.304\n",
    "            else:\n",
    "                if source == 0:\n",
    "                    slope_pd = 0.5051 #Check\n",
    "                    slope_r18 = 1.5141 #Check\n",
    "                elif source == 1:\n",
    "                    slope_pd = 0.5579\n",
    "                    slope_r18 = 1.0801\n",
    "    \n",
    "    logpdlist = np.log(pdlist**slope_pd)\n",
    "    logr18list = np.log(r18list**slope_r18)\n",
    "    lograinfalllist = np.log(rainfall_total_list)\n",
    "    \n",
    "    loglist = logpdlist + logr18list\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(loglist, lograinfalllist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(loglist, lograinfalllist) #Linear fit\n",
    "    xrange = np.linspace(min(loglist),max(loglist),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(lograinfalllist)\n",
    "    plt.xlabel('log(R18^a) + log(pressure deficit^b)')\n",
    "    plt.ylabel('log(total volume of rain within 500km)')\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall against pressure deficit and R18 of TC when making landfall in the Philippines, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue) + ', a = ' + str(slope_pd) + ', b = ' + str(slope_r18),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall against pressure deficit and R18 of TC when making landfall in the Philippines, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue) + ', a = ' + str(slope_pd) + ', b = ' + str(slope_r18),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall against pressure deficit and R18 of TC when making landfall in the Philippines, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue) + ', a = ' + str(slope_pd) + ', b = ' + str(slope_r18),fontsize = 'x-small')\n",
    "\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Rainfall against pressure deficit and R18 of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue) + ', a = ' + str(slope_pd) + ', b = ' + str(slope_r18),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Rainfall against pressure deficit and R18 of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue) + ', a = ' + str(slope_pd) + ', b = ' + str(slope_r18),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Rainfall against pressure deficit and R18 of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue) + ', a = ' + str(slope_pd) + ', b = ' + str(slope_r18),fontsize = 'x-small')\n",
    "    plt.show()\n",
    "    \n",
    "    return loglist, lograinfalllist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpdlogr18(0,0,True)\n",
    "plot_lograin_logpdlogr18(0,0,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_lograin_logpdlogr18(0,1,True)\n",
    "plot_lograin_logpdlogr18(0,1,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "#plot_lograin_logpdlogr18(1,0,True)\n",
    "plot_lograin_logpdlogr18(1,0,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "#plot_lograin_logpdlogr18(1,1,True)\n",
    "plot_lograin_logpdlogr18(1,1,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GD damage data from EM-DAT, figures taken under \"China\"\n",
    "damage_GD = {} #Total deaths, total damage in USD, 0 means no data\n",
    "damage_GD['8967'] = [188, 0] #Joe 1980\n",
    "damage_GD['9304'] = [30, 0] #Ellen 1983, no data\n",
    "# damage_GD['9319'] = 0 #Joe 1983, no data\n",
    "# damage_GD['9386'] = 0 #Wynne 1984, no data\n",
    "# damage_GD['9391'] = 0 #Betty 1984, no data\n",
    "# damage_GD['9406'] = 0 #Gerald 1984, no data\n",
    "# damage_GD['9415'] = 0 #June 1984, no data\n",
    "# daamge_GD['9509'] = 0 #Hal 1985, no data\n",
    "# damage_GD['9542'] = 0 #Tess 1985, no data\n",
    "# damage_GD['9554'] = 0 #Winona 1985, no data\n",
    "# damage_GD['9625'] = 0 #Mac 1986, no data\n",
    "damage_GD['9634'] = [172, 38e7] #Peggy 1986\n",
    "# damage_GD['9638'] = 0 #Not named 1986, no data\n",
    "# damage_GD['9673'] = 0 #Ellen 1986, no data\n",
    "# damage_GD['9728'] = 0 #Ruth 1987, no data?\n",
    "# damage_GD['9782'] = 0 #Lynn 1987, no data\n",
    "# damage_GD['9826'] = 0 #Vanessa 1988, no data\n",
    "# damage_GD['9830'] = 0 #Warren 1988, no data\n",
    "damage_GD['9874'] = [6, 0] #Kit 1989, no data?\n",
    "# damage_GD['9875'] = 0 #Mamie:Mimie 1988, no data\n",
    "damage_GD['9944'] = [84, 0] #Brenda 1989, no data?\n",
    "# damage_GD['9961'] = 0 #Gordon 1989, no data\n",
    "# damage_GD['10069'] = 0 #Nathan 1990, no data\n",
    "damage_GD['10083'] = [108, 83e6] #Tasha 1990\n",
    "damage_GD['10096'] = [144, 157000e3] #Yancy 1990\n",
    "damage_GD['10192'] = [0, 0] #Brendan 1991, no data\n",
    "damage_GD['10212'] = [0, 0] #Joel 1991, no data\n",
    "damage_GD['10221'] = [0, 0] #Nat 1991, no data\n",
    "damage_GD['10302'] = [0, 0] #Faye 1992, no data\n",
    "damage_GD['10318'] = [0, 0] #Mark 1992, no data\n",
    "damage_GD['10324'] = [0, 0] #Omar 1992, no data\n",
    "damage_GD['10417'] = [10, 219670e3] #Koryn 1993\n",
    "damage_GD['10436'] = [28, 433920e3] #Tasha 1993\n",
    "damage_GD['10449'] = [10, 12610e3] #Abe 1993\n",
    "damage_GD['10452'] = [7, 263670e3] #Becky 1993\n",
    "damage_GD['10454'] = [1, 286370e3] #Dot 1993\n",
    "damage_GD['10466'] = [0, 15890e3] #Ira 1993\n",
    "damage_GD['10518'] = [74, 700e3] #Russ 1994\n",
    "damage_GD['10520'] = [0, 0] #Sharon 1994, no data\n",
    "damage_GD['10553'] = [0, 0] #Harry 1994, no data\n",
    "damage_GD['10640'] = [26, 16e7] #Helen 1995\n",
    "damage_GD['10645'] = [0, 0] #Irving 1995, no data\n",
    "damage_GD['10653'] = [445, 87000e3] #Kent 1995\n",
    "damage_GD['10657'] = [0, 0] #Nina 1995, no data\n",
    "damage_GD['10669'] = [0, 0] #Sibyl 1995, no data\n",
    "damage_GD['10675'] = [0, 0] #Ted 1995, no data\n",
    "damage_GD['10779'] = [38, 1e8] #Willie 1996\n",
    "damage_GD['10881'] = [65, 579700e3] #Victor 1997\n",
    "damage_GD['10891'] = [7, 33e7] #Zita 1997\n",
    "damage_GD['10980'] = [0, 0] #Penny 1998, no data\n",
    "damage_GD['11077'] = [0, 0] #Maggie 1999, no data\n",
    "damage_GD['11092'] = [0, 0] #TS0725 1999, no data\n",
    "damage_GD['11106'] = [5, 18000e3] #Sam 1999\n",
    "damage_GD['11115'] = [192, 277900e3] #Wendy 1999\n",
    "damage_GD['11119'] = [18, 64300e3] #York 1999\n",
    "damage_GD['11127'] = [0, 0] #Cam 1999, no data\n",
    "damage_GD['11218'] = [47, 169e6] #Maria 2000\n",
    "damage_GD['11290'] = [33, 2743000e3] #Utor 2001\n",
    "damage_GD['11298'] = [0, 85000e3] #Yutu 2001\n",
    "damage_GD['11313'] = [4, 213e6] #Fitow 2001\n",
    "damage_GD['11318'] = [0, 0] #Nari 2001, no data\n",
    "damage_GD['11410'] = [0, 0] #Kammuri 2002, no data\n",
    "damage_GD['11417'] = [0, 0] #Vongfong 2002, no data\n",
    "damage_GD['11431'] = [25, 0] #Hagupit 2002\n",
    "damage_GD['11438'] = [0, 0] #Mekkhala 2002, no data\n",
    "damage_GD['11508'] = [20, 1e8] #Imbudo 2003\n",
    "damage_GD['11520'] = [0, 0] #Krovanh 2003, no data\n",
    "damage_GD['11528'] = [38, 241000e3] #Dujuan 2003\n",
    "damage_GD['11605'] = [0, 0] #Kompasu 2004, no data\n",
    "damage_GD['11623'] = [2, 5000e3] #Aere 2004\n",
    "damage_GD['11725'] = [0, 0] #Sanvu 2005, no data\n",
    "damage_GD['11810'] = [23, 475000e3] #Chanchu 2006\n",
    "damage_GD['11814'] = [0, 0] #Jelawat 2006, no data\n",
    "damage_GD['11826'] = [89, 9e8] #Prapiroon 2006\n",
    "damage_GD['11928'] = [0, 0] #Pabuk 2007, no data\n",
    "damage_GD['11999'] = [25, 49000e3] #Neoguri 2008\n",
    "damage_GD['12012'] = [14, 175000e3] #Fengshen 2008\n",
    "damage_GD['12025'] = [0, 80000e3] #Kammuri 2008\n",
    "damage_GD['12034'] = [4, 58000e3] #Nuri 2008\n",
    "damage_GD['12048'] = [12, 824000e3] #Hagupit 2008\n",
    "damage_GD['12052'] = [0, 0] #Higos 2008, no data\n",
    "damage_GD['12110'] = [0, 0] #Nangka 2009, no data\n",
    "damage_GD['12114'] = [0, 0] #Soudelor 2009, no data\n",
    "damage_GD['12118'] = [0, 0] #Molave 2009, no data\n",
    "damage_GD['12121'] = [9, 7000e3] #Goni 2009\n",
    "damage_GD['12146'] = [13, 295001e3] #Koppu 2009\n",
    "damage_GD['12215'] = [0, 0] #Chanthu 2010, no data\n",
    "damage_GD['12227'] = [0, 0] #Lionrock 2010, no data\n",
    "damage_GD['12238'] = [75, 298285e3] #Fanapi 2010\n",
    "damage_GD['12294'] = [23, 0] #Sarika 2011\n",
    "damage_GD['12296'] = [0, 0] #Haima 2011, no data\n",
    "damage_GD['12393'] = [0, 0] #Doksuri 2012, no data\n",
    "damage_GD['12399'] = [8, 329000e3] #Vincente 2012\n",
    "damage_GD['12408'] = [2, 262000e3] #Kai-tak 2012\n",
    "damage_GD['12485'] = [7, 177000e3] #Rumbia 2013\n",
    "damage_GD['12498'] = [88, 2120000e3] #Utor 2013\n",
    "damage_GD['12520'] = [20, 0] #Usagi 2013\n",
    "damage_GD['12594'] = [0, 131000e3] #Hagibis 2014\n",
    "damage_GD['12600'] = [71, 4232973e3] #Rammasun 2014\n",
    "damage_GD['12621'] = [0, 0] #Fourteen TD0907 2014, no data\n",
    "damage_GD['12624'] = [9, 2900000e3] #Kalmaegi 2014\n",
    "damage_GD['12688'] = [0, 213000e3] #Linfa 2015\n",
    "damage_GD['12733'] = [20, 4200000e3] #Mujigae 2015\n",
    "damage_GD['12776'] = [0, 0] #TD0526  2016, no data\n",
    "damage_GD['12793'] = [0, 123000e3] #Nida 2016\n",
    "damage_GD['12837'] = [0, 0] #Haima 2016, no data\n",
    "damage_GD['12861'] = [8, 3500000e3] #Hato 2017\n",
    "damage_GD['12862'] = [0, 770000e3] #Mangkhut 2018\n",
    "\n",
    "damage_GD_after2014 = {} #Total deaths, total damage in USD, 0 means no data\n",
    "damage_GD_after2014['12594'] = [0, 131000e3] #Hagibis 2014\n",
    "damage_GD_after2014['12600'] = [71, 4232973e3] #Rammasun 2014\n",
    "damage_GD_after2014['12621'] = [0, 0] #Fourteen TD0907 2014, no data\n",
    "damage_GD_after2014['12624'] = [9, 2900000e3] #Kalmaegi 2014\n",
    "damage_GD_after2014['12688'] = [0, 213000e3] #Linfa 2015\n",
    "damage_GD_after2014['12733'] = [20, 4200000e3] #Mujigae 2015\n",
    "damage_GD_after2014['12776'] = [0, 0] #TD0526  2016, no data\n",
    "damage_GD_after2014['12793'] = [0, 123000e3] #Nida 2016\n",
    "damage_GD_after2014['12837'] = [0, 0] #Haima 2016, no data\n",
    "damage_GD_after2014['12861'] = [8, 3500000e3] #Hato 2017\n",
    "damage_GD_after2014['12862'] = [0, 770000e3] #Mangkhut 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot damage vs pd\n",
    "def plot_damage_pd_GD(source, death_or_damage, after2014 = False, logdamage = False, logpd = False, intersect = False):\n",
    "    if after2014 == False:\n",
    "        damagedict = damage_GD\n",
    "        if source == 0:\n",
    "            pressuredict = landfalldata_pres_GD_jtwc\n",
    "        elif source == 1:\n",
    "            pressuredict = landfalldata_pres_GD_cma\n",
    "        elif source == 2:\n",
    "            pressuredict = landfalldata_pres_GD_wmo\n",
    "    else:\n",
    "        damagedict = damage_GD_after2014\n",
    "        if source == 0:\n",
    "            pressuredict = landfalldata_pres_GD2014_jtwc\n",
    "        elif source == 1:\n",
    "            pressuredict = landfalldata_pres_GD2014_cma\n",
    "        elif source == 2:\n",
    "            pressuredict = landfalldata_pres_GD2014_wmo\n",
    "    \n",
    "    if intersect == True:\n",
    "        key_a = list(landfalldata_pres_GD_jtwc.keys())\n",
    "        key_b = list(landfalldata_pres_GD_cma.keys())\n",
    "        key_c = list(landfalldata_pres_GD_wmo.keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a, key_b), key_c)\n",
    "        \n",
    "    else:\n",
    "        key_intersect_list = pressuredict.keys()\n",
    "        \n",
    "    tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    \n",
    "    damagelist = []\n",
    "    pdlist = []\n",
    "    for tc in tcindexes:\n",
    "#        print(tc)\n",
    "        if death_or_damage == 0: #Total deaths\n",
    "            damage = damagedict[str(tc)][0]\n",
    "        else:\n",
    "            damage = damagedict[str(tc)][1]\n",
    "        if damage != 0 and str(tc) in key_intersect_list:\n",
    "            pres = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "            pd = 1010-pres\n",
    "            pdlist.append(pd)\n",
    "            damagelist.append(damage)\n",
    "                \n",
    "        \n",
    "    pdlist = np.asarray(pdlist)\n",
    "    damagelist = np.asarray(damagelist)\n",
    "    \n",
    "    if logdamage == True:\n",
    "        damagelist = np.log(damagelist)\n",
    "    if logpd == True:\n",
    "        pdlist = np.log(pdlist)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(pdlist, damagelist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(pdlist, damagelist) #Linear fit\n",
    "    xrange = np.linspace(min(pdlist),max(pdlist),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(damagelist)\n",
    "    if logpd == True:\n",
    "        plt.xlabel('log(pressure deficit)')\n",
    "    else:\n",
    "        plt.xlabel('Pressure deficit (hPa)')\n",
    "    if death_or_damage == 0:\n",
    "        if logdamage == True:\n",
    "            plt.ylabel('log(total deaths)')\n",
    "        else:\n",
    "            plt.ylabel('Total deaths')\n",
    "    else:\n",
    "        if logdamage == True:\n",
    "            plt.ylabel('log(damage)')\n",
    "        else:\n",
    "            plt.ylabel('Damage (USD)')\n",
    "\n",
    "    if death_or_damage == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Total deaths against pressure deficit of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Total deaths against pressure deficit of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Total deaths against pressure deficit of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Damage against pressure deficit of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Damage against pressure deficit of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Damage against pressure deficit of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')    \n",
    "    plt.show()\n",
    "    \n",
    "    return pdlist, damagelist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# plot_damage_pd_GD(0)\n",
    "# plot_damage_pd_GD(1)\n",
    "# plot_damage_pd_GD(2)\n",
    "# plot_damage_pd_GD(0,1,False,logpd=False,logdamage=False,False)\n",
    "# plot_damage_pd_GD(1,1,False,False,False,False)\n",
    "# plot_damage_pd_GD(2,1,False,False,False,False)\n",
    "plot_damage_pd_GD(0,0,False,logdamage=True,logpd=True, intersect = False)\n",
    "plot_damage_pd_GD(1,0,False,True,True,False)\n",
    "plot_damage_pd_GD(2,0,False,True,True,False)\n",
    "# plot_damage_pd_GD(0, False, True)\n",
    "# plot_damage_pd_GD(1, False, True)\n",
    "# plot_damage_pd_GD(2, False, True)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot damage vs wind\n",
    "def plot_damage_wind_GD(source, death_or_damage, after2014 = False, logdamage = False, logwind = False, intersect = False):\n",
    "    if after2014 == False:\n",
    "        damagedict = damage_GD\n",
    "        if source == 0:\n",
    "            winddict = landfalldata_wind_GD_jtwc\n",
    "        elif source == 1:\n",
    "            winddict = landfalldata_wind_GD_cma\n",
    "        elif source == 2:\n",
    "            winddict = landfalldata_wind_GD_wmo\n",
    "    else:\n",
    "        damagedict = damage_GD_after2014\n",
    "        if source == 0:\n",
    "            winddict = landfalldata_wind_GD2014_jtwc\n",
    "        elif source == 1:\n",
    "            winddict = landfalldata_wind_GD2014_cma\n",
    "        elif source == 2:\n",
    "            winddict = landfalldata_wind_GD2014_wmo\n",
    "            \n",
    "    if intersect == True:\n",
    "        key_a = list(landfalldata_wind_GD_jtwc.keys())\n",
    "        key_b = list(landfalldata_wind_GD_cma.keys())\n",
    "        key_c = list(landfalldata_wind_GD_wmo.keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a, key_b), key_c)\n",
    "        \n",
    "    else:\n",
    "        key_intersect_list = winddict.keys()\n",
    "        \n",
    "    \n",
    "#    print(list(damagedict.keys()))\n",
    "    tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    \n",
    "    damagelist = []\n",
    "    windlist = []\n",
    "    for tc in tcindexes:\n",
    "        if death_or_damage == 0:\n",
    "            damage = damagedict[str(tc)][0]\n",
    "        else:\n",
    "            damage = damagedict[str(tc)][1]\n",
    "        if damage != 0 and str(tc) in key_intersect_list:\n",
    "            if len(winddict[str(tc)]) == 1:\n",
    "                wind = winddict[str(tc)][0] #Get TC wind speed after landfall\n",
    "            elif len(winddict[str(tc)]) == 2:\n",
    "                wind = winddict[str(tc)][1] #Get TC wind speed after landfall\n",
    "            windlist.append(wind)\n",
    "            damagelist.append(damage)\n",
    "                \n",
    "        \n",
    "    windlist = np.asarray(windlist)\n",
    "    damagelist = np.asarray(damagelist)\n",
    "    \n",
    "    if logwind == True:\n",
    "        windlist = np.log(windlist)\n",
    "    if logdamage == True:\n",
    "        damagelist = np.log(damagelist)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(windlist, damagelist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(windlist, damagelist) #Linear fit\n",
    "    xrange = np.linspace(min(windlist),max(windlist),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(damagelist)\n",
    "    \n",
    "    if logwind == True:\n",
    "        plt.xlabel('log(wind speed)')\n",
    "    else:\n",
    "        plt.xlabel('Wind speed (kts)')\n",
    "    if logdamage == True:\n",
    "        if death_or_damage == 0:\n",
    "            plt.ylabel('log(total deaths)')\n",
    "        else:\n",
    "            plt.ylabel('log(damage)')\n",
    "    else:\n",
    "        if death_or_damage == 0:\n",
    "            plt.ylabel('Total deaths')\n",
    "        else:\n",
    "            plt.ylabel('Damage (USD)')\n",
    "\n",
    "    if death_or_damage == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Total deaths against maximum wind speed of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Total deaths against maximum wind speed of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Total deaths against maximum wind speed of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Damage against maximum wind speed of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Damage against maximum wind speed of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Damage against maximum wind speed of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return windlist, damagelist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_damage_wind_GD(0, 0,False, logdamage = True, logwind = True,intersect = False)\n",
    "plot_damage_wind_GD(1, 0,False, True, True, False)\n",
    "plot_damage_wind_GD(2, 0,False, True, True, False)\n",
    "# plot_damage_wind_GD(0, 0,False, True, True,False)\n",
    "# plot_damage_wind_GD(1, 0,False, False, True,False)\n",
    "# plot_damage_wind_GD(2, 0,False, False, True,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot damage vs rainfall\n",
    "def plot_damage_rainfall_GD(source, death_or_damage, only_on_land = False, logdamage = False, lograin = False):\n",
    "    damagedict = damage_GD_after2014\n",
    "    print(list(damagedict.keys()))\n",
    "    tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    \n",
    "    damagelist = []\n",
    "    rainfall_total_list = []\n",
    "    for tc in tcindexes:\n",
    "        print(tc)\n",
    "        if death_or_damage == 0:\n",
    "            damage = damagedict[str(tc)][0]\n",
    "        else:\n",
    "            damage = damagedict[str(tc)][1]\n",
    "        if damage != 0:\n",
    "            if (source == 0 and str(tc) in landfalldata_coord_GD2014_jtwc.keys()) or (source == 1 and str(tc) in landfalldata_coord_GD2014_cma.keys()) :\n",
    "                damagelist.append(damage)\n",
    "                rainfall_list = rainfall_distribution(1, source, tc, only_on_land)[1]\n",
    "                total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                rainfall_total_list.append(total_rainfall)\n",
    "                \n",
    "        \n",
    "    rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "    damagelist = np.asarray(damagelist)\n",
    "    \n",
    "    if lograin == True:\n",
    "        rainfall_total_list = np.log(rainfall_total_list)\n",
    "    if logdamage == True:\n",
    "        damagelist = np.log(damagelist)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(rainfall_total_list, damagelist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(rainfall_total_list, damagelist) #Linear fit\n",
    "    xrange = np.linspace(min(rainfall_total_list),max(rainfall_total_list),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(damagelist)\n",
    "    \n",
    "    if lograin == True:\n",
    "        if only_on_land == True:\n",
    "            plt.xlabel('log(total volume of rain within 500km on land)')\n",
    "        else:\n",
    "            plt.xlabel('log(total volume of rain within 500km)')\n",
    "    else:\n",
    "        if only_on_land == True:\n",
    "            plt.xlabel('Total volume of rain within 500km on land (mm)')\n",
    "        else:\n",
    "            plt.xlabel('Total volume of rain within 500km (mm)')\n",
    "    if logdamage == True:\n",
    "        if death_or_damage == 0:\n",
    "            plt.ylabel('log(total deaths)')\n",
    "        else:\n",
    "            plt.ylabel('log(damage)')\n",
    "    else:\n",
    "        if death_or_damage == 0:\n",
    "            plt.ylabel('Total deaths')\n",
    "        else:\n",
    "            plt.ylabel('Damage (USD)')\n",
    "\n",
    "    if death_or_damage == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Total deaths against rainfall of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Total deaths against rainfall of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Total deaths against rainfall of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Damage against rainfall of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Damage against rainfall of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Damage against rainfall of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return rainfall_total_list, damagelist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic - time.time() #Expected runtime ~3-5 min for each graph\n",
    "plot_damage_rainfall_GD(source=0, death_or_damage=0, only_on_land = False, logdamage = True, lograin = True)\n",
    "plot_damage_rainfall_GD(1, 0, only_on_land = False, logdamage = True, lograin = True)\n",
    "# plot_damage_rainfall_GD(source=0, death_or_damage=1, only_on_land = False, logdamage = False, lograin = False)\n",
    "# plot_damage_rainfall_GD(1, 1, only_on_land = False, logdamage = False, lograin = False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot damage vs r18\n",
    "def plot_damage_r18_GD(source, death_or_damage, logscale = False, intersect = False):\n",
    "    damagedict = damage_GD\n",
    "    if source == 0:\n",
    "        r18dict = r18dict_GD_jtwc\n",
    "    elif source == 1:\n",
    "        r18dict = r18dict_GD_cma\n",
    "\n",
    "    if intersect == True:\n",
    "        key_a = list(r18dict_GD_jtwc.keys())\n",
    "        key_b = list(r18dict_GD_cma.keys())\n",
    "        key_intersect_list = np.intersect1d(key_a, key_b)\n",
    "        \n",
    "    else:\n",
    "        key_intersect_list = r18dict.keys()\n",
    "        \n",
    "#    print(list(damagedict.keys()))\n",
    "    tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    \n",
    "    damagelist = []\n",
    "    r18list = []\n",
    "    for tc in tcindexes:\n",
    "#        print(tc)\n",
    "        if death_or_damage == 0:\n",
    "            damage = damagedict[str(tc)][0]\n",
    "        else:\n",
    "            damage = damagedict[str(tc)][1]\n",
    "        if str(tc) in key_intersect_list:\n",
    "            if r18dict[str(tc)] != []:\n",
    "                r18 = r18dict[str(tc)][1] #Get TC R18 after landfall\n",
    "                if type(r18) != str and damage != 0 and str(tc) in r18dict.keys():\n",
    "                    r18list.append(r18)\n",
    "                    damagelist.append(damage)\n",
    "        \n",
    "    r18list = np.asarray(r18list)\n",
    "    damagelist = np.asarray(damagelist)\n",
    "    \n",
    "    if logscale == True:\n",
    "        r18list = np.log(r18list)\n",
    "        damagelist = np.log(damagelist)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(r18list, damagelist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(r18list, damagelist) #Linear fit\n",
    "    xrange = np.linspace(min(r18list),max(r18list),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(damagelist)\n",
    "    \n",
    "    if logscale == True:\n",
    "        if death_or_damage == 0:\n",
    "            plt.xlabel('log(R18)')\n",
    "            plt.ylabel('log(total deaths)')\n",
    "        else:\n",
    "            plt.xlabel('log(R18)')\n",
    "            plt.ylabel('log(damage)')\n",
    "    else:\n",
    "        if death_or_damage == 0:\n",
    "            plt.xlabel('R18 (km)')\n",
    "            plt.ylabel('Total deaths')\n",
    "        else:\n",
    "            plt.xlabel('R18 (km)')\n",
    "            plt.ylabel('Damage (USD)')\n",
    "    if death_or_damage == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Total deaths against R18 of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Total deaths against R18 of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Total deaths against R18 of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Total damage against R18 of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Total damage against R18 of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Total damage against R18 of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return r18list, damagelist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "#plot_damage_r18_GD(0,1,False,True)\n",
    "plot_damage_r18_GD(0,0,True,False)\n",
    "#plot_damage_r18_GD(1,1,False,True)\n",
    "plot_damage_r18_GD(1,0,True,False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot damage against numerous variables combined\n",
    "def plot_damage_pdwindrainr18(variables,source,death_or_damage,only_on_land=False,logdamage=False,logvariables=False,intersect=False):\n",
    "    #Variables should be a string list, e.g. ['pd', 'wind', 'rain']\n",
    "    #logdamage/logvariable: 'True' if plot in log scale, 'False' otherwise\n",
    "    if 'rain' in variables:\n",
    "        damagedict = damage_GD_after2014 #No rainfall data before 2014\n",
    "    else:\n",
    "        damagedict = damage_GD\n",
    "        \n",
    "    if source == 0:\n",
    "        pressuredict = landfalldata_pres_GD_jtwc\n",
    "        winddict = landfalldata_wind_GD_jtwc\n",
    "        r18dict = r18dict_GD_jtwc\n",
    "    elif source == 1:\n",
    "        pressuredict = landfalldata_pres_GD_cma\n",
    "        winddict = landfalldata_wind_GD_cma\n",
    "        r18dict = r18dict_GD_cma\n",
    "    elif source == 2:\n",
    "        pressuredict = landfalldata_pres_GD_wmo\n",
    "        winddict = landfalldata_wind_GD_wmo\n",
    "        r18dict = {}\n",
    "   \n",
    "    tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    print(tcindexes)\n",
    "    \n",
    "    pdlist = []\n",
    "    windlist = []\n",
    "    rainfall_total_list = []\n",
    "    r18list = []\n",
    "    damagelist = []\n",
    "    for tc in tcindexes:\n",
    "        print(tc)\n",
    "        if death_or_damage == 0:\n",
    "            damage = damagedict[str(tc)][0]\n",
    "        else:\n",
    "            damage = damagedict[str(tc)][1]\n",
    "        if damage != 0:\n",
    "            if str(tc) in winddict.keys() and str(tc) in r18dict.keys() and str(tc) in pressuredict.keys():\n",
    "            #if True:\n",
    "                if 'r18' in variables:\n",
    "                    if r18dict[str(tc)] != []:\n",
    "                        r18 = r18dict[str(tc)][1] #Get TC R18 after landfall\n",
    "                        if type(r18) != str:\n",
    "                            r18list.append(r18)\n",
    "                        else:\n",
    "                            r18list.append(0)\n",
    "                    else:\n",
    "                        r18list.append(0)\n",
    "                if 'pd' in variables:\n",
    "                    pres = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "                    pd = 1010-pres\n",
    "                    pdlist.append(pd)\n",
    "                if 'wind' in variables:\n",
    "                    wind = winddict[str(tc)][1]\n",
    "                    windlist.append(wind)\n",
    "                if 'rain' in variables:\n",
    "                    rainfall_list = rainfall_distribution(1, source, tc, only_on_land)[1]\n",
    "                    total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                    rainfall_total_list.append(total_rainfall) \n",
    "                damagelist.append(damage)\n",
    "                \n",
    "    \n",
    "    if 'r18' in variables:\n",
    "        r18_zeros = np.where(np.asarray(r18list) == 0) #Remove R18 missing data\n",
    "        r18_zeros = list(r18_zeros[0])\n",
    "\n",
    "        if r18_zeros != []:\n",
    "            damagelist_index = [i for i in range(len(damagelist)) if i not in r18_zeros]\n",
    "            damagelist_new = []\n",
    "            for i in damagelist_index:\n",
    "                damagelist_new.append(damagelist[i])\n",
    "            damagelist = damagelist_new\n",
    "            r18list_index = [i for i in range(len(r18list)) if i not in r18_zeros]\n",
    "            r18list_new = []\n",
    "            for i in r18list_index:\n",
    "                r18list_new.append(r18list[i])\n",
    "            r18list = r18list_new\n",
    "            if 'pd' in variables:\n",
    "                pdlist_index = [i for i in range(len(pdlist)) if i not in r18_zeros]\n",
    "                pdlist_new = []\n",
    "                for i in pdlist_index:\n",
    "                    pdlist_new.append(pdlist[i])\n",
    "                pdlist = pdlist_new\n",
    "            if 'rain' in variables:\n",
    "                rainfall_total_list = [x for x in rainfall_total_list if rainfall_total_list.index(x) not in r18_zeros]\n",
    "            if 'wind' in variables:\n",
    "                windlist_index = [i for i in range(len(windlist)) if i not in r18_zeros]\n",
    "                windlist_new = []\n",
    "                for i in windlist_index:\n",
    "                    windlist_new.append(windlist[i])\n",
    "                windlist = windlist_new\n",
    "\n",
    "    \n",
    "    pdlist = np.asarray(pdlist)\n",
    "    windlist = np.asarray(windlist)\n",
    "    rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "    r18list = np.asarray(r18list)\n",
    "    \n",
    "    variableslist = 0\n",
    "    if logvariables == True:\n",
    "        if 'pd' in variables:\n",
    "            if death_or_damage == 0:\n",
    "                if source == 0:\n",
    "                    slope_pd = 0.3227 #Slope obtained from previous individual plots\n",
    "                elif source == 1:\n",
    "                    slope_pd = 0.4848         \n",
    "            elif death_or_damage == 1:\n",
    "                if source == 0:\n",
    "                    slope_pd = 2.5911\n",
    "                else:\n",
    "                    slope_pd = 2.6996\n",
    "            pdlist = np.log(pdlist**slope_pd)\n",
    "            variableslist += pdlist\n",
    "        if 'wind' in variables:\n",
    "            if death_or_damage == 0:\n",
    "                if source == 0:\n",
    "                    slope_wind = -0.0216\n",
    "                elif source == 1:\n",
    "                    slope_wind = 0.8079\n",
    "            elif death_or_damage == 1:\n",
    "                if source == 0:\n",
    "                    slope_wind = 2.8713\n",
    "                elif source == 1:\n",
    "                    slope_wind = 4.3707\n",
    "            windlist = np.log(windlist**slope_wind)\n",
    "            variableslist += windlist\n",
    "        if 'rain' in variables:\n",
    "            if death_or_damage == 0:\n",
    "                if source == 0:\n",
    "                    slope_rain = 0.1287\n",
    "                elif source == 1:\n",
    "                    slope_rain = 0.1275\n",
    "            elif death_or_damage == 1:\n",
    "                if source == 0:\n",
    "                    slope_rain = 1.569\n",
    "                elif source == 1:\n",
    "                    slope_rain = 1.4513\n",
    "            rainfall_total_list = np.log(rainfall_total_list**slope_rain)\n",
    "            variableslist += rainfall_total_list\n",
    "        if 'r18' in variables:\n",
    "            if death_or_damage == 0:\n",
    "                if source == 0:\n",
    "                    slope_r18 = 1.406\n",
    "                else:\n",
    "                    slope_r18 = -4.1063\n",
    "            elif death_or_damage == 1:\n",
    "                if source == 0:\n",
    "                    slope_r18 = 2.2525\n",
    "                else:\n",
    "                    slope_r18 = 2.9373\n",
    "            r18list = np.log(r18list**slope_r18)\n",
    "            variableslist += r18list\n",
    "    if logdamage == True:\n",
    "        damagelist = np.log(damagelist)\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(variableslist, damagelist,color='b')\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(variableslist, damagelist) #Linear fit\n",
    "    xrange = np.linspace(min(variableslist),max(variableslist),100)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(variableslist)\n",
    "    \n",
    "    if logvariables == True:\n",
    "        plt.xlabel('log(sum of variables)')\n",
    "    else:\n",
    "        plt.xlabel('Sum of variables')\n",
    "    if death_or_damage == 1:\n",
    "        if logdamage == True:\n",
    "            plt.ylabel('log(damage)')\n",
    "        else:\n",
    "            plt.ylabel('Damage (USD)')\n",
    "    else:\n",
    "        if logdamage == True:\n",
    "            plt.ylabel('log(total deaths)')\n",
    "        else:\n",
    "            plt.ylabel('Total deaths')\n",
    "    if death_or_damage == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Total deaths against ' + str(variables) + ' of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Total deaths against ' + str(variables) + ' of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Total deaths against ' + str(variables) + ' of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Damage against ' + str(variables) + ' of TC when making landfall in Guangdong, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 1:\n",
    "            plt.title('Damage against ' + str(variables) + ' of TC when making landfall in Guangdong, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "        elif source == 2:\n",
    "            plt.title('Damage against ' + str(variables) + ' of TC when making landfall in Guangdong, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize = 'x-small')\n",
    "    plt.show()\n",
    "    \n",
    "    return variableslist, damagelist, slope, intercept, rvalue, pvalue, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time() #Expect longer runtime if 'rain' involved\n",
    "plot_damage_pdwindrainr18(variables=['pd','rain'],source=0,logvariables=True,logdamage=True,intersect=False,death_or_damage=1,only_on_land=False)\n",
    "plot_damage_pdwindrainr18(variables=['wind','rain'],source=0,logvariables=True,logdamage=True,intersect=False,death_or_damage=1,only_on_land=False)\n",
    "#plot_damage_pdwindrainr18(variables=['pd','rain','r18'],source=0,logvariables=True,logdamage=True,intersect=False,death_or_damage=1,only_on_land=False)\n",
    "#plot_damage_pdwindrainr18(variables=['wind','rain','r18'],source=0,logvariables=True,logdamage=True,intersect=False,death_or_damage=1,only_on_land=False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pd vs max wind speed\n",
    "def plot_pd_windspeed(area, source, logscale = False, intersect = False):\n",
    "    windspeed_dict = get_landfall_data_beforeandafter(area, source, False)[1]\n",
    "    pressure_dict = get_landfall_data_beforeandafter(area,source, False)[0]\n",
    "    windspeed_before_list = []\n",
    "    windspeed_after_list = []\n",
    "    pres_before_list = []\n",
    "    pres_after_list = []\n",
    "    key_intersect1_list = np.intersect1d(list(get_landfall_data_beforeandafter(area,0,False)[1].keys()), list(get_landfall_data_beforeandafter(area,1,False)[1].keys()))\n",
    "    key_intersect2_list = np.intersect1d(key_intersect1_list, list(get_landfall_data_beforeandafter(area,2,False)[1].keys()))\n",
    "    key_intersect3_list = np.intersect1d(key_intersect2_list, list(get_landfall_data_beforeandafter(area,0,False)[0].keys()))\n",
    "    key_intersect4_list = np.intersect1d(key_intersect3_list, list(get_landfall_data_beforeandafter(area,1,False)[0].keys()))\n",
    "    key_intersect5_list = np.intersect1d(key_intersect4_list, list(get_landfall_data_beforeandafter(area,2,False)[0].keys()))\n",
    "    \n",
    "    if intersect == False:\n",
    "        pres_wind_intersect = np.intersect1d(list(pressure_dict.keys()),list(windspeed_dict.keys()))\n",
    "    else:\n",
    "        pres_wind_intersect = key_intersect5_list\n",
    "        \n",
    "    for key in pres_wind_intersect:\n",
    "        if len(windspeed_dict[key]) == 1 and windspeed_dict[key][0] != 0: \n",
    "            pres_after = pressure_dict[key][0]\n",
    "            pd = 1010-pres_after\n",
    "            if pd == 0:\n",
    "                pres_after_list.append(1) #Prevent log(0) --> this will give log(pd) = 0\n",
    "            else:\n",
    "                pres_after_list.append(pd)\n",
    "            windspeed_after_list. append(windspeed_dict[key][0])\n",
    "        elif len(windspeed_dict[key]) != 1 and windspeed_dict[key][1] != 0: \n",
    "            windspeed_before_list.append(windspeed_dict[key][0])\n",
    "            windspeed_after_list.append(windspeed_dict[key][1])  \n",
    "            pres_before = pressure_dict[key][0]\n",
    "            pres_after = pressure_dict[key][1]\n",
    "            pdbefore = 1010-pres_before\n",
    "            pdafter = 1010-pres_after\n",
    "            if pdbefore == 0:\n",
    "                pres_before_list.append(1)\n",
    "            else:\n",
    "                pres_before_list.append(pdbefore)\n",
    "            if pdafter == 0:\n",
    "                pres_after_list.append(1)\n",
    "            else:\n",
    "                pres_after_list.append(pdafter)\n",
    "    \n",
    "    pres_before_list = np.asarray(pres_before_list)\n",
    "    pres_after_list = np.asarray(pres_after_list)\n",
    "    windspeed_before_list = np.asarray(windspeed_before_list)\n",
    "    windspeed_after_list = np.asarray(windspeed_after_list)\n",
    "    \n",
    "    if logscale == True:\n",
    "        pres_before_list = np.log(pres_before_list)\n",
    "        pres_after_list = np.log(pres_after_list)\n",
    "        windspeed_before_list = np.log(windspeed_before_list)\n",
    "        windspeed_after_list = np.log(windspeed_after_list)\n",
    "         \n",
    "    plt.figure()\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(pres_after_list, windspeed_after_list) #Linear fit\n",
    "    xrange = np.linspace(min(pres_after_list),max(pres_after_list),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(pres_after_list)\n",
    "    \n",
    "    if logscale == True:\n",
    "        plt.xlabel('log(pressure deficit)')\n",
    "        plt.ylabel('log(wind speed)') \n",
    "    else:\n",
    "        plt.xlabel('Pressure deficit(hPa)')\n",
    "        plt.ylabel('Wind Speed (kt)') \n",
    "    plt.scatter(pres_after_list, windspeed_after_list,color = 'k') \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in Philippines, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in Philippines, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in Philippines, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "    else:    \n",
    "        if source == 0:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in GD, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in GD, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in GD, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pd_windspeed(1, 0, True, True)\n",
    "plot_pd_windspeed(1, 1, True, True)\n",
    "plot_pd_windspeed(1, 2, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''INCOMPLETE'''\n",
    "#Plot r18 vs max wind speed\n",
    "def plot_r18_windspeed(area, source, logscale = False):\n",
    "    windspeed_dict = get_landfall_data_beforeandafter(area, source, False)[1]\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            r18_dict = r18dict_PHI_jtwc\n",
    "        else:\n",
    "            r18_dict = r18dict_PHI_cma\n",
    "    else:\n",
    "        if source == 0:\n",
    "            r18_dict = r18dict_GD_jtwc\n",
    "        else:\n",
    "            r18_dict = r18dict_GD_cma\n",
    "    windspeed_before_list = []\n",
    "    windspeed_after_list = []\n",
    "    pres_before_list = []\n",
    "    pres_after_list = []\n",
    "    key_intersect1_list = np.intersect1d(list(get_landfall_data_beforeandafter(area,0,False)[1].keys()), list(get_landfall_data_beforeandafter(area,1,False)[1].keys()))\n",
    "    key_intersect2_list = np.intersect1d(key_intersect1_list, list(get_landfall_data_beforeandafter(area,2,False)[1].keys()))\n",
    "    key_intersect3_list = np.intersect1d(key_intersect2_list, list(get_landfall_data_beforeandafter(area,0,False)[0].keys()))\n",
    "    key_intersect4_list = np.intersect1d(key_intersect3_list, list(get_landfall_data_beforeandafter(area,1,False)[0].keys()))\n",
    "    key_intersect5_list = np.intersect1d(key_intersect4_list, list(get_landfall_data_beforeandafter(area,2,False)[0].keys()))\n",
    "    for key in key_intersect5_list:\n",
    "        if len(windspeed_dict[key]) == 1: \n",
    "            windspeed_after_list. append(windspeed_dict[key][0])\n",
    "        else: \n",
    "            windspeed_before_list.append(windspeed_dict[key][0])\n",
    "            windspeed_after_list.append(windspeed_dict[key][1])  \n",
    "        if len(pressure_dict[key]) == 1: \n",
    "            pres_after = pressure_dict[key][0]\n",
    "            pres_after_list.append(1010-pres_after)\n",
    "        else: \n",
    "            pres_before = pressure_dict[key][0]\n",
    "            pres_after = pressure_dict[key][1]\n",
    "            pres_before_list.append(1010-pres_before)\n",
    "            pres_after_list.append(1010-pres_after)\n",
    "    \n",
    "    pres_before_list = np.asarray(pres_before_list)\n",
    "    pres_after_list = np.asarray(pres_after_list)\n",
    "    windspeed_before_list = np.asarray(windspeed_before_list)\n",
    "    windspeed_after_list = np.asarray(windspeed_after_list)\n",
    "    \n",
    "    if logscale == True:\n",
    "        pres_before_list = np.log(pres_before_list)\n",
    "        pres_after_list = np.log(pres_after_list)\n",
    "        windspeed_before_list = np.log(windspeed_before_list)\n",
    "        windspeed_after_list = np.log(windspeed_after_list)\n",
    "         \n",
    "    plt.figure()\n",
    "    slope, intercept, rvalue, pvalue, stderr = linregress(pres_after_list, windspeed_after_list) #Linear fit\n",
    "    xrange = np.linspace(min(pres_after_list),max(pres_after_list),1000)\n",
    "    plt.plot(xrange, slope*xrange + intercept, 'r-') #Plot linear fit\n",
    "    samplesize = len(pres_after_list)\n",
    "    if logscale == True:\n",
    "        plt.xlabel('log(pressure deficit)')\n",
    "        plt.ylabel('log(wind speed)') \n",
    "    else:\n",
    "        plt.xlabel('Pressure deficit(hPa)')\n",
    "        plt.ylabel('Wind Speed (kt)') \n",
    "    plt.scatter(pres_after_list, windspeed_after_list,color = 'k') \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in Philippines, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in Philippines, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in Philippines, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "    else:    \n",
    "        if source == 0:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in GD, source: JTWC \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in GD, source: CMA \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Maximum wind speed against central pressure deficit of typhoons at their landfalls in GD, source: WMO \\n sample size = ' + str(samplesize) + ', slope = ' + str(slope) + r'$\\pm$' + str(stderr) + ', intercept = ' + str(intercept) + '\\n r-value = ' + str(rvalue) + ', R-squared = ' + str(rvalue**2) + ', p-value = ' + str(pvalue),fontsize='small')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all variables on same plot (for GD)\n",
    "def plot_variables_sameplot(source, dvariable, area = 1, ivariables = ['pd', 'wind', 'rain', 'r18']):\n",
    "#dvariable is dependant variable, takes either 'rain', 'damage' or 'death'\n",
    "#ivariables is list of independent variables, takes a list with elements 'pd', 'wind', 'rain' and/or 'r18'\n",
    "\n",
    "    plt.figure()\n",
    "    if dvariable == 'rain': #Plotting rain against variables\n",
    "        \n",
    "        if 'pd' in ivariables: #Include pressure deficit in plot\n",
    "            if area == 0:\n",
    "                if source == 0:\n",
    "                    pressuredict = landfalldata_pres_PHI2014_jtwc.copy()\n",
    "                elif source == 1:\n",
    "                    pressuredict = landfalldata_pres_PHI2014_cma.copy()\n",
    "                elif source == 2:\n",
    "                    pressuredict = landfalldata_pres_PHI2014_wmo.copy()\n",
    "\n",
    "                pressuredict.pop('12566', None) #No rainfall data for 12566\n",
    "                pressuredict.pop('12580', None) #No rainfall data for 12580\n",
    "            else:\n",
    "                if source == 0:\n",
    "                    pressuredict = landfalldata_pres_GD2014_jtwc.copy()\n",
    "                elif source == 1:\n",
    "                    pressuredict = landfalldata_pres_GD2014_cma.copy()\n",
    "                elif source == 2:\n",
    "                    pressuredict = landfalldata_pres_GD2014_wmo.copy()\n",
    "\n",
    "                pressuredict.pop('12860', None) #12860 rainfall data not included\n",
    "                \n",
    "            print(list(pressuredict.keys()))\n",
    "            tcindexes_pres = np.asarray(list(pressuredict.keys()), dtype=int)\n",
    "            \n",
    "            pdlist = []\n",
    "            rainfall_total_list = []\n",
    "            \n",
    "            for tc in tcindexes_pres:\n",
    "                print(tc)\n",
    "                rainfall_list = rainfall_distribution(area, source, tc, only_on_land=False)[1]\n",
    "                total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                rainfall_total_list.append(total_rainfall)\n",
    "                pressure = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "                pd = 1011-pressure #Reference set to 1020 to prevent log(0)\n",
    "                pdlist.append(pd)\n",
    "                \n",
    "            pdlist = np.asarray(pdlist)\n",
    "            rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "\n",
    "            logpdlist = np.log(pdlist)\n",
    "            lograinfalllist = np.log(rainfall_total_list)\n",
    "\n",
    "            plt.scatter(logpdlist, lograinfalllist,color='r',label = 'Pressure deficit (hPa)')\n",
    "            slope, intercept, rvalue, pvalue, stderr = linregress(logpdlist, lograinfalllist) #Linear fit\n",
    "            xrange = np.linspace(min(logpdlist),max(logpdlist),1000)\n",
    "            plt.plot(xrange, slope*xrange + intercept, 'r--') #Plot linear fit\n",
    "#             samplesize = len(lograinfalllist)\n",
    "                \n",
    "                \n",
    "        if 'r18' in ivariables: #Include R18 in plot\n",
    "            if area == 0:\n",
    "                if source == 0:\n",
    "                    r18dict = r18dict_PHI_jtwc.copy()\n",
    "                elif source == 1:\n",
    "                    r18dict = r18dict_PHI_cma.copy()\n",
    "            else:\n",
    "                if source == 0:\n",
    "                    r18dict = r18dict_GD_jtwc_2014.copy()\n",
    "                elif source == 1:\n",
    "                    r18dict = r18dict_GD_cma.copy()\n",
    "                    \n",
    "            print(list(r18dict.keys()))\n",
    "            tcindexes_r18 = np.asarray(list(r18dict.keys()), dtype=int)\n",
    "            \n",
    "            rainfall_total_list = []\n",
    "            r18list = []\n",
    "            \n",
    "            for tc in tcindexes_r18:\n",
    "                print(tc)\n",
    "                if r18dict[str(tc)] != []:\n",
    "                    r18 = r18dict[str(tc)][1] #Get TC R18 after landfall\n",
    "                    if type(r18) != str:\n",
    "                        r18list.append(r18)\n",
    "                        rainfall_list = rainfall_distribution(area, source, tc, only_on_land=False)[1]\n",
    "                        total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                        rainfall_total_list.append(total_rainfall)\n",
    "            \n",
    "            r18list = np.asarray(r18list)\n",
    "            rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "\n",
    "            logr18list = np.log(r18list)\n",
    "            lograinfalllist = np.log(rainfall_total_list)\n",
    "\n",
    "            plt.scatter(logr18list, lograinfalllist,color='b',label = 'R18 (km)')\n",
    "            slope, intercept, rvalue, pvalue, stderr = linregress(logr18list, lograinfalllist) #Linear fit\n",
    "            xrange = np.linspace(min(logr18list),max(logr18list),1000)\n",
    "            plt.plot(xrange, slope*xrange + intercept, 'b--') #Plot linear fit\n",
    "#             samplesize = len(lograinfalllist)\n",
    "\n",
    "    elif dvariable == 'damage' or dvariable == 'deaths': #Plot damage or deaths\n",
    "        if area == 1:\n",
    "            if 'pd' in ivariables:\n",
    "                damagedict = damage_GD\n",
    "                if source == 0:\n",
    "                    pressuredict = landfalldata_pres_GD_jtwc\n",
    "                elif source == 1:\n",
    "                    pressuredict = landfalldata_pres_GD_cma\n",
    "                elif source == 2:\n",
    "                    pressuredict = landfalldata_pres_GD_wmo\n",
    "                    \n",
    "                tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    \n",
    "                damagelist = []\n",
    "                pdlist = []\n",
    "                for tc in tcindexes:\n",
    "                    if dvariable == 'damage':\n",
    "                        damage = damagedict[str(tc)][1] #Get damage in USD\n",
    "                    elif dvariable == 'deaths':\n",
    "                        damage = damagedict[str(tc)][0] #Get death no.\n",
    "                    if damage != 0 and str(tc) in pressuredict.keys():\n",
    "                        pres = pressuredict[str(tc)][1] #Get TC pressure after landfall\n",
    "                        pd = 1010-pres\n",
    "                        pdlist.append(pd)\n",
    "                        damagelist.append(damage)\n",
    "                \n",
    "                pdlist = np.asarray(pdlist)\n",
    "                damagelist = np.asarray(damagelist)\n",
    "\n",
    "                damagelist = np.log(damagelist)\n",
    "                pdlist = np.log(pdlist)\n",
    "                \n",
    "                plt.scatter(pdlist, damagelist,color='r',s=15, label = 'Pressure deficit (hPa)')\n",
    "                slope, intercept, rvalue, pvalue, stderr = linregress(pdlist, damagelist) #Linear fit\n",
    "                xrange = np.linspace(min(pdlist),max(pdlist),1000)\n",
    "                plt.plot(xrange, slope*xrange + intercept, 'r--') #Plot linear fit\n",
    "#                 samplesize = len(damagelist)\n",
    "\n",
    "            if 'wind' in ivariables:\n",
    "                damagedict = damage_GD\n",
    "                if source == 0:\n",
    "                    winddict = landfalldata_wind_GD_jtwc\n",
    "                elif source == 1:\n",
    "                    winddict = landfalldata_wind_GD_cma\n",
    "                elif source == 2:\n",
    "                    winddict = landfalldata_wind_GD_wmo\n",
    "                    \n",
    "                tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "    \n",
    "                damagelist = []\n",
    "                windlist = []\n",
    "                for tc in tcindexes:\n",
    "                    if dvariable == 'damage':\n",
    "                        damage = damagedict[str(tc)][1]\n",
    "                    elif dvariable == 'deaths':\n",
    "                        damage = damagedict[str(tc)][0]\n",
    "                    if damage != 0 and str(tc) in winddict.keys():\n",
    "                        if len(winddict[str(tc)]) == 1:\n",
    "                            wind = winddict[str(tc)][0] #Get TC max wind after landfall\n",
    "                        elif len(winddict[str(tc)]) == 2:\n",
    "                            wind = winddict[str(tc)][1] #Get TC max wind after landfall\n",
    "                        windlist.append(wind)\n",
    "                        damagelist.append(damage)\n",
    "\n",
    "\n",
    "                windlist = np.asarray(windlist)\n",
    "                damagelist = np.asarray(damagelist)\n",
    "\n",
    "                windlist = np.log(windlist)\n",
    "                damagelist = np.log(damagelist)\n",
    "                \n",
    "                plt.scatter(windlist, damagelist,color='y',s=15, label = 'Maximum wind speed (kts)')\n",
    "                slope, intercept, rvalue, pvalue, stderr = linregress(windlist, damagelist) #Linear fit\n",
    "                xrange = np.linspace(min(windlist),max(windlist),1000)\n",
    "                plt.plot(xrange, slope*xrange + intercept, 'y--') #Plot linear fit\n",
    "#                 samplesize = len(damagelist)\n",
    "\n",
    "            if 'rain' in ivariables:\n",
    "                damagedict = damage_GD_after2014\n",
    "                print(list(damagedict.keys()))\n",
    "                tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "\n",
    "                damagelist = []\n",
    "                rainfall_total_list = []\n",
    "                for tc in tcindexes:\n",
    "                    print(tc)\n",
    "                    if dvariable == 'damage':\n",
    "                        damage = damagedict[str(tc)][1]\n",
    "                    elif dvariable == 'deaths':\n",
    "                        damage = damagedict[str(tc)][0]\n",
    "                    if damage != 0:\n",
    "                        if (source == 0 and str(tc) in landfalldata_coord_GD2014_jtwc.keys()) or (source == 1 and str(tc) in landfalldata_coord_GD2014_cma.keys()) :\n",
    "                            damagelist.append(damage)\n",
    "                            rainfall_list = rainfall_distribution(1, source, tc, only_on_land=False)[1]\n",
    "                            total_rainfall = sum(rainfall_list) #Total rainfall within 500km of TC centre\n",
    "                            rainfall_total_list.append(total_rainfall/1000)\n",
    "\n",
    "\n",
    "                rainfall_total_list = np.asarray(rainfall_total_list)\n",
    "                damagelist = np.asarray(damagelist)\n",
    "\n",
    "                rainfall_total_list = np.log(rainfall_total_list)\n",
    "                damagelist = np.log(damagelist)\n",
    "                \n",
    "                plt.scatter(rainfall_total_list, damagelist,color='g',s=15,label='Daily rainfall within 500km of TC centre (m)')\n",
    "                slope, intercept, rvalue, pvalue, stderr = linregress(rainfall_total_list, damagelist) #Linear fit\n",
    "                xrange = np.linspace(min(rainfall_total_list),max(rainfall_total_list),1000)\n",
    "                plt.plot(xrange, slope*xrange + intercept, 'g--') #Plot linear fit\n",
    "#                 samplesize = len(damagelist)\n",
    "\n",
    "            if 'r18' in ivariables:\n",
    "                damagedict = damage_GD\n",
    "                if source == 0:\n",
    "                    r18dict = r18dict_GD_jtwc\n",
    "                elif source == 1:\n",
    "                    r18dict = r18dict_GD_cma\n",
    "\n",
    "                tcindexes = np.asarray(list(damagedict.keys()), dtype=int)\n",
    "\n",
    "                damagelist = []\n",
    "                r18list = []\n",
    "                for tc in tcindexes:\n",
    "                    if dvariable == 'damage':\n",
    "                        damage = damagedict[str(tc)][1]\n",
    "                    else:\n",
    "                        damage = damagedict[str(tc)][0]\n",
    "                    if str(tc) in r18dict.keys():\n",
    "                        if r18dict[str(tc)] != []:\n",
    "                            r18 = r18dict[str(tc)][1] #Get TC R18 after landfall\n",
    "                            if type(r18) != str and damage != 0 and str(tc) in r18dict.keys():\n",
    "                                r18list.append(r18)\n",
    "                                damagelist.append(damage)\n",
    "\n",
    "                r18list = np.asarray(r18list)\n",
    "                damagelist = np.asarray(damagelist)\n",
    "\n",
    "                r18list = np.log(r18list)\n",
    "                damagelist = np.log(damagelist)\n",
    "\n",
    "                plt.scatter(r18list, damagelist,color='b',s=15, label = 'R18 (km)')\n",
    "                slope, intercept, rvalue, pvalue, stderr = linregress(r18list, damagelist) #Linear fit\n",
    "                xrange = np.linspace(min(r18list),max(r18list),1000)\n",
    "                plt.plot(xrange, slope*xrange + intercept, 'b--') #Plot linear fit\n",
    "#                 samplesize = len(damagelist)\n",
    "    \n",
    "    plt.xlabel('log(variable)')\n",
    "    plt.ylabel('log(' + str(dvariable) + ')')\n",
    "    if dvariable == 'rain':\n",
    "        plt.legend(fontsize='small')\n",
    "    elif dvariable == 'damage':\n",
    "        plt.legend(fontsize='x-small')\n",
    "    elif dvariable == 'deaths':\n",
    "        plt.legend(fontsize='xx-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_variables_sameplot(source=0,ivariables=['pd','wind','rain','r18'],dvariable = 'damage')\n",
    "#plot_variables_sameplot(source=0,ivariables=['pd','wind','rain','r18'],dvariable = 'deaths')\n",
    "#plot_variables_sameplot(source=1,ivariables=['pd','r18'],dvariable = 'rain')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
