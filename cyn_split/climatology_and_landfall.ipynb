{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using 'all' file instead of 'wmo' file\"\"\"\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from netCDF4 import Dataset,num2date\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm, poisson, lognorm, chisquare, linregress, ttest_ind, power_divergence, ks_2samp, chi2_contingency\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import factorial\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib tk    #Uncomment for interactive figures\n",
    "import geopy.distance as gd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "path_to_data = os.path.join('data')\n",
    "\n",
    "ibt = dict() \n",
    "#loaded variables from cell 2 of Year3Projectfinal.ipynb which are used later in code\n",
    "#from ibtracs database and etopo1 global relief model\n",
    "\n",
    "for filename in os.listdir(path_to_data):\n",
    "    if filename.endswith('.pickle'):\n",
    "        path_to_file = os.path.join(path_to_data, filename)\n",
    "        with open(path_to_file,'rb') as f:\n",
    "            ibt[filename[:-7]] = pkl.load(f) # d[key] = value, where key is filename str w/o '.pickle'\n",
    "            #expected usage example: ibtracs_and_landmask['lat']\n",
    "toc = time.perf_counter()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract PHI data\n",
    "tic = time.time() #Expect runtime ~3min\n",
    "\n",
    "#Input extreme point = [x,y]\n",
    "extremeP_N = [122.9, 19.2]\n",
    "extremeP_S = [122.6, 3.5]\n",
    "extremeP_E = [128.2, 6.2]\n",
    "extremeP_W = [117.4, 18.1]\n",
    "\n",
    "#Slope of lines bounding region\n",
    "m_top_P = (extremeP_N[1]-extremeP_W[1])/(extremeP_N[0]-extremeP_W[0])\n",
    "m_bot_P = (extremeP_S[1]-extremeP_E[1])/(extremeP_S[0]-extremeP_E[0])\n",
    "m_left_P = (extremeP_S[1]-extremeP_W[1])/(extremeP_S[0]-extremeP_W[0])\n",
    "m_right_P = (extremeP_N[1]-extremeP_E[1])/(extremeP_N[0]-extremeP_E[0])\n",
    "\n",
    "#Intercept of lines\n",
    "c_top_P = extremeP_N[1]-m_top_P*extremeP_N[0]\n",
    "c_bot_P = extremeP_S[1]-m_bot_P*extremeP_S[0]\n",
    "c_left_P = extremeP_S[1]-m_left_P*extremeP_S[0]\n",
    "c_right_P = extremeP_N[1]-m_right_P*extremeP_N[0]\n",
    "\n",
    "#Get points in land mask file which are in PHI area\n",
    "def philippine_landmask_points(landmask_LON,landmask_LAT):\n",
    "    landmask_points = []\n",
    "    \n",
    "    for i in range(17400,18500): \n",
    "        for i2 in range(5600,6600):\n",
    "            equation_top = m_top_P * landmask_LON[i,i2] + c_top_P\n",
    "            equation_bot = m_bot_P * landmask_LON[i,i2] + c_bot_P \n",
    "            equation_left = m_left_P * landmask_LON[i,i2] + c_left_P \n",
    "            equation_right  = m_right_P * landmask_LON[i,i2] + c_right_P\n",
    "    \n",
    "            if landmask_LAT[i,i2] <= equation_top and landmask_LAT[i,i2] <= equation_right and landmask_LAT[i,i2] >= equation_bot and landmask_LAT[i,i2] >= equation_left:\n",
    "                landmask_points.append(i)\n",
    "                landmask_points.append(i2)\n",
    "        \n",
    "    return landmask_points\n",
    "    \n",
    "#Get TC centre points in PHI area\n",
    "def philippine_data_extraction(LON,LAT,after2014=False,separate_NS=False): \n",
    "    #after2014: True means only include TC data after 2014\n",
    "    #Separate NS: If you want to separate PHI into Northern and Southern parts, type 'N' or 'S' respectively,\n",
    "    #    otherwise, or for GD, type 'False'\n",
    "    \n",
    "    philippine_data = []\n",
    "    PHI_TCposition = {}\n",
    "    \n",
    "    philippine_data_N = []\n",
    "    philippine_data_S = []\n",
    "    PHI_TCposition_N = {}\n",
    "    PHI_TCposition_S = {}\n",
    "    \n",
    "    if separate_NS == False:\n",
    "        for i in range (len(LON)):\n",
    "            PHI_TCposition[str(i)] = []\n",
    "            for i2 in range (len(LON[i])): \n",
    "                equation_top = m_top_P * LON[i,i2] + c_top_P\n",
    "                equation_bot = m_bot_P * LON[i,i2] + c_bot_P \n",
    "                equation_left = m_left_P * LON[i,i2] + c_left_P \n",
    "                equation_right  = m_right_P * LON[i,i2] + c_right_P\n",
    "\n",
    "                if after2014 == True:\n",
    "                    if i in TCinseason and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data.append((i))\n",
    "                        PHI_TCposition[str(i)].append(i2)\n",
    "                else:\n",
    "                    if LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data.append((i))\n",
    "                        PHI_TCposition[str(i)].append(i2)\n",
    "                        \n",
    "        return np.unique(philippine_data), PHI_TCposition\n",
    "                    \n",
    "    elif separate_NS == True:\n",
    "        NSlatboundary = 14.4 #Set latitude for dividing into North and South\n",
    "        for i in range(len(LON)):\n",
    "            PHI_TCposition_N[str(i)] = []\n",
    "            PHI_TCposition_S[str(i)] = []\n",
    "            for i2 in range (len(LON[i])): \n",
    "                equation_top = m_top_P * LON[i,i2] + c_top_P #Equation of straight line\n",
    "                equation_bot = m_bot_P * LON[i,i2] + c_bot_P \n",
    "                equation_left = m_left_P * LON[i,i2] + c_left_P \n",
    "                equation_right  = m_right_P * LON[i,i2] + c_right_P\n",
    "                \n",
    "                #Check to see if a point is inside the boundary\n",
    "                if after2014 == True:\n",
    "                    if i in TCinseason and LAT[i,i2] > NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_N.append((i))\n",
    "                        PHI_TCposition_N[str(i)].append(i2)\n",
    "                    elif i in TCinseason and LAT[i,i2] <= NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_S.append((i))\n",
    "                        PHI_TCposition_S[str(i)].append(i2)\n",
    "\n",
    "                else:\n",
    "                    if LAT[i,i2] > NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_N.append((i))\n",
    "                        PHI_TCposition_N[str(i)].append(i2)\n",
    "                    elif LAT[i,i2] <= NSlatboundary and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                        philippine_data_S.append((i))\n",
    "                        PHI_TCposition_S[str(i)].append(i2)\n",
    "                    \n",
    "        return np.unique(philippine_data_N), np.unique(philippine_data_S), PHI_TCposition_N, PHI_TCposition_S\n",
    "                \n",
    "\n",
    "landmask_in_area_PHI = np.array(philippine_landmask_points(landmask_LON,landmask_LAT))\n",
    "landmask_in_area_PHI = landmask_in_area_PHI.reshape(int(len(landmask_in_area_PHI)/2),2)\n",
    "\n",
    "z_coastline_PHI = [] #Find PHI coastline from land mask (this list contains index of elements)\n",
    "z_land_PHI = [] #Find PHI land points from land mask\n",
    "for i in range(len(landmask_in_area_PHI)):\n",
    "    if z[landmask_in_area_PHI[i,1],landmask_in_area_PHI[i,0]] == 0: #Coast if altitude == 0\n",
    "        z_coastline_PHI.append(landmask_in_area_PHI[i,0])\n",
    "        z_coastline_PHI.append(landmask_in_area_PHI[i,1])\n",
    "    elif z[landmask_in_area_PHI[i,1],landmask_in_area_PHI[i,0]] >= 0: #Land if altitude >= 0\n",
    "        z_land_PHI.append(landmask_in_area_PHI[i,0])\n",
    "        z_land_PHI.append(landmask_in_area_PHI[i,1])\n",
    "        \n",
    "z_coastline_PHI = np.asarray(z_coastline_PHI).reshape(int(len(z_coastline_PHI)/2),2)\n",
    "z_land_PHI = np.asarray(z_land_PHI).reshape(int(len(z_land_PHI)/2),2)\n",
    "\n",
    "z_coastline_coord_PHI = np.zeros(z_coastline_PHI.shape) #list of coordinates of PHI coastline (change index to actual coordinates)\n",
    "z_coastline_coord_PHI[:,0] = landmask_lon[z_coastline_PHI[:,0]]\n",
    "z_coastline_coord_PHI[:,1] = landmask_lat[z_coastline_PHI[:,1]]\n",
    "\n",
    "z_land_coord_PHI = np.zeros(z_land_PHI.shape) #List of coordinates of PHI land\n",
    "z_land_coord_PHI[:,0] = landmask_lon[z_land_PHI[:,0]]\n",
    "z_land_coord_PHI[:,1] = landmask_lat[z_land_PHI[:,1]]\n",
    "\n",
    "landfallTC_PHI_jtwc = philippine_data_extraction(LON[:,:,0],LAT[:,:,0])[0] #list (keys)\n",
    "landfallTC_PHI_jtwc_after2014 = philippine_data_extraction(LON[:,:,0],LAT[:,:,0], True)[0]\n",
    "landfallTC_PHI_cma = philippine_data_extraction(LON[:,:,1],LAT[:,:,1])[0] #list (keys)\n",
    "landfallTC_PHI_cma_after2014 = philippine_data_extraction(LON[:,:,1],LAT[:,:,1], True)[0]\n",
    "landfallTC_PHI_wmo = philippine_data_extraction(LON[:,:,2],LAT[:,:,2])[0] #list (keys)\n",
    "landfallTC_PHI_wmo_after2014 = philippine_data_extraction(LON[:,:,2],LAT[:,:,2], True)[0]\n",
    "\n",
    "PHI_TCposition_jtwc = philippine_data_extraction(LON[:,:,0],LAT[:,:,0])[1] #dict (tc index and position index)\n",
    "PHI_TCposition_jtwc_after2014 = philippine_data_extraction(LON[:,:,0],LAT[:,:,0],True)[1]\n",
    "PHI_TCposition_cma = philippine_data_extraction(LON[:,:,1],LAT[:,:,1])[1] #dict (tc index and position index)\n",
    "PHI_TCposition_cma_after2014 = philippine_data_extraction(LON[:,:,1],LAT[:,:,1],True)[1]\n",
    "PHI_TCposition_wmo = philippine_data_extraction(LON[:,:,2],LAT[:,:,2])[1] #dict (tc index and position index)\n",
    "PHI_TCposition_wmo_after2014 = philippine_data_extraction(LON[:,:,2],LAT[:,:,2],True)[1]\n",
    "\n",
    "landfallTC_PHI_jtwc_N, landfallTC_PHI_jtwc_S, PHI_TCposition_jtwc_N, PHI_TCposition_jtwc_S = philippine_data_extraction(LON[:,:,0],LAT[:,:,0],False, True)\n",
    "landfallTC_PHI_jtwc_N_after2014, landfallTC_PHI_jtwc_S_after2014, PHI_TCposition_jtwc_N_after2014, PHI_TCposition_jtwc_S_after2014 = philippine_data_extraction(LON[:,:,0],LAT[:,:,0],True, True)\n",
    "landfallTC_PHI_cma_N, landfallTC_PHI_cma_S, PHI_TCposition_cma_N, PHI_TCposition_cma_S = philippine_data_extraction(LON[:,:,1],LAT[:,:,1],False, True)\n",
    "landfallTC_PHI_cma_N_after2014, landfallTC_PHI_cma_S_after2014, PHI_TCposition_cma_N_after2014, PHI_TCposition_cma_S_after2014 = philippine_data_extraction(LON[:,:,1],LAT[:,:,1],True, True)\n",
    "landfallTC_PHI_wmo_N, landfallTC_PHI_wmo_S, PHI_TCposition_wmo_N, PHI_TCposition_wmo_S = philippine_data_extraction(LON[:,:,2],LAT[:,:,2],False, True)\n",
    "landfallTC_PHI_wmo_N_after2014, landfallTC_PHI_wmo_S_after2014, PHI_TCposition_wmo_N_after2014, PHI_TCposition_wmo_S_after2014 = philippine_data_extraction(LON[:,:,2],LAT[:,:,2],True, True)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract GD data\n",
    "\n",
    "tic = time.time() #Expect runtime ~2min\n",
    "\n",
    "extremeG_N = [117.4, 24.2]\n",
    "extremeG_S = [109.8, 19.9]\n",
    "extremeG_E = [117.7, 22.9]\n",
    "extremeG_W = [109.4, 22.2]\n",
    "\n",
    "m_top_G = (extremeG_N[1]-extremeG_W[1])/(extremeG_N[0]-extremeG_W[0])\n",
    "m_bot_G = (extremeG_S[1]-extremeG_E[1])/(extremeG_S[0]-extremeG_E[0])\n",
    "m_left_G = (extremeG_S[1]-extremeG_W[1])/(extremeG_S[0]-extremeG_W[0])\n",
    "m_right_G = (extremeG_N[1]-extremeG_E[1])/(extremeG_N[0]-extremeG_E[0])\n",
    "\n",
    "c_top_G = extremeG_N[1]-m_top_G*extremeG_N[0]\n",
    "c_bot_G = extremeG_S[1]-m_bot_G*extremeG_S[0]\n",
    "c_left_G = extremeG_S[1]-m_left_G*extremeG_S[0]\n",
    "c_right_G = extremeG_N[1]-m_right_G*extremeG_N[0]\n",
    "\n",
    "def guangdong_landmask_points(landmask_LON,landmask_LAT):\n",
    "\n",
    "    landmask_points = []\n",
    "\n",
    "    for i in range(17200,17900): \n",
    "        for i2 in range(6500,7000):\n",
    "            equation_top = m_top_G * landmask_LON[i,i2] + c_top_G\n",
    "            equation_bot = m_bot_G * landmask_LON[i,i2] + c_bot_G \n",
    "            equation_left = m_left_G * landmask_LON[i,i2] + c_left_G\n",
    "            equation_right  = m_right_G * landmask_LON[i,i2] + c_right_G\n",
    "    \n",
    "            if landmask_LAT[i,i2] <= equation_top and landmask_LAT[i,i2] <= equation_right and landmask_LAT[i,i2] >= equation_bot and landmask_LAT[i,i2] >= equation_left:\n",
    "                landmask_points.append(i)\n",
    "                landmask_points.append(i2)\n",
    "        \n",
    "    return landmask_points\n",
    "\n",
    "def guangdong_data_extraction(LON,LAT,after2014=False): \n",
    "    guangdong_data = []\n",
    "    GD_TCposition = {}\n",
    "    \n",
    "    for i in range (len(LON)):\n",
    "        GD_TCposition[str(i)] = []\n",
    "        for i2 in range (len(LON[i])):\n",
    "            equation_top = m_top_G * LON[i,i2] + c_top_G\n",
    "            equation_bot = m_bot_G * LON[i,i2] + c_bot_G \n",
    "            equation_left = m_left_G * LON[i,i2] + c_left_G \n",
    "            equation_right  = m_right_G * LON[i,i2] + c_right_G\n",
    "            \n",
    "            if after2014 == True:\n",
    "                if i in TCinseason and LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                    guangdong_data.append((i))\n",
    "                    GD_TCposition[str(i)].append(i2)\n",
    "            else:\n",
    "                if LAT[i,i2] <= equation_top and LAT[i,i2] <= equation_right and LAT[i,i2] >= equation_bot and LAT[i,i2] >= equation_left: \n",
    "                    guangdong_data.append((i))\n",
    "                    GD_TCposition[str(i)].append(i2)\n",
    "            \n",
    "    return np.unique(guangdong_data), GD_TCposition\n",
    "\n",
    "landmask_in_area_GD = np.asarray(guangdong_landmask_points(landmask_LON,landmask_LAT))\n",
    "landmask_in_area_GD = landmask_in_area_GD.reshape(int(len(landmask_in_area_GD)/2),2)\n",
    "\n",
    "\n",
    "z_coastline_GD = []\n",
    "z_land_GD = []\n",
    "for i in range(len(landmask_in_area_GD)):\n",
    "    if z[landmask_in_area_GD[i,1],landmask_in_area_GD[i,0]] == 0: \n",
    "        z_coastline_GD.append(landmask_in_area_GD[i,0])\n",
    "        z_coastline_GD.append(landmask_in_area_GD[i,1])\n",
    "    elif z[landmask_in_area_GD[i,1],landmask_in_area_GD[i,0]] >= 0:\n",
    "        z_land_GD.append(landmask_in_area_GD[i,0])\n",
    "        z_land_GD.append(landmask_in_area_GD[i,1])\n",
    "        \n",
    "z_coastline_GD = np.asarray(z_coastline_GD).reshape(int(len(z_coastline_GD)/2),2)\n",
    "z_land_GD = np.asarray(z_land_GD).reshape(int(len(z_land_GD)/2),2)\n",
    "\n",
    "z_coastline_coord_GD = np.zeros(z_coastline_GD.shape) #list of coordinates of GD coastline\n",
    "z_coastline_coord_GD[:,0] = landmask_lon[z_coastline_GD[:,0]]\n",
    "z_coastline_coord_GD[:,1] = landmask_lat[z_coastline_GD[:,1]]\n",
    "\n",
    "z_land_coord_GD = np.zeros(z_land_GD.shape)\n",
    "z_land_coord_GD[:,0] = landmask_lon[z_land_GD[:,0]]\n",
    "z_land_coord_GD[:,1] = landmask_lat[z_land_GD[:,1]]\n",
    "        \n",
    "landfallTC_GD_jtwc = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0])[0] #list (index)\n",
    "landfallTC_GD_jtwc_after2014 = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0],True)[0]\n",
    "landfallTC_GD_cma = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1])[0] #list (index)\n",
    "landfallTC_GD_cma_after2014 = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1],True)[0]\n",
    "landfallTC_GD_wmo = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2])[0] #list (index)\n",
    "landfallTC_GD_wmo_after2014 = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2],True)[0]\n",
    "\n",
    "GD_TCposition_jtwc = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0])[1] #dict (tc index & position index)\n",
    "GD_TCposition_jtwc_after2014 = guangdong_data_extraction(LON[:,:,0],LAT[:,:,0],True)[1]\n",
    "GD_TCposition_cma = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1])[1] #dict (tc index & position index)\n",
    "GD_TCposition_cma_after2014 = guangdong_data_extraction(LON[:,:,1],LAT[:,:,1],True)[1]\n",
    "GD_TCposition_wmo = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2])[1] #dict (tc index & position index)\n",
    "GD_TCposition_wmo_after2014 = guangdong_data_extraction(LON[:,:,2],LAT[:,:,2],True)[1]\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "'''\n",
    "Here, we are only looking at the landfall typhoon point and the point before that\n",
    "'''\n",
    "\n",
    "tic = time.time() #Expected runtime ~45s\n",
    "\n",
    "#Gets the data for TCs at first landfall point, and closest point before landfall\n",
    "def get_landfall_data_beforeandafter(area, source, after2014 = False, PHI_NS = False):\n",
    "    #area: if PHI, type '0'; if GD, type '1'\n",
    "    #source: if JTWC, type '0'; if CMA, type '1'; if WMO, type '2'\n",
    "    #after2014: True means only include TC data after 2014\n",
    "    #Separate NS: If you want to separate PHI into Northern and Southern parts, type 'N' or 'S' respectively,\n",
    "    #    otherwise, or for GD, type 'False'\n",
    "    \n",
    "    pres = {}\n",
    "    wind = {}\n",
    "    coord = {}\n",
    "    disttoland = {}\n",
    "    list_of_index = {}\n",
    "    epsilon = 1e-5 #To account for rounding errors when comparing numbers\n",
    "    \n",
    "    if area == 0: #PHI\n",
    "        if source == 0: #jtwc\n",
    "            if PHI_NS == False:\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_jtwc_after2014\n",
    "                    posindex = PHI_TCposition_jtwc_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_jtwc\n",
    "                    posindex = PHI_TCposition_jtwc\n",
    "            elif PHI_NS == 'N':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_jtwc_N_after2014\n",
    "                    posindex = PHI_TCposition_jtwc_N_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_jtwc_N\n",
    "                    posindex = PHI_TCposition_jtwc_N\n",
    "            elif PHI_NS == 'S':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_jtwc_S_after2014\n",
    "                    posindex = PHI_TCposition_jtwc_S_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_jtwc_S\n",
    "                    posindex = PHI_TCposition_jtwc_S\n",
    "        elif source == 1: #cma\n",
    "            if PHI_NS == False:\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_cma_after2014\n",
    "                    posindex = PHI_TCposition_cma_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_cma\n",
    "                    posindex = PHI_TCposition_cma\n",
    "            elif PHI_NS == 'N':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_cma_N_after2014\n",
    "                    posindex = PHI_TCposition_cma_N_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_cma_N\n",
    "                    posindex = PHI_TCposition_cma_N\n",
    "            elif PHI_NS == 'S':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_cma_S_after2014\n",
    "                    posindex = PHI_TCposition_cma_S_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_cma_S\n",
    "                    posindex = PHI_TCposition_cma_S\n",
    "        elif source == 2: #wmo\n",
    "            if PHI_NS == False:\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_wmo_after2014\n",
    "                    posindex = PHI_TCposition_wmo_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_wmo\n",
    "                    posindex = PHI_TCposition_wmo\n",
    "            elif PHI_NS == 'N':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_wmo_N_after2014\n",
    "                    posindex = PHI_TCposition_wmo_N_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_wmo_N\n",
    "                    posindex = PHI_TCposition_wmo_N\n",
    "            elif PHI_NS == 'S':\n",
    "                if after2014 == True:\n",
    "                    tcindex = landfallTC_PHI_wmo_S_after2014\n",
    "                    posindex = PHI_TCposition_wmo_S_after2014\n",
    "                else:\n",
    "                    tcindex = landfallTC_PHI_wmo_S\n",
    "                    posindex = PHI_TCposition_wmo_S\n",
    "            \n",
    "            \n",
    "        landmask_lat = z_land_coord_PHI[:,1]\n",
    "        landmask_lon = z_land_coord_PHI[:,0]\n",
    "        for i in list(tcindex): #Loop over each TC in list\n",
    "            landindexinarea = []\n",
    "            for j in posindex[str(i)]: #Loop over each data point for that TC\n",
    "                TClat = LAT[:,:,source][i][j]\n",
    "                TClon = LON[:,:,source][i][j]\n",
    "                \n",
    "                #Find all land points with same latitude\n",
    "                landpoint_onlat_temp1 = np.where(landmask_lat <= TClat + epsilon)\n",
    "                landpoint_onlat_temp2 = np.where(landmask_lat >= TClat - epsilon)\n",
    "                landpoint_onlat_index = np.intersect1d(landpoint_onlat_temp1,landpoint_onlat_temp2) #Index of points in landmask array where latitude is same as TClat\n",
    "                landpoint_onlat_lon = landmask_lon[landpoint_onlat_index] #Lon of landmask points with same lat as TClat\n",
    "                \n",
    "                if landpoint_onlat_lon.size != 0:\n",
    "                    landpoint_onlat_maxlon = max(landpoint_onlat_lon) #Find easternmost PHI land point on same latitude\n",
    "                    landpoint_onlat_minlon = min(landpoint_onlat_lon) #Find westernmost PHI land point on same latitude\n",
    "                \n",
    "                    #Check whether TC is on land or ocean\n",
    "                    if landpoint_onlat_minlon-epsilon <= TClon <= landpoint_onlat_maxlon+epsilon:\n",
    "                        landindexinarea.append(j)\n",
    "            \n",
    "            landindexinarea = np.asarray(landindexinarea)\n",
    "            if landindexinarea.size != 0:\n",
    "                first_land_index = landindexinarea[0]\n",
    "                if first_land_index == 0:\n",
    "                    indexlist = [first_land_index]\n",
    "                else: \n",
    "                    indexlist = [first_land_index-1, first_land_index]\n",
    "\n",
    "                pres[str(i)] = MIN_PRES[:,:,source][int(i)][indexlist]\n",
    "                pres[str(i)] = [k for k in pres[str(i)] if k >= 0]\n",
    "                if pres[str(i)] == []:\n",
    "                    del pres[str(i)]\n",
    "                wind[str(i)] = MAX_WIND[:,:,source][int(i)][indexlist]\n",
    "                wind[str(i)] = [k for k in wind[str(i)] if k >= 0]\n",
    "                if wind[str(i)] == []:\n",
    "                    del wind[str(i)]\n",
    "                coord[str(i)] = np.array([LAT[:,:,source][int(i),indexlist],LON[:,:,source][int(i),indexlist]]).transpose()\n",
    "                if list(coord[str(i)][0]) == [-3e4,-3e4]: #Remove non-existant data\n",
    "                    coord[str(i)] = np.delete(coord[str(i)],0,0)\n",
    "                disttoland[str(i)] = DIST2LAND[int(i)][indexlist]\n",
    "                list_of_index[str(i)] = indexlist\n",
    "\n",
    "        if source == 1 and (PHI_NS == False or PHI_NS == 'N'):\n",
    "            #Add Mangkhut (to the end of the dict), source: cma\n",
    "            pres[str(len(list(season))+1)] = [910.0, 925.0] #Mangkhut\n",
    "            wind[str(len(list(season))+1)] = [65*1.944, 58*1.944] #Change m/s to knots\n",
    "            coord[str(len(list(season))+1)] = np.array([[17.8,123.4],[18.1,121.5]])    \n",
    "                \n",
    "\n",
    "    elif area == 1: #GD\n",
    "        if source == 0: #jtwc\n",
    "            if after2014 == True:\n",
    "                tcindex = landfallTC_GD_jtwc_after2014\n",
    "                posindex = GD_TCposition_jtwc_after2014\n",
    "            else:\n",
    "                tcindex = landfallTC_GD_jtwc\n",
    "                posindex = GD_TCposition_jtwc\n",
    "        elif source == 1: #cma\n",
    "            if after2014 == True:\n",
    "                tcindex = landfallTC_GD_cma_after2014\n",
    "                posindex = GD_TCposition_cma_after2014\n",
    "            else:\n",
    "                tcindex = landfallTC_GD_cma\n",
    "                posindex = GD_TCposition_cma\n",
    "        elif source == 2: #wmo\n",
    "            if after2014 == True:\n",
    "                tcindex = landfallTC_GD_wmo_after2014\n",
    "                posindex = GD_TCposition_wmo_after2014\n",
    "            else:\n",
    "                tcindex = landfallTC_GD_wmo\n",
    "                posindex = GD_TCposition_wmo\n",
    "\n",
    "        for i in list(tcindex):\n",
    "            distlist = DIST2LAND[int(i)][DIST2LAND[int(i)]>=0]\n",
    "            landindexes = np.where(distlist == 0)\n",
    "            landindexinarea = np.intersect1d(posindex[str(i)],landindexes)\n",
    "\n",
    "            if landindexinarea.size != 0:\n",
    "                first_land_index = landindexinarea[0]\n",
    "                if first_land_index == 0:\n",
    "                    indexlist = [first_land_index]\n",
    "                else: \n",
    "                    indexlist = [first_land_index-1, first_land_index]\n",
    "\n",
    "                pres[str(i)] = MIN_PRES[:,:,source][int(i)][indexlist]\n",
    "                pres[str(i)] = [k for k in pres[str(i)] if k >= 0] #Remove non-existant data\n",
    "                if pres[str(i)] == []:\n",
    "                    del pres[str(i)]\n",
    "                wind[str(i)] = MAX_WIND[:,:,source][int(i)][indexlist]\n",
    "                wind[str(i)] = [k for k in wind[str(i)] if k >= 0]\n",
    "                if wind[str(i)] == []:\n",
    "                    del wind[str(i)]\n",
    "                coord[str(i)] = np.array([LAT[:,:,source][int(i),indexlist],LON[:,:,source][int(i),indexlist]]).transpose()\n",
    "                if list(coord[str(i)][0]) == [-3e4,-3e4]: #Remove non-existant data\n",
    "                    coord[str(i)] = np.delete(coord[str(i)],0,0)\n",
    "                disttoland[str(i)] = DIST2LAND[int(i)][indexlist]\n",
    "                list_of_index[str(i)] = indexlist\n",
    "        \n",
    "        if source == 0:\n",
    "            #Add Hato (to the end of the dict), source: jtwc\n",
    "            pres[str(len(list(season)))] = [956.0, 964.0] #Hato\n",
    "            wind[str(len(list(season)))] = [90., 85.] #In knots\n",
    "            coord[str(len(list(season)))] = np.array([[21.5,114.5],[22.2,112.8]])\n",
    "            \n",
    "        elif source == 1:        \n",
    "            #Add Hato and Mangkhut (to the end of the dict), source: cma\n",
    "            pres[str(len(list(season)))] = [950.0, 950.0] #Hato\n",
    "            wind[str(len(list(season)))] = [42*1.944, 45*1.944] #Change m/s to knots\n",
    "            coord[str(len(list(season)))] = np.array([[21.5,114.7],[22.0,113.2]])\n",
    "\n",
    "            pres[str(len(list(season))+1)] = [950.0, 960.0] #Mangkhut\n",
    "            wind[str(len(list(season))+1)] = [48*1.944, 42*1.944]\n",
    "            coord[str(len(list(season))+1)] = np.array([[21.4, 113.8],[21.9, 112.0]])\n",
    "            \n",
    "    return pres, wind, coord, disttoland, list_of_index\n",
    "            \n",
    "##################### READ TILL HERE #################\n",
    "    \n",
    "landfalldata_pres_PHI_jtwc, landfalldata_wind_PHI_jtwc, landfalldata_coord_PHI_jtwc, landfalldata_dist2land_PHI_jtwc, landfalldata_indexlist_PHI_jtwc = get_landfall_data_beforeandafter(0,0)\n",
    "landfalldata_pres_GD_jtwc, landfalldata_wind_GD_jtwc, landfalldata_coord_GD_jtwc, landfalldata_dist2land_GD_jtwc, landfalldata_indexlist_GD_jtwc = get_landfall_data_beforeandafter(1,0)\n",
    "landfalldata_pres_PHI2014_jtwc, landfalldata_wind_PHI2014_jtwc, landfalldata_coord_PHI2014_jtwc, landfalldata_dist2land_PHI2014_jtwc, landfalldata_indexlist_PHI2014_jtwc = get_landfall_data_beforeandafter(0,0,True)\n",
    "landfalldata_pres_GD2014_jtwc, landfalldata_wind_GD2014_jtwc, landfalldata_coord_GD2014_jtwc, landfalldata_dist2land_GD2014_jtwc, landfalldata_indexlist_GD2014_jtwc = get_landfall_data_beforeandafter(1,0,True)\n",
    "\n",
    "landfalldata_pres_PHI_cma, landfalldata_wind_PHI_cma, landfalldata_coord_PHI_cma, landfalldata_dist2land_PHI_cma, landfalldata_indexlist_PHI_cma = get_landfall_data_beforeandafter(0,1)\n",
    "landfalldata_pres_GD_cma, landfalldata_wind_GD_cma, landfalldata_coord_GD_cma, landfalldata_dist2land_GD_cma, landfalldata_indexlist_GD_cma = get_landfall_data_beforeandafter(1,1)\n",
    "landfalldata_pres_PHI2014_cma, landfalldata_wind_PHI2014_cma, landfalldata_coord_PHI2014_cma, landfalldata_dist2land_PHI2014_cma, landfalldata_indexlist_PHI2014_cma = get_landfall_data_beforeandafter(0,1,True)\n",
    "landfalldata_pres_GD2014_cma, landfalldata_wind_GD2014_cma, landfalldata_coord_GD2014_cma, landfalldata_dist2land_GD2014_cma, landfalldata_indexlist_GD2014_cma = get_landfall_data_beforeandafter(1,1,True)\n",
    "\n",
    "landfalldata_pres_PHI_wmo, landfalldata_wind_PHI_wmo, landfalldata_coord_PHI_wmo, landfalldata_dist2land_PHI_wmo, landfalldata_indexlist_PHI_wmo = get_landfall_data_beforeandafter(0,2)\n",
    "landfalldata_pres_GD_wmo, landfalldata_wind_GD_wmo, landfalldata_coord_GD_wmo, landfalldata_dist2land_GD_wmo, landfalldata_indexlist_GD_wmo = get_landfall_data_beforeandafter(1,2)\n",
    "landfalldata_pres_PHI2014_wmo, landfalldata_wind_PHI2014_wmo, landfalldata_coord_PHI2014_wmo, landfalldata_dist2land_PHI2014_wmo, landfalldata_indexlist_PHI2014_wmo = get_landfall_data_beforeandafter(0,2,True)\n",
    "landfalldata_pres_GD2014_wmo, landfalldata_wind_GD2014_wmo, landfalldata_coord_GD2014_wmo, landfalldata_dist2land_GD2014_wmo, landfalldata_indexlist_GD2014_wmo = get_landfall_data_beforeandafter(1,2,True)\n",
    "\n",
    "landfalldata_pres_PHI_N_jtwc, landfalldata_wind_PHI_N_jtwc, landfalldata_coord_PHI_N_jtwc, landfalldata_dist2land_PHI_N_jtwc, landfalldata_indexlist_PHI_N_jtwc = get_landfall_data_beforeandafter(0,0,False,'N')\n",
    "landfalldata_pres_PHI_N2014_jtwc, landfalldata_wind_PHI_N2014_jtwc, landfalldata_coord_PHI_N2014_jtwc, landfalldata_dist2land_PHI_N2014_jtwc, landfalldata_indexlist_PHI_N2014_jtwc = get_landfall_data_beforeandafter(0,0,True,'N')\n",
    "landfalldata_pres_PHI_S_jtwc, landfalldata_wind_PHI_S_jtwc, landfalldata_coord_PHI_S_jtwc, landfalldata_dist2land_PHI_S_jtwc, landfalldata_indexlist_PHI_S_jtwc = get_landfall_data_beforeandafter(0,0,False,'S')\n",
    "landfalldata_pres_PHI_S2014_jtwc, landfalldata_wind_PHI_S2014_jtwc, landfalldata_coord_PHI_S2014_jtwc, landfalldata_dist2land_PHI_S2014_jtwc, landfalldata_indexlist_PHI_S2014_jtwc = get_landfall_data_beforeandafter(0,0,True,'S')\n",
    "\n",
    "landfalldata_pres_PHI_N_cma, landfalldata_wind_PHI_N_cma, landfalldata_coord_PHI_N_cma, landfalldata_dist2land_PHI_N_cma, landfalldata_indexlist_PHI_N_cma = get_landfall_data_beforeandafter(0,1,False,'N')\n",
    "landfalldata_pres_PHI_N2014_cma, landfalldata_wind_PHI_N2014_cma, landfalldata_coord_PHI_N2014_cma, landfalldata_dist2land_PHI_N2014_cma, landfalldata_indexlist_PHI_N2014_cma = get_landfall_data_beforeandafter(0,1,True,'N')\n",
    "landfalldata_pres_PHI_S_cma, landfalldata_wind_PHI_S_cma, landfalldata_coord_PHI_S_cma, landfalldata_dist2land_PHI_S_cma, landfalldata_indexlist_PHI_S_cma = get_landfall_data_beforeandafter(0,1,False,'S')\n",
    "landfalldata_pres_PHI_S2014_cma, landfalldata_wind_PHI_S2014_cma, landfalldata_coord_PHI_S2014_cma, landfalldata_dist2land_PHI_S2014_cma, landfalldata_indexlist_PHI_S2014_cma = get_landfall_data_beforeandafter(0,1,True,'S')\n",
    "\n",
    "landfalldata_pres_PHI_N_wmo, landfalldata_wind_PHI_N_wmo, landfalldata_coord_PHI_N_wmo, landfalldata_dist2land_PHI_N_wmo, landfalldata_indexlist_PHI_N_wmo = get_landfall_data_beforeandafter(0,2,False,'N')\n",
    "landfalldata_pres_PHI_N2014_wmo, landfalldata_wind_PHI_N2014_wmo, landfalldata_coord_PHI_N2014_wmo, landfalldata_dist2land_PHI_N2014_wmo, landfalldata_indexlist_PHI_N2014_wmo = get_landfall_data_beforeandafter(0,2,True,'N')\n",
    "landfalldata_pres_PHI_S_wmo, landfalldata_wind_PHI_S_wmo, landfalldata_coord_PHI_S_wmo, landfalldata_dist2land_PHI_S_wmo, landfalldata_indexlist_PHI_S_wmo = get_landfall_data_beforeandafter(0,2,False,'S')\n",
    "landfalldata_pres_PHI_S2014_wmo, landfalldata_wind_PHI_S2014_wmo, landfalldata_coord_PHI_S2014_wmo, landfalldata_dist2land_PHI_S2014_wmo, landfalldata_indexlist_PHI_S2014_wmo = get_landfall_data_beforeandafter(0,2,True,'S')\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Pressure deficit\n",
    "\n",
    "def pressure_deficit(area,source,separate_PHI = False, intersect = False):\n",
    "    #separate_PHI: 'N','S' or False\n",
    "    #intersect: 'True' if only using data of TCs appearing in all 3 agencies (to compare like to like events), 'False' otherwise\n",
    "    \n",
    "    pressure_dict = get_landfall_data_beforeandafter(area,source,False,separate_PHI)[0]\n",
    "    pres_def_before_list = []\n",
    "    pres_def_after_list = []\n",
    "    \n",
    "    if intersect == True:\n",
    "        key_a = list(get_landfall_data_beforeandafter(area,0,False,separate_PHI)[0].keys())\n",
    "        key_b = list(get_landfall_data_beforeandafter(area,1,False,separate_PHI)[0].keys())\n",
    "        key_c = list(get_landfall_data_beforeandafter(area,2,False,separate_PHI)[0].keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a,key_b),key_c) #Intersected list of TCs\n",
    "    else:\n",
    "        key_intersect_list = list(pressure_dict.keys())\n",
    "    \n",
    "    for key in key_intersect_list:\n",
    "        if len(pressure_dict[key]) == 1: \n",
    "            pres_def_after = 1010 - pressure_dict[key][0]\n",
    "            pres_def_after_list.append(pres_def_after)\n",
    "        else: \n",
    "            pres_def_before = 1010 - pressure_dict[key][0]\n",
    "            pres_def_after = 1010 - pressure_dict[key][1]\n",
    "            pres_def_before_list.append(pres_def_before)\n",
    "            pres_def_after_list.append(pres_def_after)\n",
    "    return pres_def_before_list, pres_def_after_list #pressure_deficit(area)[0] for the first list and pressure_deficit(area)[1] for the second list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Pressure deficit\n",
    "\n",
    "def pressure_deficit(area,source,separate_PHI = False, intersect = False):\n",
    "    #separate_PHI: 'N','S' or False\n",
    "    #intersect: 'True' if only using data of TCs appearing in all 3 agencies (to compare like to like events), 'False' otherwise\n",
    "    \n",
    "    pressure_dict = get_landfall_data_beforeandafter(area,source,False,separate_PHI)[0]\n",
    "    pres_def_before_list = []\n",
    "    pres_def_after_list = []\n",
    "    \n",
    "    if intersect == True:\n",
    "        key_a = list(get_landfall_data_beforeandafter(area,0,False,separate_PHI)[0].keys())\n",
    "        key_b = list(get_landfall_data_beforeandafter(area,1,False,separate_PHI)[0].keys())\n",
    "        key_c = list(get_landfall_data_beforeandafter(area,2,False,separate_PHI)[0].keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a,key_b),key_c) #Intersected list of TCs\n",
    "    else:\n",
    "        key_intersect_list = list(pressure_dict.keys())\n",
    "    \n",
    "    for key in key_intersect_list:\n",
    "        if len(pressure_dict[key]) == 1: \n",
    "            pres_def_after = 1010 - pressure_dict[key][0]\n",
    "            pres_def_after_list.append(pres_def_after)\n",
    "        else: \n",
    "            pres_def_before = 1010 - pressure_dict[key][0]\n",
    "            pres_def_after = 1010 - pressure_dict[key][1]\n",
    "            pres_def_before_list.append(pres_def_before)\n",
    "            pres_def_after_list.append(pres_def_after)\n",
    "    return pres_def_before_list, pres_def_after_list #pressure_deficit(area)[0] for the first list and pressure_deficit(area)[1] for the second list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# presdef_probability(area=0,source=0,binsize=10)\n",
    "# presdef_probability(0,1,10)\n",
    "# presdef_probability(0,2,10)\n",
    "# presdef_probability(1,0,10, False,False)\n",
    "# presdef_probability(1,1,10, False,False)\n",
    "# presdef_probability(1,2,10, False,False)\n",
    "# presdef_probability(0,0,10,'N')\n",
    "# presdef_probability(0,0,10,'S')\n",
    "# presdef_probability(0,1,10,'N')\n",
    "# presdef_probability(0,1,10,'S')\n",
    "#presdef_probability(0,2,10,'N')\n",
    "#presdef_probability(0,2,10,'S')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "'''\n",
    "calculating probability of max wind speed with log-normal fit\n",
    "'''\n",
    "def wind_speed(area, source, separate_PHI=False, intersect = False, pd_wind_int = False):\n",
    "    #pd_wind_int: 'True' if same TCs for plotting pd prob (in above) and wind prob, 'False' otherwise\n",
    "    windspeed_dict = get_landfall_data_beforeandafter(area, source, False,separate_PHI)[1]\n",
    "    windspeed_before_list = []\n",
    "    windspeed_after_list = []\n",
    "    \n",
    "    if pd_wind_int == True:\n",
    "        pressure_dict = get_landfall_data_beforeandafter(area, source, False,separate_PHI)[0]\n",
    "        key_a = list(pressure_dict.keys())\n",
    "        key_b = list(windspeed_dict.keys())\n",
    "        key_intersect_list = np.intersect1d(key_a,key_b)\n",
    "    \n",
    "    elif intersect == True:\n",
    "        key_a = list(get_landfall_data_beforeandafter(area,0,False,separate_PHI)[1].keys())\n",
    "        key_b = list(get_landfall_data_beforeandafter(area,1,False,separate_PHI)[1].keys())\n",
    "        key_c = list(get_landfall_data_beforeandafter(area,2,False,separate_PHI)[1].keys())\n",
    "        key_intersect_list = np.intersect1d(np.intersect1d(key_a,key_b),key_c)\n",
    "    else:\n",
    "        key_intersect_list = list(windspeed_dict.keys())\n",
    "        \n",
    "    \n",
    "    for key in key_intersect_list:\n",
    "        if len(windspeed_dict[key]) == 1: \n",
    "            windspeed_after_list. append(windspeed_dict[key][0])\n",
    "        else: \n",
    "            windspeed_before_list.append(windspeed_dict[key][0])\n",
    "            windspeed_after_list.append(windspeed_dict[key][1])\n",
    "\n",
    "    return windspeed_before_list, windspeed_after_list #before landfall, after landfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "'''\n",
    "calculating probability of max wind speed \n",
    "'''\n",
    "def wind_probability(area, source, separate_PHI = False, fitnorm = False, intersect = False, pd_wind_int = False):\n",
    "    #fitnorm: 'True' if fitting normal function, 'False' if fitting log-normal\n",
    "    x_range = list(range(0,131,10))\n",
    "    b, a = wind_speed(area, source, separate_PHI, intersect, pd_wind_int)\n",
    "    b = [i for i in b if i != 0] #Remove 0 values as they are actually missing data\n",
    "    a = [j for j in a if j != 0]\n",
    "    before_list = [int(i) for i in b]\n",
    "    after_list = [int(j) for j in a]\n",
    "    \n",
    "\n",
    "    \n",
    "    prob_before = []\n",
    "    prob_after = []\n",
    "    for i in range(len(x_range)-1) : \n",
    "        count_before = 0 \n",
    "        count_after = 0\n",
    "        for j in range(len(after_list)):\n",
    "            if i < len(x_range)-1 and x_range[i+1] > after_list[j] >= x_range[i]: # to make sure that it only includes one range each time but not more than one\n",
    "                count_after = count_after + 1 \n",
    "        for j in range(len(before_list)):\n",
    "            if i < len(x_range)-1 and x_range[i+1] > before_list[j] >= x_range[i]:\n",
    "                count_before = count_before + 1 \n",
    "        prob_before.append((count_before/len(before_list))/(130/len(x_range)))\n",
    "        prob_after.append((count_after/len(after_list))/(130/len(x_range)))\n",
    "        \n",
    "    prob_before = np.asarray(prob_before)\n",
    "    prob_after = np.asarray(prob_after)\n",
    "        \n",
    "    #Plot before landfall\n",
    "    plt.figure()\n",
    "    plt.xlabel('Maximum Wind Speed (kt)')\n",
    "    plt.ylabel('Probability') \n",
    "    plt.ylim(0,0.06)\n",
    "    x_axis = list(np.arange(5,130,10))\n",
    "    plt.scatter(x_axis, prob_before,color = 'k')\n",
    "\n",
    "    x = np.arange(0, 131, 1)\n",
    "    \n",
    "    if fitnorm == True:\n",
    "        mu, std = norm.fit(after_list)\n",
    "        p = norm.pdf(x, mu,std)\n",
    "        skew = 0\n",
    "    else:\n",
    "        s, loc, scale = lognorm.fit(before_list, loc = 0)\n",
    "        mu, var, skew = lognorm.stats(s, loc, scale, moments='mvs')\n",
    "        std = np.sqrt(var)\n",
    "        p = lognorm.pdf(x, s, loc, scale)\n",
    "    p = np.asarray(p)\n",
    "    zeroindexlist = np.where(p == 0)\n",
    "    p[zeroindexlist] = 1e-80 #Make zero to a very small number for chi-square test\n",
    "    \n",
    "    x_at_datapt_index = [i for i in range(len(x)) if x[i] in x_axis] #Find index in x where there is a data point in x_axis\n",
    "    p_mse = p[x_at_datapt_index]\n",
    "    chisq, pvalue = chisquare(prob_before*130/len(x_range)*len(before_list), p_mse*130/len(x_range)*len(before_list), ddof=2) #Perform chi-sq test\n",
    "#    print(str(source), chisq, pvalue)\n",
    "\n",
    "    rmserr = np.sqrt(mean_squared_error(prob_before, p_mse))\n",
    "    \n",
    "    samplesize = len(before_list)\n",
    "    plt.plot(x, p,'b-')\n",
    "    \n",
    "    #Plot title\n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Northern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Southern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 1:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Northern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Southern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 2:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Northern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons before their landfalls in the Southern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "    \n",
    "    else: \n",
    "        if source == 0:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons before their landfalls in Guangdong \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons before their landfalls in Guangdong \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons before their landfalls in Guangdong \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Plot after landfall\n",
    "    plt.figure()\n",
    "    plt.xlabel('Maximum Wind Speed (kt)')  \n",
    "    plt.ylabel('Probability') \n",
    "    plt.ylim(0,0.06)\n",
    "    x_axis = list(np.arange(5,130,10))\n",
    "    plt.scatter(x_axis, prob_after,color = 'r')\n",
    "    \n",
    "    x = np.arange(0, 131, 1)\n",
    "    if fitnorm == True:\n",
    "        mu, std = norm.fit(after_list)\n",
    "        p = norm.pdf(x, mu,std)\n",
    "        skew = 0\n",
    "    else:\n",
    "        s, loc, scale = lognorm.fit(after_list, loc = 0)\n",
    "        mu, var, skew = lognorm.stats(s, loc, scale, moments='mvs')\n",
    "        std = np.sqrt(var)\n",
    "        p = lognorm.pdf(x, s, loc, scale)\n",
    "    p = np.asarray(p)\n",
    "    zeroindexlist = np.where(p == 0)\n",
    "    p[zeroindexlist] = 1e-80 #Make zero to a very small number for chi-square test\n",
    "    \n",
    "    x_at_datapt_index = [i for i in range(len(x)) if x[i] in x_axis] #Find index in x where there is a data point in x_axis\n",
    "    p_mse = p[x_at_datapt_index]\n",
    "    chisq, pvalue = chisquare(prob_after*130/len(x_range)*len(after_list), p_mse*130/len(x_range)*len(after_list), ddof=2)\n",
    "#    print(str(source), chisq, pvalue)\n",
    "\n",
    "    rmserr = np.sqrt(mean_squared_error(prob_after, p_mse))\n",
    "\n",
    "    samplesize = len(after_list)\n",
    "    plt.plot(x, p, 'b-')\n",
    "    \n",
    "    print(prob_after*130/len(x_range)*len(after_list))\n",
    "    print(p_mse*130/len(x_range)*len(after_list))\n",
    "\n",
    "    \n",
    "    if area == 0:\n",
    "        if source == 0:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Northern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Southern Philippines \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "        elif source == 1:\n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Northern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Southern Philippines \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "        elif source == 2: \n",
    "            if separate_PHI == False:\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'N':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Northern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "            elif separate_PHI == 'S':\n",
    "                plt.title('Probability distribution of max wind speed of typhoons at their landfalls in the Southern Philippines \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small') \n",
    "    else: \n",
    "        if source == 0:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons at their landfalls in Guangdong \\n source: JTWC, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 1:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons at their landfalls in Guangdong \\n source: CMA, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "        elif source == 2:\n",
    "            plt.title('Probability distribution of max wind speed of typhoons at their landfalls in Guangdong \\n source: WMO, sample size = ' + str(samplesize) + ', mu = ' + str(mu) + '\\n s.d. = ' + str(std) + ', skewness = ' + str(skew) + ', RMS error = ' + str(rmserr), fontsize='small')\n",
    "    plt.show()\n",
    "    \n",
    "    return prob_before, prob_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "wind_probability(0,0,False)\n",
    "# wind_probability(0,1,False)\n",
    "# wind_probability(0,2,False)\n",
    "# wind_probability(1,0,False,False,False,True)\n",
    "# wind_probability(1,0,False,False,False,False)\n",
    "# wind_probability(1,1,False,False,False,True)\n",
    "# wind_probability(1,2,False,False,False,True)\n",
    "# wind_probability(0, 0,'N')\n",
    "# wind_probability(0, 1,'N')\n",
    "# wind_probability(0, 2,'N')\n",
    "# wind_probability(0, 0,'S')\n",
    "# wind_probability(0, 1,'S')\n",
    "# wind_probability(0, 2,'S')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise TC coordinates\n",
    "#Plots the coastline and the landfall TC coordinates of whole area\n",
    "def plot_points(area, source, after2014 = False, PHI_NS = False): \n",
    "    if area == 0: #PHI\n",
    "        landcoord = z_land_coord_PHI\n",
    "        if source == 0:\n",
    "            if after2014 == True:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI2014_jtwc #List of coordinates of TC centre\n",
    "                    keys = landfalldata_coord_PHI2014_jtwc.keys() #Keys of dict (TC indexes)\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N2014_jtwc\n",
    "                    keys = landfalldata_coord_PHI_N2014_jtwc.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S2014_jtwc\n",
    "                    keys = landfalldata_coord_PHI_S2014_jtwc.keys()\n",
    "            elif after2014 == False:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI_jtwc\n",
    "                    keys = landfalldata_coord_PHI_jtwc.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N_jtwc\n",
    "                    keys = landfalldata_coord_PHI_N_jtwc.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S_jtwc\n",
    "                    keys = landfalldata_coord_PHI_S_jtwc.keys()\n",
    "                    \n",
    "        elif source == 1:\n",
    "            if after2014 == True:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI2014_cma\n",
    "                    keys = landfalldata_coord_PHI2014_cma.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N2014_cma\n",
    "                    keys = landfalldata_coord_PHI_N2014_cma.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S2014_cma\n",
    "                    keys = landfalldata_coord_PHI_S2014_cma.keys()\n",
    "            elif after2014 == False:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI_cma\n",
    "                    keys = landfalldata_coord_PHI_cma.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N_cma\n",
    "                    keys = landfalldata_coord_PHI_N_cma.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S_cma\n",
    "                    keys = landfalldata_coord_PHI_S_cma.keys()\n",
    "        elif source == 2:\n",
    "            if after2014 == True:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI2014_wmo\n",
    "                    keys = landfalldata_coord_PHI2014_wmo.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N2014_wmo\n",
    "                    keys = landfalldata_coord_PHI_N2014_wmo.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S2014_wmo\n",
    "                    keys = landfalldata_coord_PHI_S2014_wmo.keys()\n",
    "            elif after2014 == False:\n",
    "                if PHI_NS == False:\n",
    "                    coordlist = landfalldata_coord_PHI_wmo\n",
    "                    keys = landfalldata_coord_PHI_wmo.keys()\n",
    "                elif PHI_NS == 'N':\n",
    "                    coordlist = landfalldata_coord_PHI_N_wmo\n",
    "                    keys = landfalldata_coord_PHI_N_wmo.keys()\n",
    "                elif PHI_NS == 'S':\n",
    "                    coordlist = landfalldata_coord_PHI_S_wmo\n",
    "                    keys = landfalldata_coord_PHI_S_wmo.keys()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    elif area == 1: #GD\n",
    "        landcoord = z_land_coord_GD\n",
    "        if source == 0:\n",
    "            if after2014 == True:\n",
    "                coordlist = landfalldata_coord_GD2014_jtwc\n",
    "                keys = landfalldata_coord_GD2014_jtwc.keys()\n",
    "            elif after2014 == False:\n",
    "                coordlist = landfalldata_coord_GD_jtwc\n",
    "                keys = landfalldata_coord_GD_jtwc.keys()\n",
    "        elif source == 1:\n",
    "            if after2014 == True:\n",
    "                coordlist = landfalldata_coord_GD2014_cma\n",
    "                keys = landfalldata_coord_GD2014_cma.keys()\n",
    "            elif after2014 == False:\n",
    "                coordlist = landfalldata_coord_GD_cma\n",
    "                keys = landfalldata_coord_GD_cma.keys()\n",
    "        elif source == 2:\n",
    "            if after2014 == True:\n",
    "                coordlist = landfalldata_coord_GD2014_wmo\n",
    "                keys = landfalldata_coord_GD2014_wmo.keys()\n",
    "            elif after2014 == False:\n",
    "                coordlist = landfalldata_coord_GD_wmo\n",
    "                keys = landfalldata_coord_GD_wmo.keys()    \n",
    "    color = iter(cm.rainbow(np.linspace(0,1,len(keys))))\n",
    "    plt.figure()  \n",
    "    if area == 0: \n",
    "        if source == 0:\n",
    "            if PHI_NS == False:\n",
    "                plt.title('Tracks of typhoons with landfall in the Philippines, source: JTWC') \n",
    "            elif PHI_NS == 'N':\n",
    "                plt.title('Tracks of typhoons with landfall in the Northern Philippines, source: JTWC') \n",
    "            elif PHI_NS == 'S':\n",
    "                plt.title('Tracks of typhoons with landfall in the Southern Philippines, source: JTWC')\n",
    "        elif source == 1:\n",
    "            if PHI_NS == False:\n",
    "                plt.title('Tracks of typhoons with landfall in the Philippines, source: CMA') \n",
    "            elif PHI_NS == 'N':\n",
    "                plt.title('Tracks of typhoons with landfall in the Northern Philippines, source: CMA') \n",
    "            elif PHI_NS == 'S':\n",
    "                plt.title('Tracks of typhoons with landfall in the Southern Philippines, source: CMA')\n",
    "        elif source == 2:\n",
    "            if PHI_NS == False:\n",
    "                plt.title('Tracks of typhoons with landfall in the Philippines, source: WMO') \n",
    "            elif PHI_NS == 'N':\n",
    "                plt.title('Tracks of typhoons with landfall in the Northern Philippines, source: WMO') \n",
    "            elif PHI_NS == 'S':\n",
    "                plt.title('Tracks of typhoons with landfall in the Southern Philippines, source: WMO')\n",
    "    else:\n",
    "        if source == 0:\n",
    "            plt.title('Tracks of typhoons with landfall in Guangdong, source: JTWC')\n",
    "        elif source == 1:\n",
    "            plt.title('Tracks of typhoons with landfall in Guangdong, source: CMA')\n",
    "        elif source == 2:   \n",
    "            plt.title('Tracks of typhoons with landfall in Guangdong, source: WMO')\n",
    "    plt.xlabel('Longitude (E)') \n",
    "    plt.ylabel('Latitude (N)')\n",
    "    plt.scatter(landcoord[:,0],landcoord[:,1],color = 'k', s=5)\n",
    "    if after2014 == True:\n",
    "        size = 20\n",
    "    else:\n",
    "        size = 5\n",
    "    for index in list(keys):\n",
    "        c=next(color)\n",
    "        plt.scatter(coordlist[index][:,1],coordlist[index][:,0],color = c,s=size, label = index)\n",
    "    if after2014 == False:\n",
    "        plt.legend(fontsize=4)\n",
    "    else:\n",
    "        plt.legend(fontsize='x-small')\n",
    "    plt.axis('equal')\n",
    "\n",
    "\n",
    "#Plots the coastline and the landfall TC coordinates of individual TC\n",
    "def plot_points_landfall_indiv(source, tcindex):\n",
    "    plt.figure()\n",
    "    plt.title(str(tcindex))\n",
    "    if source == 0:\n",
    "        coorddictPHI = landfalldata_coord_PHI_jtwc\n",
    "        coorddictGD = landfalldata_coord_GD_jtwc\n",
    "    else:\n",
    "        coorddictPHI = landfalldata_coord_PHI_cma\n",
    "        coorddictGD = landfalldata_coord_GD_cma\n",
    "    if str(tcindex) in landfalldata_coord_PHI:\n",
    "        plt.scatter(z_land_coord_PHI[:,0],z_land_coord_PHI[:,1],color = 'k')\n",
    "        plt.scatter(coorddictPHI[str(tcindex)][:,1],coorddictPHI[str(tcindex)][:,0], color = 'r')\n",
    "    if str(tcindex) in landfalldata_coord_GD:\n",
    "        plt.scatter(z_land_coord_GD[:,0],z_land_coord_GD[:,1],color = 'k')\n",
    "        plt.scatter(coorddictGD[str(tcindex)][:,1],coorddictGD[str(tcindex)][:,0], color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_points(0, 0, True, False)\n",
    "plot_points(0, 1, True, False)\n",
    "plot_points(0, 2, True, False)\n",
    "plot_points(0, 0, True, 'N')\n",
    "plot_points(0, 1, True, 'N')\n",
    "plot_points(0, 0, True, 'S')\n",
    "plot_points(0, 1, True, 'S')\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_points(0, 0, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "plot_points(1, 1, True)\n",
    "#plot_points(1, 1, True)\n",
    "#plot_points(1, 0, False)\n",
    "#plot_points(1, 1, False)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "'''\n",
    "extract dates of typhoon for rainfall data\n",
    "'''\n",
    "\n",
    "time_units = ibt.variables['source_time'].getncattr('units')\n",
    "\n",
    "#Change dates of TCs to common understandable format\n",
    "def getdates(tcindex): \n",
    "    datelist = list(num2date(time_record,time_units)[tcindex])\n",
    "\n",
    "    return datelist #returns a list in (year, month, day, hour, minute, second) format\n",
    "\n",
    "#Get dates of TCs at landfall\n",
    "def getdates_landfall(area, after2014 = False):\n",
    "    landfall_dates = {}\n",
    "    if after2014 == True:\n",
    "        indexlist = get_landfall_data_beforeandafter(area, True)[4]\n",
    "    else:\n",
    "        indexlist = get_landfall_data_beforeandafter(area, False)[4]\n",
    "        \n",
    "    for key in indexlist.keys():\n",
    "        print(key)\n",
    "        landfall_dates[key] = list(num2date(time_record,time_units)[int(key), indexlist[key]])\n",
    "    return landfall_dates\n",
    "\n",
    "#WARNING: Extremely long runtime, dates are pasted in cell below so code does not have to be rerun again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "'''\n",
    "Probability of landfall in GD and PHI \n",
    "'''\n",
    "tic = time.time() #WARNING: Expected runtime ~30min\n",
    "\n",
    "#Creates a dictionary recording data\n",
    "def landfall_probability(area, source):\n",
    "    yeardict = {}\n",
    "    yeardicttotal = {}\n",
    "    \n",
    "    if source == 0:\n",
    "        startyear = 1945\n",
    "    elif source == 1:\n",
    "        startyear = 1949\n",
    "    elif source == 2: \n",
    "        startyear = 1951\n",
    "        \n",
    "    for i in range(startyear, 2017): #No data before startyear, and 2017 data not complete\n",
    "        yeardict[str(i)] = []\n",
    "        yeardicttotal[str(i)] = []\n",
    "    for tcindex in range(len(list(season))):\n",
    "        if tcindex%100 == 0: #Just to check whether code is running + progress\n",
    "            print(tcindex)\n",
    "        i = list(season)[tcindex] #i is the year\n",
    "        if i in list(range(startyear,2017)):\n",
    "            yeardicttotal[str(i)].append(tcindex)\n",
    "            if area == 0:\n",
    "                if source == 0:\n",
    "                    if str(tcindex) in landfalldata_coord_PHI_jtwc.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 1:\n",
    "                    if str(tcindex) in landfalldata_coord_PHI_cma.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 2:\n",
    "                    if str(tcindex) in landfalldata_coord_PHI_wmo.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "            else:\n",
    "                if source == 0:\n",
    "                    if str(tcindex) in landfalldata_coord_GD_jtwc.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 1:\n",
    "                    if str(tcindex) in landfalldata_coord_GD_cma.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "                elif source == 2:\n",
    "                    if str(tcindex) in landfalldata_coord_GD_wmo.keys():\n",
    "                        yeardict[str(i)].append(tcindex)\n",
    "\n",
    "    landfall_number_list = []\n",
    "    landfall_number_list_total = []\n",
    "    landfall_counts = {}\n",
    "    landfall_counts_total = {}\n",
    "    for year in yeardict.keys():\n",
    "        landfall_number_list.append(len(yeardict[year])) #Append the number of landfalls in year\n",
    "#        landfall_number_list_total.append(len(yeardicttotal[year]))\n",
    "    for n in range(max(landfall_number_list)+1):\n",
    "        landfall_counts[str(n)] = landfall_number_list.count(n)\n",
    "#        landfall_counts_total[str(n)] = landfall_number_list_total.count(n)\n",
    "        \n",
    "#     print(yeardict, landfall_number_list)\n",
    "    return landfall_counts #, yeardict, yeardicttotal\n",
    "    \n",
    "landfall_no_PHI_jtwc = landfall_probability(0,0)\n",
    "landfall_no_PHI_cma = landfall_probability(0,1)\n",
    "landfall_no_PHI_wmo = landfall_probability(0,2)\n",
    "landfall_no_GD_jtwc = landfall_probability(1,0)\n",
    "landfall_no_GD_cma = landfall_probability(1,1)\n",
    "landfall_no_GD_wmo = landfall_probability(1,2)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
